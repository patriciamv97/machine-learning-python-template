{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils import db_connect\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import numpy as np\n",
                "import statsmodels.api as sm\n",
                "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
                "from sklearn.model_selection import train_test_split\n",
                "import xgboost as xgb\n",
                "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from lazypredict.Supervised import LazyRegressor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "ename": "OperationalError",
                    "evalue": "(psycopg2.OperationalError) connection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  database \"example\" does not exist\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:146\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3304\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[1;32m   3284\u001b[0m \n\u001b[1;32m   3285\u001b[0m \u001b[38;5;124;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3302\u001b[0m \n\u001b[1;32m   3303\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:449\u001b[0m, in \u001b[0;36mPool.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m \n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:1263\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[0;32m-> 1263\u001b[0m     fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:712\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 712\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:179\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:177\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:390\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:674\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[0;34m(self, pool, connect)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:900\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 900\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    901\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:896\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 896\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py:643\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[0;34m(connection_record)\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[0;32m--> 643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py:617\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[0;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_dbapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/psycopg2/__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                        "\u001b[0;31mOperationalError\u001b[0m: connection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  database \"example\" does not exist\n",
                        "\nThe above exception was the direct cause of the following exception:\n",
                        "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Establecer la conexión a la base de datos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[43mdb_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Verificar si la conexión es exitosa\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#if engine:\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#print(\"Conexión exitosa\")\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Consultar la tabla en la base de datos y crear un DataFrame\u001b[39;00m\n\u001b[1;32m      9\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql_table(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019-ABNB\u001b[39m\u001b[38;5;124m'\u001b[39m, engine)\n",
                        "File \u001b[0;32m/workspaces/machine-learning-python-template/src/utils.py:12\u001b[0m, in \u001b[0;36mdb_connect\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     11\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_engine(os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATABASE_URL\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 12\u001b[0m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3280\u001b[0m, in \u001b[0;36mEngine.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Connection:\n\u001b[1;32m   3258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[1;32m   3259\u001b[0m \n\u001b[1;32m   3260\u001b[0m \u001b[38;5;124;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3277\u001b[0m \n\u001b[1;32m   3278\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:148\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 148\u001b[0m         \u001b[43mConnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception_noconnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2444\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception_noconnection\u001b[0;34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[0m\n\u001b[1;32m   2442\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2443\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2445\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2446\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:146\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    148\u001b[0m         Connection\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[1;32m    149\u001b[0m             err, dialect, engine\n\u001b[1;32m    150\u001b[0m         )\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3304\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[1;32m   3283\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[1;32m   3284\u001b[0m \n\u001b[1;32m   3285\u001b[0m \u001b[38;5;124;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3302\u001b[0m \n\u001b[1;32m   3303\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:449\u001b[0m, in \u001b[0;36mPool.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m \n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:1263\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_checkout\u001b[39m(\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     fairy: Optional[_ConnectionFairy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ConnectionFairy:\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[0;32m-> 1263\u001b[0m         fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1266\u001b[0m             threadconns\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(fairy)\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:712\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    710\u001b[0m     rec \u001b[38;5;241m=\u001b[39m cast(_ConnectionRecord, pool\u001b[38;5;241m.\u001b[39m_do_get())\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 712\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     dbapi_connection \u001b[38;5;241m=\u001b[39m rec\u001b[38;5;241m.\u001b[39mget_connection()\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:179\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:177\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inc_overflow():\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:390\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ConnectionPoolEntry:\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:674\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[0;34m(self, pool, connect)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pool \u001b[38;5;241m=\u001b[39m pool\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:900\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 900\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    901\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py:896\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 896\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m     pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py:643\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[0;34m(connection_record)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[0;32m--> 643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py:617\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[0;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_dbapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/psycopg2/__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     kwasync[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcursor_factory \u001b[38;5;241m=\u001b[39m cursor_factory\n",
                        "\u001b[0;31mOperationalError\u001b[0m: (psycopg2.OperationalError) connection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  database \"example\" does not exist\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
                    ]
                }
            ],
            "source": [
                "\n",
                "# Establecer la conexión a la base de datos\n",
                "engine = db_connect()\n",
                "\n",
                "# Verificar si la conexión es exitosa\n",
                "#if engine:\n",
                "    #print(\"Conexión exitosa\")\n",
                "\n",
                "# Consultar la tabla en la base de datos y crear un DataFrame\n",
                "data = pd.read_sql_table('2019-ABNB', engine)\n",
                "\n",
                "pd.set_option('display.max_columns', None)  # muestra todas las columnas del dataframe\n",
                "data.head()\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>id</th>\n",
                            "      <th>name</th>\n",
                            "      <th>host_id</th>\n",
                            "      <th>host_name</th>\n",
                            "      <th>neighbourhood_group</th>\n",
                            "      <th>neighbourhood</th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>room_type</th>\n",
                            "      <th>price</th>\n",
                            "      <th>minimum_nights</th>\n",
                            "      <th>number_of_reviews</th>\n",
                            "      <th>last_review</th>\n",
                            "      <th>reviews_per_month</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>2539</td>\n",
                            "      <td>Clean &amp; quiet apt home by the park</td>\n",
                            "      <td>2787</td>\n",
                            "      <td>John</td>\n",
                            "      <td>Brooklyn</td>\n",
                            "      <td>Kensington</td>\n",
                            "      <td>40.65</td>\n",
                            "      <td>-73.97</td>\n",
                            "      <td>Private room</td>\n",
                            "      <td>149</td>\n",
                            "      <td>1</td>\n",
                            "      <td>9</td>\n",
                            "      <td>2018-10-19</td>\n",
                            "      <td>0.21</td>\n",
                            "      <td>6</td>\n",
                            "      <td>365</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2595</td>\n",
                            "      <td>Skylit Midtown Castle</td>\n",
                            "      <td>2845</td>\n",
                            "      <td>Jennifer</td>\n",
                            "      <td>Manhattan</td>\n",
                            "      <td>Midtown</td>\n",
                            "      <td>40.75</td>\n",
                            "      <td>-73.98</td>\n",
                            "      <td>Entire home/apt</td>\n",
                            "      <td>225</td>\n",
                            "      <td>1</td>\n",
                            "      <td>45</td>\n",
                            "      <td>2019-05-21</td>\n",
                            "      <td>0.38</td>\n",
                            "      <td>2</td>\n",
                            "      <td>355</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>3647</td>\n",
                            "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
                            "      <td>4632</td>\n",
                            "      <td>Elisabeth</td>\n",
                            "      <td>Manhattan</td>\n",
                            "      <td>Harlem</td>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>Private room</td>\n",
                            "      <td>150</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>1</td>\n",
                            "      <td>365</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>3831</td>\n",
                            "      <td>Cozy Entire Floor of Brownstone</td>\n",
                            "      <td>4869</td>\n",
                            "      <td>LisaRoxanne</td>\n",
                            "      <td>Brooklyn</td>\n",
                            "      <td>Clinton Hill</td>\n",
                            "      <td>40.69</td>\n",
                            "      <td>-73.96</td>\n",
                            "      <td>Entire home/apt</td>\n",
                            "      <td>89</td>\n",
                            "      <td>1</td>\n",
                            "      <td>270</td>\n",
                            "      <td>2019-07-05</td>\n",
                            "      <td>4.64</td>\n",
                            "      <td>1</td>\n",
                            "      <td>194</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>5022</td>\n",
                            "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
                            "      <td>7192</td>\n",
                            "      <td>Laura</td>\n",
                            "      <td>Manhattan</td>\n",
                            "      <td>East Harlem</td>\n",
                            "      <td>40.80</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>Entire home/apt</td>\n",
                            "      <td>80</td>\n",
                            "      <td>10</td>\n",
                            "      <td>9</td>\n",
                            "      <td>2018-11-19</td>\n",
                            "      <td>0.10</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "     id                                              name  host_id  \\\n",
                            "0  2539                Clean & quiet apt home by the park     2787   \n",
                            "1  2595                             Skylit Midtown Castle     2845   \n",
                            "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
                            "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
                            "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
                            "\n",
                            "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
                            "0         John            Brooklyn    Kensington     40.65     -73.97   \n",
                            "1     Jennifer           Manhattan       Midtown     40.75     -73.98   \n",
                            "2    Elisabeth           Manhattan        Harlem     40.81     -73.94   \n",
                            "3  LisaRoxanne            Brooklyn  Clinton Hill     40.69     -73.96   \n",
                            "4        Laura           Manhattan   East Harlem     40.80     -73.94   \n",
                            "\n",
                            "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
                            "0     Private room    149               1                  9  2018-10-19   \n",
                            "1  Entire home/apt    225               1                 45  2019-05-21   \n",
                            "2     Private room    150               3                  0         NaN   \n",
                            "3  Entire home/apt     89               1                270  2019-07-05   \n",
                            "4  Entire home/apt     80              10                  9  2018-11-19   \n",
                            "\n",
                            "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
                            "0               0.21                               6               365  \n",
                            "1               0.38                               2               355  \n",
                            "2                NaN                               1               365  \n",
                            "3               4.64                               1               194  \n",
                            "4               0.10                               1                 0  "
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data = pd.read_csv('/workspaces/machine-learning-python-template/data/raw/AB_NYC_2019.csv')\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 48895 entries, 0 to 48894\n",
                        "Data columns (total 16 columns):\n",
                        " #   Column                          Non-Null Count  Dtype  \n",
                        "---  ------                          --------------  -----  \n",
                        " 0   id                              48895 non-null  int64  \n",
                        " 1   name                            48879 non-null  object \n",
                        " 2   host_id                         48895 non-null  int64  \n",
                        " 3   host_name                       48874 non-null  object \n",
                        " 4   neighbourhood_group             48895 non-null  object \n",
                        " 5   neighbourhood                   48895 non-null  object \n",
                        " 6   latitude                        48895 non-null  float64\n",
                        " 7   longitude                       48895 non-null  float64\n",
                        " 8   room_type                       48895 non-null  object \n",
                        " 9   price                           48895 non-null  int64  \n",
                        " 10  minimum_nights                  48895 non-null  int64  \n",
                        " 11  number_of_reviews               48895 non-null  int64  \n",
                        " 12  last_review                     38843 non-null  object \n",
                        " 13  reviews_per_month               38843 non-null  float64\n",
                        " 14  calculated_host_listings_count  48895 non-null  int64  \n",
                        " 15  availability_365                48895 non-null  int64  \n",
                        "dtypes: float64(3), int64(7), object(6)\n",
                        "memory usage: 6.0+ MB\n"
                    ]
                }
            ],
            "source": [
                "# Mostrar informacion sobre el dataframe\n",
                "data.shape\n",
                "data.info()\n",
                "\n",
                "# En principio vemos que las columna id, host_id se pueden eliminar\n",
                "\n",
                "# host_name tambien se puede eliminar, ya que de entre todos los anuncios listados (48895), 48874 son distintos, es decir,\n",
                "#  * solo hay 21 inmuebles que podrían tener el mismo propietario, 0,04% de la muestra. Por tanto, podemos predecir ya que la identidad del propietario no tiene mayor impacto en la cuestion.\n",
                "\n",
                "# En cuanto a la columna 'name', que vemos que contiene una pequeña descripción, nos encontramos en una situacion parecida, sin embargo,\n",
                "#  * puesto que se trata de un pequeño 'titular', podemos pensar que no tiene relacion con el precio, pero si es posible que este titular tenga\n",
                "#  * impacto sobre la demanda, lo que tiene impacto en el precio. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>name</th>\n",
                            "      <th>number_of_reviews</th>\n",
                            "      <th>price</th>\n",
                            "      <th>reviews_per_month</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Clean &amp; quiet apt home by the park</td>\n",
                            "      <td>9</td>\n",
                            "      <td>149</td>\n",
                            "      <td>0.21</td>\n",
                            "      <td>6</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>Skylit Midtown Castle</td>\n",
                            "      <td>45</td>\n",
                            "      <td>225</td>\n",
                            "      <td>0.38</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
                            "      <td>0</td>\n",
                            "      <td>150</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>Cozy Entire Floor of Brownstone</td>\n",
                            "      <td>270</td>\n",
                            "      <td>89</td>\n",
                            "      <td>4.64</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
                            "      <td>9</td>\n",
                            "      <td>80</td>\n",
                            "      <td>0.10</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48890</th>\n",
                            "      <td>Charming one bedroom - newly renovated rowhouse</td>\n",
                            "      <td>0</td>\n",
                            "      <td>70</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48891</th>\n",
                            "      <td>Affordable room in Bushwick/East Williamsburg</td>\n",
                            "      <td>0</td>\n",
                            "      <td>40</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48892</th>\n",
                            "      <td>Sunny Studio at Historical Neighborhood</td>\n",
                            "      <td>0</td>\n",
                            "      <td>115</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48893</th>\n",
                            "      <td>43rd St. Time Square-cozy single bed</td>\n",
                            "      <td>0</td>\n",
                            "      <td>55</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>6</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48894</th>\n",
                            "      <td>Trendy duplex in the very heart of Hell's Kitchen</td>\n",
                            "      <td>0</td>\n",
                            "      <td>90</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>48895 rows × 5 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                    name  number_of_reviews  \\\n",
                            "0                     Clean & quiet apt home by the park                  9   \n",
                            "1                                  Skylit Midtown Castle                 45   \n",
                            "2                    THE VILLAGE OF HARLEM....NEW YORK !                  0   \n",
                            "3                        Cozy Entire Floor of Brownstone                270   \n",
                            "4       Entire Apt: Spacious Studio/Loft by central park                  9   \n",
                            "...                                                  ...                ...   \n",
                            "48890    Charming one bedroom - newly renovated rowhouse                  0   \n",
                            "48891      Affordable room in Bushwick/East Williamsburg                  0   \n",
                            "48892            Sunny Studio at Historical Neighborhood                  0   \n",
                            "48893               43rd St. Time Square-cozy single bed                  0   \n",
                            "48894  Trendy duplex in the very heart of Hell's Kitchen                  0   \n",
                            "\n",
                            "       price  reviews_per_month  calculated_host_listings_count  \n",
                            "0        149               0.21                               6  \n",
                            "1        225               0.38                               2  \n",
                            "2        150                NaN                               1  \n",
                            "3         89               4.64                               1  \n",
                            "4         80               0.10                               1  \n",
                            "...      ...                ...                             ...  \n",
                            "48890     70                NaN                               2  \n",
                            "48891     40                NaN                               2  \n",
                            "48892    115                NaN                               1  \n",
                            "48893     55                NaN                               6  \n",
                            "48894     90                NaN                               1  \n",
                            "\n",
                            "[48895 rows x 5 columns]"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "\n",
                "data[['name', 'number_of_reviews', 'price', 'reviews_per_month', 'calculated_host_listings_count']]\n",
                "\n",
                "# Estudiando las columnas en conjunto podemos concluir que la columna 'name', no tendra practicamente interés para el modelo,\n",
                "# ya que no oferce informacion relevante y a simplpe vista no parece tener correlacion entre el precio y el numero de visitas.\n",
                "# Además, sabiendo el mercado del que se trata, es decir inmuebles turísticos de Airbnb, podemos concluír que a la hora de hacer una búsqueda\n",
                "#  * de alojamiento, el precio y la situación son las principales variables, y que el nombre apenas tiene interés ni llamada al 'click',\n",
                "#  * y que en todo caso seria da descripcion detallada y sobre todo las fotografía lo que podría inclinar la balanza de la demanda.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>number_of_reviews</th>\n",
                            "      <th>reviews_per_month</th>\n",
                            "      <th>price</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>number_of_reviews</th>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.55</td>\n",
                            "      <td>-0.05</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>reviews_per_month</th>\n",
                            "      <td>0.55</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>-0.03</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>price</th>\n",
                            "      <td>-0.05</td>\n",
                            "      <td>-0.03</td>\n",
                            "      <td>1.00</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                   number_of_reviews  reviews_per_month  price\n",
                            "number_of_reviews               1.00               0.55  -0.05\n",
                            "reviews_per_month               0.55               1.00  -0.03\n",
                            "price                          -0.05              -0.03   1.00"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data[['number_of_reviews', 'reviews_per_month', 'price']].corr()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "number_of_reviews    0.00\n",
                            "reviews_per_month   20.56\n",
                            "last_review         20.56\n",
                            "dtype: float64"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data[['number_of_reviews','reviews_per_month', 'last_review']].isnull().mean()*100\n",
                "\n",
                "# La correlación entre 'number_of_reviews' y 'reviews_per_month' es positiva moderada (0.5499).\n",
                "# Puesto un mayor número total de reseñas también tengan una tasa de reseñas mensuales más alta, tienen una tasa del 20%, que es un nº considerable,\n",
                "# y la información que ofrece no es relevante, ya que no tiene apenas correlación con el precio (variable clave), eliminaremos tambien estas columnas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "id                                48895\n",
                            "name                              47905\n",
                            "host_id                           37457\n",
                            "host_name                         11452\n",
                            "neighbourhood_group                   5\n",
                            "neighbourhood                       221\n",
                            "latitude                          19048\n",
                            "longitude                         14718\n",
                            "room_type                             3\n",
                            "price                               674\n",
                            "minimum_nights                      109\n",
                            "number_of_reviews                   394\n",
                            "last_review                        1764\n",
                            "reviews_per_month                   937\n",
                            "calculated_host_listings_count       47\n",
                            "availability_365                    366\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data.nunique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>neighbourhood_group</th>\n",
                            "      <th>neighbourhood</th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>room_type</th>\n",
                            "      <th>price</th>\n",
                            "      <th>minimum_nights</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Brooklyn</td>\n",
                            "      <td>Kensington</td>\n",
                            "      <td>40.65</td>\n",
                            "      <td>-73.97</td>\n",
                            "      <td>Private room</td>\n",
                            "      <td>149</td>\n",
                            "      <td>1</td>\n",
                            "      <td>6</td>\n",
                            "      <td>365</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>Manhattan</td>\n",
                            "      <td>Midtown</td>\n",
                            "      <td>40.75</td>\n",
                            "      <td>-73.98</td>\n",
                            "      <td>Entire home/apt</td>\n",
                            "      <td>225</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>355</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>Manhattan</td>\n",
                            "      <td>Harlem</td>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>Private room</td>\n",
                            "      <td>150</td>\n",
                            "      <td>3</td>\n",
                            "      <td>1</td>\n",
                            "      <td>365</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>Brooklyn</td>\n",
                            "      <td>Clinton Hill</td>\n",
                            "      <td>40.69</td>\n",
                            "      <td>-73.96</td>\n",
                            "      <td>Entire home/apt</td>\n",
                            "      <td>89</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>194</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>Manhattan</td>\n",
                            "      <td>East Harlem</td>\n",
                            "      <td>40.80</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>Entire home/apt</td>\n",
                            "      <td>80</td>\n",
                            "      <td>10</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "  neighbourhood_group neighbourhood  latitude  longitude        room_type  \\\n",
                            "0            Brooklyn    Kensington     40.65     -73.97     Private room   \n",
                            "1           Manhattan       Midtown     40.75     -73.98  Entire home/apt   \n",
                            "2           Manhattan        Harlem     40.81     -73.94     Private room   \n",
                            "3            Brooklyn  Clinton Hill     40.69     -73.96  Entire home/apt   \n",
                            "4           Manhattan   East Harlem     40.80     -73.94  Entire home/apt   \n",
                            "\n",
                            "   price  minimum_nights  calculated_host_listings_count  availability_365  \n",
                            "0    149               1                               6               365  \n",
                            "1    225               1                               2               355  \n",
                            "2    150               3                               1               365  \n",
                            "3     89               1                               1               194  \n",
                            "4     80              10                               1                 0  "
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data.drop(['id', 'name', 'host_id', 'host_name', 'number_of_reviews','last_review', 'reviews_per_month'], axis=1, inplace=True)\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0\n",
                        "False\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>count</th>\n",
                            "      <th>mean</th>\n",
                            "      <th>std</th>\n",
                            "      <th>min</th>\n",
                            "      <th>25%</th>\n",
                            "      <th>50%</th>\n",
                            "      <th>75%</th>\n",
                            "      <th>max</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>latitude</th>\n",
                            "      <td>48895.00</td>\n",
                            "      <td>40.73</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>40.50</td>\n",
                            "      <td>40.69</td>\n",
                            "      <td>40.72</td>\n",
                            "      <td>40.76</td>\n",
                            "      <td>40.91</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>longitude</th>\n",
                            "      <td>48895.00</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>-74.24</td>\n",
                            "      <td>-73.98</td>\n",
                            "      <td>-73.96</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>-73.71</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>price</th>\n",
                            "      <td>48895.00</td>\n",
                            "      <td>152.72</td>\n",
                            "      <td>240.15</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>69.00</td>\n",
                            "      <td>106.00</td>\n",
                            "      <td>175.00</td>\n",
                            "      <td>10000.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>minimum_nights</th>\n",
                            "      <td>48895.00</td>\n",
                            "      <td>7.03</td>\n",
                            "      <td>20.51</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>3.00</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>1250.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <td>48895.00</td>\n",
                            "      <td>7.14</td>\n",
                            "      <td>32.95</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>327.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>availability_365</th>\n",
                            "      <td>48895.00</td>\n",
                            "      <td>112.78</td>\n",
                            "      <td>131.62</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>45.00</td>\n",
                            "      <td>227.00</td>\n",
                            "      <td>365.00</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                  count   mean    std    min    25%    50%  \\\n",
                            "latitude                       48895.00  40.73   0.05  40.50  40.69  40.72   \n",
                            "longitude                      48895.00 -73.95   0.05 -74.24 -73.98 -73.96   \n",
                            "price                          48895.00 152.72 240.15   0.00  69.00 106.00   \n",
                            "minimum_nights                 48895.00   7.03  20.51   1.00   1.00   3.00   \n",
                            "calculated_host_listings_count 48895.00   7.14  32.95   1.00   1.00   1.00   \n",
                            "availability_365               48895.00 112.78 131.62   0.00   0.00  45.00   \n",
                            "\n",
                            "                                  75%      max  \n",
                            "latitude                        40.76    40.91  \n",
                            "longitude                      -73.94   -73.71  \n",
                            "price                          175.00 10000.00  \n",
                            "minimum_nights                   5.00  1250.00  \n",
                            "calculated_host_listings_count   2.00   327.00  \n",
                            "availability_365               227.00   365.00  "
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Buscamos duplicados\n",
                "print(data.duplicated().sum())\n",
                "\n",
                "# Buscamos valores nulos en todo el conjunto\n",
                "print(data.isnull().any().any())\n",
                "\n",
                "data.describe().T"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "11\n"
                    ]
                }
            ],
            "source": [
                "data[data['price'] == 0]\n",
                "print((data['price'] == 0).sum())\n",
                "data.drop(data[data['price'] == 0].index, axis=0, inplace=True)\n",
                "\n",
                "# Observamos que hay 11 inmuebles a precio 0. Esto debe ser un error y es proporcionalmente nimio, limpiamos estas filas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "239\n",
                        "0.488912527616398%\n"
                    ]
                }
            ],
            "source": [
                "print((data['price'] > 1000).sum())\n",
                "print(f\"{((data['price'] > 1000).sum()) / len(data['price']) * 100}%\")\n",
                "data.drop(data[data['price'] > 1000].index, axis=0, inplace=True)\n",
                "\n",
                "# Hacemos lo mismo con los inmuebles que valen más de 1000$, que suponen tan solo el 0,5 del conjunto,\n",
                "# y sería mas efectivo observaros en un modelo 'de lujo'."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Es posible que al filtrar y eliminar algunas filas del DataFrame original usando el método dropna() con inplace=True, el índice del DataFrame no se haya ajustado correctamente,\n",
                "# lo que puede llevar a que el DataFrame resultante tenga índices adicionales que no corresponden a las filas eliminadas.\n",
                "\n",
                "data.reset_index(drop=True, inplace=True)  # Restablece el índice del DataFrame después de eliminar filas no deseadas\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9kAAAKyCAYAAADB8B3HAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAADUgUlEQVR4nOzde3hM1/4/8PdMkplcJ5GQW3MRgiQk4m5K1SUMzVHafJ2jlKjg0ERFWtQ56tpWq66H4PQm2lKqrZ5WFBF1DyUV4paicaJHJqmEjBC5rt8ffrObyT1MTMj79Tz7YfZas/Zn7ZnMns+svdeWCSEEiIiIiIiIiOihyU0dABEREREREdGTgkk2ERERERERkZEwySYiIiIiIiIyEibZREREREREREbCJJuIiIiIiIjISJhkExERERERERkJk2wiIiIiIiIiI2GSTURERERERGQk5qYOwJTKyspw/fp12NnZQSaTmTocIiJ6TAghcPv2bbi7u0Muf7J/r+axkoiIHkRTOlZW1KST7OvXr8PT09PUYRAR0WPq2rVr8PDwMHUYDYrHSiIiehhN4VhZUZNOsu3s7ADcf+FVKpWJoyEioseFTqeDp6endBx5kvFYSURED6IpHSsratJJtv60N5VKxS8ORERUb03h9GkeK4mI6GE0hWNlRU3r5HgiIqJG6L333oNMJkN0dLS07t69e4iMjISTkxNsbW0RFhaGrKwsg+dlZGQgNDQU1tbWcHZ2xowZM1BSUmJQZ//+/ejcuTOUSiV8fX0RFxf3CHpERETUdDHJJiIiMqETJ07g3//+N4KCggzWT58+HT/88AO2bduGAwcO4Pr163jxxRel8tLSUoSGhqKoqAhHjx7Fxo0bERcXh7lz50p10tPTERoain79+iElJQXR0dGYMGECdu/e/cj6R0RE1NQwySYiIjKR/Px8jB49Gh999BGaNWsmrc/Ly8Mnn3yC5cuXo3///ujSpQs2bNiAo0eP4tixYwCAPXv24Pz58/jiiy8QHByMIUOGYNGiRYiNjUVRUREAYP369fDx8cGyZcvg7++PqKgo/N///R9WrFhhkv4SERE1BUyyiYiITCQyMhKhoaEICQkxWJ+cnIzi4mKD9X5+fvDy8kJSUhIAICkpCYGBgXBxcZHqaDQa6HQ6nDt3TqpTsW2NRiO1UZXCwkLodDqDhYiIiOquSU98RkREZCpbtmzBL7/8ghMnTlQq02q1UCgUcHBwMFjv4uICrVYr1SmfYOvL9WU11dHpdCgoKICVlVWlbS9evBgLFix44H4RERE1dRzJJiIiesSuXbuGadOmYdOmTbC0tDR1OAZmz56NvLw8abl27ZqpQyIiInqsMMkmIiJ6xJKTk5GdnY3OnTvD3Nwc5ubmOHDgAP71r3/B3NwcLi4uKCoqwq1btwyel5WVBVdXVwCAq6trpdnG9Y9rq6NSqaocxQYApVIp3a6Lt+0iIiKqPybZREREj9iAAQOQmpqKlJQUaenatStGjx4t/d/CwgKJiYnSc9LS0pCRkQG1Wg0AUKvVSE1NRXZ2tlQnISEBKpUKAQEBUp3ybejr6NsgIiIi4+M12URERI+YnZ0dOnToYLDOxsYGTk5O0vqIiAjExMTA0dERKpUKU6dOhVqtRs+ePQEAgwYNQkBAAMaMGYMlS5ZAq9Vizpw5iIyMhFKpBABMnjwZa9aswcyZMzF+/Hjs27cPX331FeLj4x9th4mIiJoQJtlERESN0IoVKyCXyxEWFobCwkJoNBqsXbtWKjczM8OOHTswZcoUqNVq2NjYIDw8HAsXLpTq+Pj4ID4+HtOnT8eqVavg4eGBjz/+GBqNxhRdIiIiahJkQghh6iBMRafTwd7eHnl5ebzmrIFlZGTgxo0bpg6jUWvevDm8vLxMHQYR1UFTOn401r4KIZCbmwsAcHR0hEwmM3FERERUXmM9fjwKHMmmBpeRkQE/P38UFNw1dSiNmpWVNS5evMBEm4ioDnJzczF27f3rzT97dQCcnJxMHBEREdF9TLKpwd24cQMFBXfRY/w8qNxamjqcRkmXeRXHP12AGzduMMkmIqojhU3TGhkhIqLHA5NsemRUbi3h6NXO1GEQERERERE1GN7Ci4iIiIiIiMhImGQTERERERERGQmTbCIiIiIiIiIjYZJNREREREREZCRMsomIiIiIiIiMhEk2ERERERERkZEwySYiIiIiIiIyEibZREREREREREbCJJuIiIiIiIjISJhkExERERERERmJuakDICIiItITQiA3NxcA4OjoCJlMZuKIiIiI6qdeI9mLFy9Gt27dYGdnB2dnZwwfPhxpaWkGde7du4fIyEg4OTnB1tYWYWFhyMrKMqiTkZGB0NBQWFtbw9nZGTNmzEBJSYlBnf3796Nz585QKpXw9fVFXFxcpXhiY2PRsmVLWFpaokePHvj555/r0x0iIiJqZHJzczF2bSLGrk2Ukm0iIqLHSb2S7AMHDiAyMhLHjh1DQkICiouLMWjQINy5c0eqM336dPzwww/Ytm0bDhw4gOvXr+PFF1+UyktLSxEaGoqioiIcPXoUGzduRFxcHObOnSvVSU9PR2hoKPr164eUlBRER0djwoQJ2L17t1Rn69atiImJwbx58/DLL7+gY8eO0Gg0yM7Ofpj9QURERCamsFFBYaMydRhEREQPpF6ni+/atcvgcVxcHJydnZGcnIw+ffogLy8Pn3zyCTZv3oz+/fsDADZs2AB/f38cO3YMPXv2xJ49e3D+/Hns3bsXLi4uCA4OxqJFizBr1izMnz8fCoUC69evh4+PD5YtWwYA8Pf3x+HDh7FixQpoNBoAwPLlyzFx4kS88sorAID169cjPj4en376Kd58882H3jFERERERERE9fVQ12Tn5eUBuH/NFAAkJyejuLgYISEhUh0/Pz94eXkhKSkJPXv2RFJSEgIDA+Hi4iLV0Wg0mDJlCs6dO4dOnTohKSnJoA19nejoaABAUVERkpOTMXv2bKlcLpcjJCQESUlJ1cZbWFiIwsJC6bFOp3vwzleQkZGBGzduGK29J8mFCxdMHQIREREREdEj8cBJdllZGaKjo9GrVy906NABAKDVaqFQKODg4GBQ18XFBVqtVqpTPsHWl+vLaqqj0+lQUFCAmzdvorS0tMo6Fy9erDbmxYsXY8GCBfXvbC0yMjLg5+ePgoK7Rm/7SVJcWGTqEIiIiIiIiBrUAyfZkZGROHv2LA4fPmzMeBrU7NmzERMTIz3W6XTw9PR86HZv3LiBgoK76DF+HlRuLR+6vSdNZmoSzn7/YaXJ7YiIiIiIiJ40D5RkR0VFYceOHTh48CA8PDyk9a6urigqKsKtW7cMRrOzsrLg6uoq1ak4C7h+9vHydSrOSJ6VlQWVSgUrKyuYmZnBzMysyjr6NqqiVCqhVCrr3+E6Urm1hKNXuwZr/3Gly7xq6hCIiIiIiIgeiXrNLi6EQFRUFLZv3459+/bBx8fHoLxLly6wsLBAYmKitC4tLQ0ZGRlQq9UAALVajdTUVINZwBMSEqBSqRAQECDVKd+Gvo6+DYVCgS5duhjUKSsrQ2JiolSHiIiIiIiI6FGr10h2ZGQkNm/ejP/85z+ws7OTrqG2t7eHlZUV7O3tERERgZiYGDg6OkKlUmHq1KlQq9Xo2bMnAGDQoEEICAjAmDFjsGTJEmi1WsyZMweRkZHSKPPkyZOxZs0azJw5E+PHj8e+ffvw1VdfIT4+XoolJiYG4eHh6Nq1K7p3746VK1fizp070mzjRERERERERI9avUay161bh7y8PPTt2xdubm7SsnXrVqnOihUr8Je//AVhYWHo06cPXF1d8e2330rlZmZm2LFjB8zMzKBWq/Hyyy9j7NixWLhwoVTHx8cH8fHxSEhIQMeOHbFs2TJ8/PHH0u27AOBvf/sbli5dirlz5yI4OBgpKSnYtWtXpcnQiIiIGqN169YhKCgIKpUKKpUKarUaP/74o1Tet29fyGQyg2Xy5MkGbWRkZCA0NBTW1tZwdnbGjBkzKs1/sX//fnTu3BlKpRK+vr6Ii4t7FN0jIiJqsuo1ki2EqLWOpaUlYmNjERsbW20db29v7Ny5s8Z2+vbti1OnTtVYJyoqClFRUbXGRERE1Nh4eHjgvffeQ5s2bSCEwMaNGzFs2DCcOnUK7du3BwBMnDjR4Edoa2tr6f+lpaUIDQ2Fq6srjh49iszMTIwdOxYWFhZ49913AQDp6ekIDQ3F5MmTsWnTJiQmJmLChAlwc3Mz+OGaiIiIjOeh7pNNRERED2bo0KEGj9955x2sW7cOx44dk5Jsa2vraif03LNnD86fP4+9e/fCxcUFwcHBWLRoEWbNmoX58+dDoVBg/fr18PHxwbJlywAA/v7+OHz4MFasWMEkm4iIqIHU63RxIiIiMr7S0lJs2bIFd+7cMZjAc9OmTWjevDk6dOiA2bNn4+7du1JZUlISAgMDDS6T0mg00Ol0OHfunFQnJCTEYFsajQZJSUkN3CMiIqKmiyPZREREJpKamgq1Wo179+7B1tYW27dvl+60MWrUKHh7e8Pd3R1nzpzBrFmzkJaWJs1zotVqK81Don+sn5i0ujo6nQ4FBQWwsrKqFFNhYSEKCwulxzqdzngdJiIiagKYZBMREZlIu3btkJKSgry8PHz99dcIDw/HgQMHEBAQgEmTJkn1AgMD4ebmhgEDBuDKlSto3bp1g8W0ePFiLFiwoMHaJyIietLxdHEiIiITUSgU8PX1RZcuXbB48WJ07NgRq1atqrJujx49AACXL18GALi6uiIrK8ugjv6x/jru6uqoVKoqR7EBYPbs2cjLy5OWa9euPXgHiYiImiAm2URERI1EWVmZwana5aWkpAAA3NzcAABqtRqpqanIzs6W6iQkJEClUkmnnKvVaiQmJhq0k5CQYHDdd0VKpVK6rZh+ISIiorrj6eJEREQmMHv2bAwZMgReXl64ffs2Nm/ejP3792P37t24cuUKNm/ejOeeew5OTk44c+YMpk+fjj59+iAoKAgAMGjQIAQEBGDMmDFYsmQJtFot5syZg8jISCiVSgDA5MmTsWbNGsycORPjx4/Hvn378NVXXyE+Pt6UXSciInqiMckmIiIygezsbIwdOxaZmZmwt7dHUFAQdu/ejYEDB+LatWvYu3cvVq5ciTt37sDT0xNhYWGYM2eO9HwzMzPs2LEDU6ZMgVqtho2NDcLDww3uq+3j44P4+HhMnz4dq1atgoeHBz7++GPevouIiKgBMckmIiIygU8++aTaMk9PTxw4cKDWNry9vbFz584a6/Tt2xenTp2qd3xERET0YHhNNhEREREREZGRMMkmIiIiIiIiMhIm2URERERERERGwiSbiIiIiIiIyEiYZBMREREREREZCZNsIiIiIiIiIiNhkk1ERERERERkJEyyiYiIiIiIiIyESTYRERERERGRkTDJJiIiIiIiIjISJtlERERERERERsIkm4iIiIiIiMhImGQTERERERERGQmTbCIiIiIiIiIjYZJNREREREREZCRMsomIiIiIiIiMhEk2ERERERERkZEwySYiIiIiIiIyEibZREREREREREbCJJuIiIiIiIjISJhkExERERERERkJk2wiIiIiIiIiI2GSTURERERERGQkTLKJiIiIiIiIjIRJNhERkQmsW7cOQUFBUKlUUKlUUKvV+PHHH6Xye/fuITIyEk5OTrC1tUVYWBiysrIM2sjIyEBoaCisra3h7OyMGTNmoKSkxKDO/v370blzZyiVSvj6+iIuLu5RdI+IiKjJYpJNRERkAh4eHnjvvfeQnJyMkydPon///hg2bBjOnTsHAJg+fTp++OEHbNu2DQcOHMD169fx4osvSs8vLS1FaGgoioqKcPToUWzcuBFxcXGYO3euVCc9PR2hoaHo168fUlJSEB0djQkTJmD37t2PvL9ERERNhbmpAyAiImqKhg4davD4nXfewbp163Ds2DF4eHjgk08+webNm9G/f38AwIYNG+Dv749jx46hZ8+e2LNnD86fP4+9e/fCxcUFwcHBWLRoEWbNmoX58+dDoVBg/fr18PHxwbJlywAA/v7+OHz4MFasWAGNRvPI+0xERNQUcCSbiIjIxEpLS7FlyxbcuXMHarUaycnJKC4uRkhIiFTHz88PXl5eSEpKAgAkJSUhMDAQLi4uUh2NRgOdTieNhiclJRm0oa+jb4OIiIiMjyPZREREJpKamgq1Wo179+7B1tYW27dvR0BAAFJSUqBQKODg4GBQ38XFBVqtFgCg1WoNEmx9ub6spjo6nQ4FBQWwsrKqFFNhYSEKCwulxzqd7qH7SURE1JRwJJuIiMhE2rVrh5SUFBw/fhxTpkxBeHg4zp8/b9KYFi9eDHt7e2nx9PQ0aTxERESPGybZREREJqJQKODr64suXbpg8eLF6NixI1atWgVXV1cUFRXh1q1bBvWzsrLg6uoKAHB1da0027j+cW11VCpVlaPYADB79mzk5eVJy7Vr14zRVSIioiaDSTYREVEjUVZWhsLCQnTp0gUWFhZITEyUytLS0pCRkQG1Wg0AUKvVSE1NRXZ2tlQnISEBKpUKAQEBUp3ybejr6NuoilKplG4rpl+IiIio7nhNNhERkQnMnj0bQ4YMgZeXF27fvo3Nmzdj//792L17N+zt7REREYGYmBg4OjpCpVJh6tSpUKvV6NmzJwBg0KBBCAgIwJgxY7BkyRJotVrMmTMHkZGRUCqVAIDJkydjzZo1mDlzJsaPH499+/bhq6++Qnx8vCm7TkRE9ERjkk1ERGQC2dnZGDt2LDIzM2Fvb4+goCDs3r0bAwcOBACsWLECcrkcYWFhKCwshEajwdq1a6Xnm5mZYceOHZgyZQrUajVsbGwQHh6OhQsXSnV8fHwQHx+P6dOnY9WqVfDw8MDHH3/M23cRERE1ICbZREREJvDJJ5/UWG5paYnY2FjExsZWW8fb2xs7d+6ssZ2+ffvi1KlTDxQjERER1R+vySYiIiIiIiIyEibZREREREREREbCJJuIiIiIiIjISJhkExERERERERkJk2wiIiIiIiIiI2GSTURERERERGQkTLKJiIiIiIiIjIRJNhEREREREZGR1DvJPnjwIIYOHQp3d3fIZDJ89913BuXjxo2DTCYzWAYPHmxQJzc3F6NHj4ZKpYKDgwMiIiKQn59vUOfMmTN45plnYGlpCU9PTyxZsqRSLNu2bYOfnx8sLS0RGBiInTt31rc7REREREREREZT7yT7zp076NixI2JjY6utM3jwYGRmZkrLl19+aVA+evRonDt3DgkJCdixYwcOHjyISZMmSeU6nQ6DBg2Ct7c3kpOT8cEHH2D+/Pn48MMPpTpHjx7FSy+9hIiICJw6dQrDhw/H8OHDcfbs2fp2iYiIiIiIiMgozOv7hCFDhmDIkCE11lEqlXB1da2y7MKFC9i1axdOnDiBrl27AgBWr16N5557DkuXLoW7uzs2bdqEoqIifPrpp1AoFGjfvj1SUlKwfPlyKRlftWoVBg8ejBkzZgAAFi1ahISEBKxZswbr16+vb7eIiIiIiIiIHlqDXJO9f/9+ODs7o127dpgyZQpycnKksqSkJDg4OEgJNgCEhIRALpfj+PHjUp0+ffpAoVBIdTQaDdLS0nDz5k2pTkhIiMF2NRoNkpKSqo2rsLAQOp3OYCEiIiIiIiIyFqMn2YMHD8Znn32GxMREvP/++zhw4ACGDBmC0tJSAIBWq4Wzs7PBc8zNzeHo6AitVivVcXFxMaijf1xbHX15VRYvXgx7e3tp8fT0fLjOEhEREREREZVT79PFazNy5Ejp/4GBgQgKCkLr1q2xf/9+DBgwwNibq5fZs2cjJiZGeqzT6ZhoExERERERkdE0+C28WrVqhebNm+Py5csAAFdXV2RnZxvUKSkpQW5urnQdt6urK7Kysgzq6B/XVqe6a8GB+9eKq1Qqg4WIiIiIiIjIWBo8yf7999+Rk5MDNzc3AIBarcatW7eQnJws1dm3bx/KysrQo0cPqc7BgwdRXFws1UlISEC7du3QrFkzqU5iYqLBthISEqBWqxu6S0RERERERERVqneSnZ+fj5SUFKSkpAAA0tPTkZKSgoyMDOTn52PGjBk4duwYrl69isTERAwbNgy+vr7QaDQAAH9/fwwePBgTJ07Ezz//jCNHjiAqKgojR46Eu7s7AGDUqFFQKBSIiIjAuXPnsHXrVqxatcrgVO9p06Zh165dWLZsGS5evIj58+fj5MmTiIqKMsJuISIiIiIiIqq/eifZJ0+eRKdOndCpUycAQExMDDp16oS5c+fCzMwMZ86cwfPPP4+2bdsiIiICXbp0waFDh6BUKqU2Nm3aBD8/PwwYMADPPfccevfubXAPbHt7e+zZswfp6eno0qULXn/9dcydO9fgXtpPP/00Nm/ejA8//BAdO3bE119/je+++w4dOnR4mP1BREREj4AQAjk5OcjJyYEQwtThEBERGU29Jz7r27dvjQfD3bt319qGo6MjNm/eXGOdoKAgHDp0qMY6I0aMwIgRI2rdHhERETUuubm5GLv2/mVfn706AE5OTiaOiIiIyDiMPrs4ERERUV0obDgBKRERPXkafOIzIiIiIiIioqaCSTYRERERERGRkTDJJiIiIiIiIjISJtlERERERERERsIkm4iIyAQWL16Mbt26wc7ODs7Ozhg+fDjS0tIM6vTt2xcymcxgmTx5skGdjIwMhIaGwtraGs7OzpgxYwZKSkoM6uzfvx+dO3eGUqmEr68v4uLiGrp7RERETRaTbCIiIhM4cOAAIiMjcezYMSQkJKC4uBiDBg3CnTt3DOpNnDgRmZmZ0rJkyRKprLS0FKGhoSgqKsLRo0exceNGxMXFYe7cuVKd9PR0hIaGol+/fkhJSUF0dDQmTJhQp1tuEhERUf3xFl5EREQmsGvXLoPHcXFxcHZ2RnJyMvr06SOtt7a2hqura5Vt7NmzB+fPn8fevXvh4uKC4OBgLFq0CLNmzcL8+fOhUCiwfv16+Pj4YNmyZQAAf39/HD58GCtWrIBGo2m4DhIRETVRHMkmIiJqBPLy8gAAjo6OBus3bdqE5s2bo0OHDpg9ezbu3r0rlSUlJSEwMBAuLi7SOo1GA51Oh3Pnzkl1QkJCDNrUaDRISkqqMo7CwkLodDqDhYiIiOqOI9lEREQmVlZWhujoaPTq1QsdOnSQ1o8aNQre3t5wd3fHmTNnMGvWLKSlpeHbb78FAGi1WoMEG4D0WKvV1lhHp9OhoKAAVlZWBmWLFy/GggULjN5HIiKipoJJNhERkYlFRkbi7NmzOHz4sMH6SZMmSf8PDAyEm5sbBgwYgCtXrqB169YNEsvs2bMRExMjPdbpdPD09GyQbRERET2JeLo4ERGRCUVFRWHHjh346aef4OHhUWPdHj16AAAuX74MAHB1dUVWVpZBHf1j/XXc1dVRqVSVRrEBQKlUQqVSGSxPGiEEcnJykJOTAyGEqcMhIqInDJNsIiIiExBCICoqCtu3b8e+ffvg4+NT63NSUlIAAG5ubgAAtVqN1NRUZGdnS3USEhKgUqkQEBAg1UlMTDRoJyEhAWq12kg9efzk5uZi7NpEjF2biNzcXFOHQ0RETxgm2URERCYQGRmJL774Aps3b4adnR20Wi20Wi0KCgoAAFeuXMGiRYuQnJyMq1ev4vvvv8fYsWPRp08fBAUFAQAGDRqEgIAAjBkzBqdPn8bu3bsxZ84cREZGQqlUAgAmT56M3377DTNnzsTFixexdu1afPXVV5g+fbrJ+t4YKGxUUNg8eaP0RERkekyyiYiITGDdunXIy8tD37594ebmJi1bt24FACgUCuzduxeDBg2Cn58fXn/9dYSFheGHH36Q2jAzM8OOHTtgZmYGtVqNl19+GWPHjsXChQulOj4+PoiPj0dCQgI6duyIZcuW4eOPP+btu4iIiBoIJz4jIiIygdquBfb09MSBAwdqbcfb2xs7d+6ssU7fvn1x6tSpesVHRERED4Yj2URERERERERGwiSbiIiIiIiIyEiYZBMREREREREZCZNsIiIiIiIiIiNhkk1ERERERERkJEyyiYiIiIiIiIyESTYRERERERGRkTDJJiIiIiIiIjISJtlERERERERERsIkm4iIiIiIiMhImGQTERERERERGQmTbCIiIiIiIiIjYZJNREREREREZCRMsomIiIiIiIiMhEk2ERERERERkZEwySYiIiIiIiIyEibZREREREREREbCJJuIiIiIiIjISJhkExERERERERkJk2wiIiIiIiIiI2GSTURERERERGQkTLKJiIiIiIiIjIRJNhEREREREZGRMMkmIiIygcWLF6Nbt26ws7ODs7Mzhg8fjrS0NIM69+7dQ2RkJJycnGBra4uwsDBkZWUZ1MnIyEBoaCisra3h7OyMGTNmoKSkxKDO/v370blzZyiVSvj6+iIuLq6hu0dERNRkMckmIiIygQMHDiAyMhLHjh1DQkICiouLMWjQINy5c0eqM336dPzwww/Ytm0bDhw4gOvXr+PFF1+UyktLSxEaGoqioiIcPXoUGzduRFxcHObOnSvVSU9PR2hoKPr164eUlBRER0djwoQJ2L179yPtLxERUVNhbuoAiIiImqJdu3YZPI6Li4OzszOSk5PRp08f5OXl4ZNPPsHmzZvRv39/AMCGDRvg7++PY8eOoWfPntizZw/Onz+PvXv3wsXFBcHBwVi0aBFmzZqF+fPnQ6FQYP369fDx8cGyZcsAAP7+/jh8+DBWrFgBjUbzyPtNRET0pONINhERUSOQl5cHAHB0dAQAJCcno7i4GCEhIVIdPz8/eHl5ISkpCQCQlJSEwMBAuLi4SHU0Gg10Oh3OnTsn1Snfhr6Ovg0iIiIyLo5kExERmVhZWRmio6PRq1cvdOjQAQCg1WqhUCjg4OBgUNfFxQVarVaqUz7B1pfry2qqo9PpUFBQACsrK4OywsJCFBYWSo91Ot3Dd5CIiKgJ4Ug2ERGRiUVGRuLs2bPYsmWLqUPB4sWLYW9vLy2enp6mDomIiOixwiSbiIjIhKKiorBjxw789NNP8PDwkNa7urqiqKgIt27dMqiflZUFV1dXqU7F2cb1j2uro1KpKo1iA8Ds2bORl5cnLdeuXXvoPhIRETUlTLKJiIhMQAiBqKgobN++Hfv27YOPj49BeZcuXWBhYYHExERpXVpaGjIyMqBWqwEAarUaqampyM7OluokJCRApVIhICBAqlO+DX0dfRsVKZVKqFQqg8UUhBDIzc3FjRs3cOPGDQghTBIHERFRffGabCIiIhOIjIzE5s2b8Z///Ad2dnbSNdT29vawsrKCvb09IiIiEBMTA0dHR6hUKkydOhVqtRo9e/YEAAwaNAgBAQEYM2YMlixZAq1Wizlz5iAyMhJKpRIAMHnyZKxZswYzZ87E+PHjsW/fPnz11VeIj483Wd/rovjubUR9cQJlRQUoKSnB12/+H5ycnEwdFhERUa2YZBMREZnAunXrAAB9+/Y1WL9hwwaMGzcOALBixQrI5XKEhYWhsLAQGo0Ga9euleqamZlhx44dmDJlCtRqNWxsbBAeHo6FCxdKdXx8fBAfH4/p06dj1apV8PDwwMcff/xY3L7LwloFYW4OWXGJqUMhIiKqMybZREREJlCX058tLS0RGxuL2NjYaut4e3tj586dNbbTt29fnDp1qt4xEhERUf3xmmwiIiIiIiIiI2GSTURERERERGQk9U6yDx48iKFDh8Ld3R0ymQzfffedQbkQAnPnzoWbmxusrKwQEhKCS5cuGdTJzc3F6NGjoVKp4ODggIiICOTn5xvUOXPmDJ555hlYWlrC09MTS5YsqRTLtm3b4OfnB0tLSwQGBtZ6uhwRERERERFRQ6p3kn3nzh107Nix2uvDlixZgn/9619Yv349jh8/DhsbG2g0Gty7d0+qM3r0aJw7dw4JCQnYsWMHDh48iEmTJknlOp0OgwYNgre3N5KTk/HBBx9g/vz5+PDDD6U6R48exUsvvYSIiAicOnUKw4cPx/Dhw3H27Nn6domIiIiIiIjIKOo98dmQIUMwZMiQKsuEEFi5ciXmzJmDYcOGAQA+++wzuLi44LvvvsPIkSNx4cIF7Nq1CydOnEDXrl0BAKtXr8Zzzz2HpUuXwt3dHZs2bUJRURE+/fRTKBQKtG/fHikpKVi+fLmUjK9atQqDBw/GjBkzAACLFi1CQkIC1qxZg/Xr1z/QziAiIqInk/6+246OjqYOhYiInnBGvSY7PT0dWq0WISEh0jp7e3v06NEDSUlJAICkpCQ4ODhICTYAhISEQC6X4/jx41KdPn36QKFQSHU0Gg3S0tJw8+ZNqU757ejr6LdTlcLCQuh0OoOFiIiInny5ubkYuXQ7cnNzTR0KERE94YyaZGu1WgCAi4uLwXoXFxepTKvVwtnZ2aDc3Nwcjo6OBnWqaqP8Nqqroy+vyuLFi2Fvby8tnp6e9e0iERERPaYU1namDoGIiJqAJjW7+OzZs5GXlyct165dM3VIRERERERE9AQxapLt6uoKAMjKyjJYn5WVJZW5uroiOzvboLykpAS5ubkGdapqo/w2qqujL6+KUqmESqUyWIiIiIhqIoRATk4OhBCmDoWIiB4DRk2yfXx84OrqisTERGmdTqfD8ePHoVarAQBqtRq3bt1CcnKyVGffvn0oKytDjx49pDoHDx5EcXGxVCchIQHt2rVDs2bNpDrlt6Ovo98OERERkTHwem4iIqqPeifZ+fn5SElJQUpKCoD7k52lpKQgIyMDMpkM0dHRePvtt/H9998jNTUVY8eOhbu7O4YPHw4A8Pf3x+DBgzFx4kT8/PPPOHLkCKKiojBy5Ei4u7sDAEaNGgWFQoGIiAicO3cOW7duxapVqxATEyPFMW3aNOzatQvLli3DxYsXMX/+fJw8eRJRUVEPv1eIiIiIyuH13EREVFf1voXXyZMn0a9fP+mxPvENDw9HXFwcZs6ciTt37mDSpEm4desWevfujV27dsHS0lJ6zqZNmxAVFYUBAwZALpcjLCwM//rXv6Rye3t77NmzB5GRkejSpQuaN2+OuXPnGtxL++mnn8bmzZsxZ84c/OMf/0CbNm3w3XffoUOHDg+0I4iIiIiIiIgeVr2T7L59+9Z4TZJMJsPChQuxcOHCaus4Ojpi8+bNNW4nKCgIhw4dqrHOiBEjMGLEiJoDJiIiIiIiInpEmtTs4kREREREREQNiUk2ERERERERkZEwySYiIiIiIiIyEibZREREREREREbCJJuIiIiIiIjISJhkExERERERERkJk2wiIiIiIiIiI2GSTURERERERGQkTLKJiIiIiIiIjIRJNhEREREREZGRmJs6ACIiIiJjEEIgNzcXAODo6AiZTGbiiIiIqCniSDYREZEJHDx4EEOHDoW7uztkMhm+++47g/Jx48ZBJpMZLIMHDzaok5ubi9GjR0OlUsHBwQERERHIz883qHPmzBk888wzsLS0hKenJ5YsWdLQXTOZ3NxcjF2biLFrE6Vkm4iI6FFjkk1ERGQCd+7cQceOHREbG1ttncGDByMzM1NavvzyS4Py0aNH49y5c0hISMCOHTtw8OBBTJo0SSrX6XQYNGgQvL29kZycjA8++ADz58/Hhx9+2GD9MjWFjQoKG5WpwyAioiaMp4sTERGZwJAhQzBkyJAa6yiVSri6ulZZduHCBezatQsnTpxA165dAQCrV6/Gc889h6VLl8Ld3R2bNm1CUVERPv30UygUCrRv3x4pKSlYvny5QTL+KOlP6eZIMxERPak4kk1ERNRI7d+/H87OzmjXrh2mTJmCnJwcqSwpKQkODg5Sgg0AISEhkMvlOH78uFSnT58+UCgUUh2NRoO0tDTcvHmzym0WFhZCp9MZLMakP6X71U8Pori4xKhtExERNQZMsomIiBqhwYMH47PPPkNiYiLef/99HDhwAEOGDEFpaSkAQKvVwtnZ2eA55ubmcHR0hFarleq4uLgY1NE/1tepaPHixbC3t5cWT09PY3ft/ind1nZGb5eIiKgx4OniREREjdDIkSOl/wcGBiIoKAitW7fG/v37MWDAgAbb7uzZsxETEyM91ul0DZJoExERPak4kk1ERPQYaNWqFZo3b47Lly8DAFxdXZGdnW1Qp6SkBLm5udJ13K6ursjKyjKoo39c3bXeSqUSKpXKYCEiIqK6Y5JNRET0GPj999+Rk5MDNzc3AIBarcatW7eQnJws1dm3bx/KysrQo0cPqc7BgwdRXFws1UlISEC7du3QrFmzR9sBIiKiJoJJNhERkQnk5+cjJSUFKSkpAID09HSkpKQgIyMD+fn5mDFjBo4dO4arV68iMTERw4YNg6+vLzQaDQDA398fgwcPxsSJE/Hzzz/jyJEjiIqKwsiRI+Hu7g4AGDVqFBQKBSIiInDu3Dls3boVq1atMjgdnIiIiIyLSTYREZEJnDx5Ep06dUKnTp0AADExMejUqRPmzp0LMzMznDlzBs8//zzatm2LiIgIdOnSBYcOHYJSqZTa2LRpE/z8/DBgwAA899xz6N27t8E9sO3t7bFnzx6kp6ejS5cueP311zF37lyT3b6LiIioKeDEZ0RERCbQt29fCCGqLd+9e3etbTg6OmLz5s011gkKCsKhQ4fqHR8RERE9GI5kExERERERERkJk2wiIiIiIiIiI2GSTURERERERGQkTLKJiIiIiIiIjIRJNhEREREREZGRMMkmIiIiIiIiMhIm2URERERERERGwiSbiIiIiIiIyEiYZBMREREREREZCZNsIiIiIiIiIiNhkk1ERERERERkJEyyiYiIiIiIiIyESTYRERERERGRkTDJJiIiIiIiIjISJtlERERERERERsIkm4iIiIiIiMhImGQTERERERERGQmTbCIiIiIiIiIjYZJNREREREREZCTmpg6AiIiImjYhBHJycqT/N+R2cnNzG6x9IiIigEk2ERERmdjNmzcRveUUAGDlyE4P1EZdEujignxEfXECZUUFUDq4wMKCX4OIiMj4eLo4ERERmZzCRgWFjeqBn5+bm4sJsfEoLi6psZ6FtQoKa7sH3g4REVFtmGQTERHRE0FhZWvqEIiIiJhkExERmcLBgwcxdOhQuLu7QyaT4bvvvjMoF0Jg7ty5cHNzg5WVFUJCQnDp0iWDOrm5uRg9ejRUKhUcHBwQERGB/Px8gzpnzpzBM888A0tLS3h6emLJkiUN3TUiIqImjUk2ERGRCdy5cwcdO3ZEbGxsleVLlizBv/71L6xfvx7Hjx+HjY0NNBoN7t27J9UZPXo0zp07h4SEBOzYsQMHDx7EpEmTpHKdTodBgwbB29sbycnJ+OCDDzB//nx8+OGHDd4/IiKipoozfhA1IhcuXDB1CI1a8+bN4eXlZeowiIxiyJAhGDJkSJVlQgisXLkSc+bMwbBhwwAAn332GVxcXPDdd99h5MiRuHDhAnbt2oUTJ06ga9euAIDVq1fjueeew9KlS+Hu7o5NmzahqKgIn376KRQKBdq3b4+UlBQsX77cIBknIiIi42GSTdQIFOTlAJDh5ZdfNnUojZqVlTUuXrzARJueeOnp6dBqtQgJCZHW2dvbo0ePHkhKSsLIkSORlJQEBwcHKcEGgJCQEMjlchw/fhwvvPACkpKS0KdPHygUCqmORqPB+++/j5s3b6JZs2aPtF9ERERNAZNsokag+O5tAALBo2ahhY+fqcNplHSZV3H80wW4ceMGk2x64mm1WgCAi4uLwXoXFxepTKvVwtnZ2aDc3Nwcjo6OBnV8fHwqtaEvqyrJLiwsRGFhofRYp9M9ZG+IiIiaFibZRI2IrbMXHL3amToMImrCFi9ejAULFpg6DCIioscWJz4jIiJqZFxdXQEAWVlZBuuzsrKkMldXV2RnZxuUl5SUIDc316BOVW2U30ZFs2fPRl5enrRcu3bt4TtERETUhBg9yZ4/fz5kMpnB4uf35+mv9+7dQ2RkJJycnGBra4uwsLBKXwAyMjIQGhoKa2trODs7Y8aMGSgpKTGos3//fnTu3BlKpRK+vr6Ii4szdleIiIhMwsfHB66urkhMTJTW6XQ6HD9+HGq1GgCgVqtx69YtJCcnS3X27duHsrIy9OjRQ6pz8OBBFBcXS3USEhLQrl27aq/HViqVUKlUBgsRERHVXYOMZLdv3x6ZmZnScvjwYals+vTp+OGHH7Bt2zYcOHAA169fx4svviiVl5aWIjQ0FEVFRTh69Cg2btyIuLg4zJ07V6qTnp6O0NBQ9OvXDykpKYiOjsaECROwe/fuhugOERGR0eXn5yMlJQUpKSkA7h/bUlJSkJGRAZlMhujoaLz99tv4/vvvkZqairFjx8Ld3R3Dhw8HAPj7+2Pw4MGYOHEifv75Zxw5cgRRUVEYOXIk3N3dAQCjRo2CQqFAREQEzp07h61bt2LVqlWIiYkxUa+JiIiefA1yTba5uXmVp6Hl5eXhk08+webNm9G/f38AwIYNG+Dv749jx46hZ8+e2LNnD86fP4+9e/fCxcUFwcHBWLRoEWbNmoX58+dDoVBg/fr18PHxwbJlywDc/6Jx+PBhrFixAhqNpiG6REREZFQnT55Ev379pMf6xDc8PBxxcXGYOXMm7ty5g0mTJuHWrVvo3bs3du3aBUtLS+k5mzZtQlRUFAYMGAC5XI6wsDD861//ksrt7e2xZ88eREZGokuXLmjevDnmzp3L23cRERE1oAZJsi9dugR3d3dYWlpCrVZj8eLF8PLyQnJyMoqLiw1uSeLn5wcvLy8kJSWhZ8+eSEpKQmBgoMGMqhqNBlOmTMG5c+fQqVMnJCUlGbShrxMdHV1jXJwxlYiIGou+fftCCFFtuUwmw8KFC7Fw4cJq6zg6OmLz5s01bicoKAiHDh164DifdEII5OTkALi/P2UymYkjIiKix53RTxfv0aMH4uLisGvXLqxbtw7p6el45plncPv2bWi1WigUCjg4OBg8p+ItSaq6ZYm+rKY6Op0OBQUF1ca2ePFi2NvbS4unp+fDdpeIiIgeYzdv3sTYtYkYuzYRubm5tdbXJ+U5OTk1/kjSGOhjbexxEhE9aYyeZA8ZMgQjRoxAUFAQNBoNdu7ciVu3buGrr74y9qbqjTOmEhERUUUKGxUUNnWb4C03N7deSbkp5ebmYuTS7Y0+TiKiJ02D38LLwcEBbdu2xeXLl+Hq6oqioiLcunXLoE7FW5LUdruR6uqoVCpYWVlVGwtnTCUiIqKHVZ+k3NQU1namDoGIqMlp8CQ7Pz8fV65cgZubG7p06QILCwuDW5KkpaUhIyPD4JYkqampBvf+TEhIgEqlQkBAgFSnfBv6Ovo2iIiIiIiIiEzB6En2G2+8gQMHDuDq1as4evQoXnjhBZiZmeGll16Cvb09IiIiEBMTg59++gnJycl45ZVXoFar0bNnTwDAoEGDEBAQgDFjxuD06dPYvXs35syZg8jISCiVSgDA5MmT8dtvv2HmzJm4ePEi1q5di6+++grTp083dneIiIiIiIiI6szos4v//vvveOmll5CTk4MWLVqgd+/eOHbsGFq0aAEAWLFihXSbkcLCQmg0Gqxdu1Z6vpmZGXbs2IEpU6ZArVbDxsYG4eHhBrOr+vj4ID4+HtOnT8eqVavg4eGBjz/+mLfvIiIiIiIiIpMyepK9ZcuWGsstLS0RGxuL2NjYaut4e3tj586dNbbTt29fnDp16oFiJCIiIiIiImoIDX5NNhEREREREVFTwSSbiIiIiIiIyEiYZBMREREREREZCZNsIiIieqwIIZCbm2vqMIiIiKrEJJuIiIgeK7m5uZgQG4/i4hJTh2IUQgjk5OQgJycHQghTh0NERA+JSTYRERE9dhRWtqYOwWhyc3Mxdm0ixq5N5Ag9EdETwOi38CIiIiKi+lHYqEwdAhERGQlHsomIiIiIiIiMhEk2ERERERERkZEwySYiIiIiIiIyEibZREREREREREbCJJuIiIiIiIjISJhkExERUZMkhMDNmzdNHQYRET1hmGQTERFRk1R89zZiPjuE4uISU4dCRERPECbZRERE1GSZW9qaOgQiInrCMMkmIiIiIiIiMhIm2URERGQyvC6aiIieNEyyiYiIGqn58+dDJpMZLH5+flL5vXv3EBkZCScnJ9ja2iIsLAxZWVkGbWRkZCA0NBTW1tZwdnbGjBkzUFLSeK5B5nXRRET0pDE3dQBERERUvfbt22Pv3r3SY3PzPw/d06dPR3x8PLZt2wZ7e3tERUXhxRdfxJEjRwAApaWlCA0NhaurK44ePYrMzEyMHTsWFhYWePfddx95X6rTGK6LFkIgNzcXQggAgJOTE2QymYmjIiKixxGTbCIiokbM3Nwcrq6uldbn5eXhk08+webNm9G/f38AwIYNG+Dv749jx46hZ8+e2LNnD86fP4+9e/fCxcUFwcHBWLRoEWbNmoX58+dDoVA86u40WsV3byPqixMoKypASUkJvn7z/+Dk5GTqsIiI6DHE08WJiIgasUuXLsHd3R2tWrXC6NGjkZGRAQBITk5GcXExQkJCpLp+fn7w8vJCUlISACApKQmBgYFwcXGR6mg0Guh0Opw7d+7RduQR0o9K5+TkSCPTdWFhrYLC2g4WVnYNGB0RET3pOJJNRETUSPXo0QNxcXFo164dMjMzsWDBAjzzzDM4e/YstFotFAoFHBwcDJ7j4uICrVYLANBqtQYJtr5cX1aVwsJCFBYWSo91Op0Re2R8+oS6PP2otLm5OT57dUCTGZEuvy8cHR1NHA0RUdPFJJuIiKiRGjJkiPT/oKAg9OjRA97e3vjqq69gZWXVINtcvHgxFixY0CBt1+ZBZhovf5p3cXEplP9/vYW1ChYWTetrTm5uLsauTQQAfPbqABNHQ0TUdPF0cSIioseEg4MD2rZti8uXL8PV1RVFRUW4deuWQZ2srCzpGm5XV9dKs43rH1d1nTcAzJ49G3l5edJy7do143ekGg8607j+NG9jedDTzRsDhY0KChuVqcMgImrSmGQTERE9JvLz83HlyhW4ubmhS5cusLCwQGJiolSelpaGjIwMqNVqAIBarUZqaiqys7OlOgkJCVCpVAgICKhyG0qlEiqVymB5lBrDTOPFBfmI+uIExq5NrHQqOhERUW2a1nlUREREj5E33ngDQ4cOhbe3N65fv4558+bBzMwML730Euzt7REREYGYmBg4OjpCpVJh6tSpUKvV6NmzJwBg0KBBCAgIwJgxY7BkyRJotVrMmTMHkZGRUCqVtWy9aWuKp5sTEZFx8OhBRETUSP3+++946aWXkJOTgxYtWqB37944duwYWrRoAQBYsWIF5HI5wsLCUFhYCI1Gg7Vr10rPNzMzw44dOzBlyhSo1WrY2NggPDwcCxcuNFWXmpSKE5HVdt/t+tYnIqLGiUk2ERFRI7Vly5Yayy0tLREbG4vY2Nhq63h7e2Pnzp3GDo3qoOJEZLXNct5UZ0UnInrS8JpsIiIiogZS34nILKyf/InLhBCP5aRyRER1xSSbiIiI6DGlT1gfp6Q1NzcXI5du56RyRPTE4uniRERE1KhVvFb5caXvhzGvty5/SvrKkZ2M0uajYMxbrhERNTYcySYiIqJGzVS31NInxbm5uQb/f1B1HcHVb6uuI9O8NzYRUePCkWwiIiJq9ExxSy39RGRlRQUoLi6R/q90cHngWOoyglt89zYmfbgPX7/p2GgmP+PM50REdceRbCIiIqJqWFirpMS4/P8bfLtWjet0av1p6Y/6bAIioscRR7KJiIiIHgOmHk3mKelERHXDJJuIiIgeC+WTzKaovvfdbmimTvqJiBorJtlERET0WDC8RroUSlMHZAKNaTS5sSX9RESNBZNsIiIiemxYWKsgzM1RnHfT1KEQGlfST0TUWHDiMyIiInpiCSGQk5PzSE4z12+rrrfeaoz0fXjc+0FEZEpMsomIiOiJdfPmTYxdm4hXPz2I4uJSo7Vb/l7W+sT08uXLdboPdn3af9TJ7qOeRZxJPRE9iXi6OBERET3R9Kc0G/MU8/L3sgaAsWsTUXT3NmQW1sZpvyAfUV+cgLm5+SO/3rkup4AbaxI6XtdNRE8iJtlERE+QjIwM3Lhxw9RhNFrNmzeHl5eXqcOgJ0T5e1lLiXxxifHat1bBwqJxflXLzc3FhNh42Ln5PnSMvK6biJ40jfOTm4iI6i0jIwN+fv4oKLhr6lAaLSsra1y8eIGJNpERKKxsjdqe/tRxwHS3BONtyYjIGJhkExE9IW7cuIGCgrvoMX4eVG4tTR1Oo6PLvIrjny7AjRs3mGSbSFO9z3VT7Xd93bx5E9FbTgEw3anjPH2diIyBSTYR0RNG5dYSjl7tTB0GUSXlTzF+FIQQuHnT9Lf6Kn9/b5mFlanDaTD6HxMqjgBXHB2uSWM4dbwxxEBEjzfOLk5ERESPjLFPMa5J8d3biPnskFGvky5PnzzWZZTawloFhbVdrfVMxRi3OsvNza1ydvVHPWN5XXFmcyJqKBzJJiIioieWuWXDJfX6GcDLigqgdHBpsO08CvpEuOjubSgdXB54MrPqfkioz+hwdSPiD1qvOsY6NZzXcRNRRRzJJiIiInpAjWWE2hinxitsGkdf9LdHq23Uu7qR8/pQ2Kge+vTwxjpST0SmwySbiIiIyMge9WRnDX1q/KNW/vZowJ+ndlc8rbsx/CgA1C1Zf5jT03lqO9HjhUk2ERERkZHok+vLly9jQmz8I016G/LUeFMzxqj1o1LdDwL1HfEu305Vz61uO6bCHwKI/sRrsonosXLhwgVTh9Bocd8QmV7567Rl5sabSbz8yHj55Kq+p4iXvxe1TCar0zXEDzMqX9fnVuxLVTOSN9Sodflru2sq18dS2/7S/yCw5Y0XKl3nXZdT08tPqPfqpwew5Y0XqnxuTdsxBd7+jOhPTLKJ6LFQkJcDQIaXX37Z1KE0esWFRaYOgahJs7BWQZibozjPeLcPK3/7M1F0F+P/9QNsnNzqPelabm4uwt7+Apb2zjAzM8OqlzqjWbNmNSbC5bdd1wnRyieKdXnu/dPdz8PB8/7tB/U/Vpibm+OzVwfUuX/lt60fTS3/Y0L5Hxn0Sb3+GvCv36w6yX6Q5LG+PwiUT/TLT0Ins7A26nbqGw8Ag31X20RzD3N9e2OaQK4xxUKPp8c+yY6NjcUHH3wArVaLjh07YvXq1ejevbupwyIiIyu+exuAQPCoWWjh42fqcBqlzNQknP3+Q5SUPBnXZJJx8XjZuFQcma6L8rc/M7e0lZL5mtqurh0LaxVE0V1p1L3g9i0pwa1p23UdmTZIFKsY0a+qnYqnu1tYqwwS87reb7v8tuUKK+nHBF9fX4MfGcr/QGFuaVvzPqtn8vgwo9/lt1fxcoPaRt0fZNvVxVPxh4WGGDmv+HcQvm6fwTZNhaPy9LAe6yR769atiImJwfr169GjRw+sXLkSGo0GaWlpcHZ2NnV4RNQAbJ294OhV/RfBpkyXedXUIVAjxeNl41F+hDd6yykIITB/sE+t9euj+O7tP09Zt6j5lHVp1L2O146Xb7u4uBTKGmKUEsUqRvQf5PZndRnd1sei37ZMYQ1RdBcT/52Ij/7+/+OyqvwDRcV4qhp1r2okt2KSqP9/+Vg3TukPmUxW6+tYl1Hp2kbdhRC4fPkyorecAlB9glgxWS8/8q+vX9UPC/oYjZHIV4x15chODz3Te/m263t7t4pnORgrFmqaHuske/ny5Zg4cSJeeeUVAMD69esRHx+PTz/9FG+++aaJoyMiImoceLxsPColl0V3EfPZoWpHkatKautCn0QWFRUbJFB1vYa7puu+K54OX5+kvqp2aoujfHJqYa2CublZtQlr+dPTDclq3Y8V49HvAylxLpfg6hPRiqfxl9+GrcP9WH/77Tcs2H1Vuge5Pv7yCW51/aluxL8u/ddvRwgBIYRBsnnz5k2D6731I//FxcX46O9//oBR3ftAP9IrhJDOEqgYc8UEvqoYyseqb798n5s1ayatr5gwV1Wv/Ptc37/yPzJUvJTAyclJarOqsxzKv1bVbbt8PyueWl/VJQtV7aea2q5LGU9vb3we2yS7qKgIycnJmD17trROLpcjJCQESUlJVT6nsLAQhYWF0uO8vDwAgE6ne6hY8vPzAQC5/01DSWHBQ7X1JNJl/hcAkPe/S7Aw5x99VbiPasd9VDvuo5rptBkA7n9mP+znvv75j8MMuvU9XjbUsRIAbt++jbu3bqBMAGVF9yBXWKKs6B7u5efBzNys0v+rKn+YdQ3Z9oNsr+ymFmVF91BSdA8F////xu5LQX4exq/+A2XF9yC3sERZ8T2UlpbW+Bro141adAhWzZzr9ZySO7eRkXH/b+1OjhbFBflSvSIzc6msPu+D8avTKsWgXye3sERGRgZu374N4H5yVVJY8/6sy74rMjPHmTNnsGjHORQV3IGlffP7/Sspqff2Xl19CPZPtTJ4zccs+QXrXn0OABDz+WEUFdyR+lJ+35V//fQxVHxNa4pHv58K83XSa6l/H5TfXvG9uygpLMC9/DyMXx1vsL3y74OKzykuyMeYJV9JfdHHXVX/qoqhtLQU5v8/1vL7afzqNJibm+Gtv7THoh3nAADLx/RGs2bNpM+TmzdvIubzwwAg1dPvx6r2TfnnFBXcQWlJKda9+pzUpn7flRTerfK1qm7by8f0BgBE/XsX1vx9sJTwl39dzc3Nqoy//HOqa7suZTU950HVdElCXT1Ox0qjE4+p//3vfwKAOHr0qMH6GTNmiO7du1f5nHnz5gkAXLhw4cKFi1GWa9euPYpD3kOp7/GSx0ouXLhw4WLM5XE4VhrbYzuS/SBmz56NmJgY6XFZWRlyc3MNThV5Euh0Onh6euLatWtQqXg9SVW4j2rHfVQz7p/aPcn7SAiB27dvw93d3dShGF1DHiv174nz588jICBA+heAUdYZq51H3Tb70jjbZl8aZ9vsy6PZnjGO3U/ysbI2j22S3bx5c5iZmSErK8tgfVZWFlxdXat8jlKphFJpeBWOg4NDQ4VociqV6on7Ymts3Ee14z6qGfdP7Z7UfWRvb2/qEOqkvsfLR3GstLOzM/jXWOse17bZl8bZNvvSONtmXx7N9ox17H5cjpXGJjd1AA9KoVCgS5cuSExMlNaVlZUhMTERarXahJERERE1HjxeEhERPVqP7Ug2AMTExCA8PBxdu3ZF9+7dsXLlSty5c0eaPZWIiIh4vCQiInqUHusk+29/+xv++OMPzJ07F1qtFsHBwdi1axdcXOp2v8UnlVKpxLx58yqd7kd/4j6qHfdRzbh/asd91Hg0luOl/j2hUqmkf//5z38CwEOvM1Y7j7pt9qVxts2+NM622ZdHtz0eux+OTIimOKc6ERERERERkfE9ttdkExERERERETU2TLKJiIiIiIiIjIRJNhEREREREZGRMMl+wo0bNw7Dhw+vtnz+/PkIDg5+ZPE8SnFxcU/0fdDpyVDb36ix8O+haav4PhNCYNKkSXB0dIRMJkNKSkqVz5PJZPjuu+8AAFevXpXqWlpa4tlnn8X+/fshk8mk5datWwAAPz8/aV1KSgrGjRtnUF4+HplMhv79+2P48OHSc86cOWMQl75+3759ER0djb59+2LQoEHSe7r8ehsbGynucePGoVu3bpDJZLC1tYVMJsO0adMMYtYv+vLqFn0s+v3w/PPPQyaTwdvb2+C5NjY2iI6OrrINhUIBmUwGpVIJX19fqQ/6/ejh4SHVtba2RnR0tNTWK6+8Uqk9Z2dnyGQyvPbaawbry2+/U6dOBmX6uMuXW1hYoG/fvlJsMpkML7zwAvr27YuAgADIZDL4+PjAysrK4LkvvvgilEol3Nzc4OvrK/WvRYsW0mvSrFkzyGQyuLu7Y+XKlQgODoZCoYCfnx+Cg4Mxbtw42NvbS23K5XLIZDL89a9/hUwmQ6tWrTBu3Dh07twZtra20j6Sy+UGr4c+zqqWd999FzKZDE8//TRkMhnWrl0LBwcHTJgwATKZDHZ2dlLdwMBAyGQyjBw50qCNrl27wsrKCnK5HL6+vnB3d5fK9PvfwsICMpkMhw4dkt7b+v6Ym5tj/PjxBm06OjrCw8MDDg4OkMlkGDp0aKW/KR8fH+l9JZPJ0KdPH4PyGTNmVHqOfptyuRwWFhZQqVTS+2Dr1q0AAC8vL+nvXyaToXfv3lXuO7lcDnt7eygUCulvdOTIkQgODkbLli3RokULjBs3Dn5+fnB0dMSgQYMMnu/g4GDw2RMXFyeVtW7dWvq/lZUVhgwZIj22tLSEi4sLZDIZBg8eDF9fX6ns448/hkwmw5tvvgmFQiG9Z5999lmpTo8ePTBu3DiDbfTv3196j5qZmSE4OBgODg6wtbWFSqXCypUrYW1tDblcDldXVzg6OsLKykra956enhg3bpzUR4VCgdatW1f5OThu3Djp71O/uLm5QSaTYfjw4WjRooW0/rvvvoOXl5fBe23QoEHSvpfJKn8+jRo1CiqVymBdYGCg9Pegv9/1lClTpPePvkz/fP1rXn7b5T9bVq5cKb1u+r9nmUyGDh06oHXr1jAzMwMAuLq6Sp9Z+vee/rhR3XFIv8/0x4SK2ymfn9T0/eVRfbcpf/yrM0ENLjw8XACQFkdHR6HRaMTp06cfybaHDRtWbfm8efNEx44dGzwOfSwAxN///vdKZa+++qoAIMLDw422vQ0bNgh7e/uHbgeA2L59u8G6R7nfapKRkSFeeeUV4ebmJiwsLISXl5d47bXXxI0bN0wd2gPJzs4WkydPFp6enkKhUAgXFxcxaNAgcfjwYalOVa9HXXh7e4sVK1YYL9ga1PZ396B1H0Z9/h5M+ZnV1NW278uXW1hYiNatW4sFCxaIPn36iGnTplVqr1evXsLc3Fy0bt3aoF394uLiIpRKpcG65s2bCwBCLpdX+ZyaFldX1zrVk8lk9W6bS9Nd+H7h0lgWc3Nzk2zXzMxMTJkypdY6CoVCirFZs2bV1rW0tBRqtVoA948zNbX7008/CQsLC+lYYWFhUeXxoVevXtL/9d/Tyn/HKf//wsJCkZmZKcrKygzqK5VK0bZtW6FUKqXv2frvL1V9XzLWd/3apKenCwDi1KlTdX4OR7IfkcGDByMzMxOZmZlITEyEubk5/vKXv1Rbv7i4+BFG9+h4enpiy5YtKCgokNbdu3cPmzdvhpeXlwkje/z89ttv6Nq1Ky5duoQvv/wSly9fxvr165GYmAi1Wo3c3FxTh1hvYWFhOHXqFDZu3Ihff/0V33//Pfr27YucnBxTh9bk8DPLdGrb9/ryS5cu4fXXX8f8+fNx7dq1KtsqKyuT/m9paYn27dvDwsICgwcPhlwuh4ODA/z8/KQ61tbWuHHjBgCgc+fOVbbp4+MDALCwsKhUdu/ePYPH+lvAyGQyg/X6UZa6sLe3r3L9uHHjANy/9UxDUSgUAO7vl/L+8Y9/GH1bVfVTP1rbmFV8bY3drpeXF5YtWyatb9OmTYNsrz70I3j11VD7qj7vExsbG7z77ruV1qtUKtja2lb5nIrv/0et/H4LDAystt6j+HspKSkxeFzVPpPL5Wjfvr1Rt+vi4oJNmzZJj83N79+FufzntBACRUVFaNasGezs7LBnz55q2+vYsSNOnz5dZdn27dvh4OAgbSMkJAQlJSUoKioCAKxevRqdOnWCubk53nrrLTRv3hwAcOLECamNsrIyg+OB/rl6CoVCOpPiYYnGeqOshsr46U9V/fJy6NAhAUBkZ2dLv45s2bJF9OnTRyiVSrFhwwZRWloqFixYIJ566imhUChEx44dxY8//mjQzpkzZ0S/fv2EpaWlcHR0FBMnThS3b9+udts///yzaN68uXjvvfeEEIYjsgcOHBDm5uYiMzPTYBvTpk0TvXv3FkL8+YvRrl27hJ+fn7CxsREajUZcv369zvuhQ4cO4osvvpDWb9q0SQQFBYlhw4ZJI9k//vij6NWrl7C3txeOjo4iNDRUXL58WXqOfp998803om/fvsLKykoEBQWJo0ePSnXqEuvPP/8sQkJChJOTk1CpVKJPnz4iOTlZKvf29jb4lc7b21ts2LCh0q93GzZsEEIIsWzZMtGhQwdhbW0tPDw8xJQpUwxej4fZfxUNHjxYeHh4iLt37xqsz8zMFNbW1mLy5MlCiKpHfu3t7aWYhbg/Ij5ixAhhb28vmjVrJp5//nmRnp5u8JyPPvpI+Pn5CaVSKdq1aydiY2Olsrq8HlevXhV/+ctfhIODg7C2thYBAQEiPj5eKr9586YAIPbv319tn6t6PYQQ4vLly+L5558Xzs7OwsbGRnTt2lUkJCRIz3v22WcrvWZ6hw4dEr179xaWlpbCw8NDTJ06VeTn5xts85133hGvvPKKsLW1FZ6enuLf//53tTEKUfnvbtu2baJDhw7S3+mAAQOkbVSsa4z3vhD332uenp7CyspKDB8+XCxdurReI9kN8ZlVl9hfeeUVERgYKO7duyeEuP9rd3BwsBgzZkydYn/c1bbvw8PDxaBBgwz+Xlu0aCFsbW3FtGnTRHh4uHj++efF008/LY3+yeVy4eHhIT3mqCAXLly4cDHVUp9jkKOjo1AoFFWW+fr6CicnJwHc/0538+ZNMWLECKFQKIRMJhNyuVwEBAQYfB8Uom7f644fPy6Cg4OFUqkUXbp0Ed9++60A6jeSzST7Eaj4pen27dvi73//u/D19RWlpaXSF8+WLVuKb775Rvz222/i+vXrYvny5UKlUokvv/xSXLx4UcycOVNYWFiIX3/9VQghRH5+vnBzcxMvvviiSE1NFYmJicLHx8fglOvy205MTBT29vYGb6SKpz23bdtWLFmyRHpcVFQkmjdvLj799FMhxP0v7hYWFiIkJEScOHFCJCcnC39/fzFq1Kg674fly5eLAQMGSOsHDBggVqxYYZBkf/311+Kbb74Rly5dEqdOnRJDhw4VgYGBorS0VAjx55d1Pz8/sWPHDpGWlib+7//+T3h7e4vi4uI6x5qYmCg+//xzceHCBXH+/HkREREhXFxchE6nE0LcP30ZuJ9EZ2ZmiuzsbHH37l3x+uuvi/bt24vMzEyRmZkpJborVqwQ+/btE+np6SIxMVG0a9dOTJkyRdrew+y/8nJycoRMJhPvvvtuleUTJ04UzZo1q3Qajl75JLuoqEj4+/uL8ePHizNnzojz58+LUaNGiXbt2onCwkIhhBBffPGFcHNzk96f33zzjXB0dBRxcXF1fj1CQ0PFwIEDxZkzZ8SVK1fEDz/8IA4cOCDFVFxcLGxtbUV0dLSUYFVU1eshhBApKSli/fr1IjU1Vfz6669izpw5wtLSUvz3v/+V9peHh4dYuHCh9JoJcT85t7GxEStWrBC//vqrOHLkiOjUqZMYN26ctE1vb2/h6OgoYmNjxaVLl8TixYuFXC4XFy9erPb1Kf93d/36dWFubi6WL18u0tPTxZkzZ0RsbKz040vFzwdjvPePHTsm5HK5eP/990VaWppYtWqVcHBweOAk21ifWXWJ/fbt26JVq1YiOjpaCCHEG2+8IVq2bCny8vLqFPvjrrZ9P2bMGGFra2vw9/rUU08JmUwmoqKiRHh4uFAoFEKhUIgVK1YIPz8/gy8lzZo1E5aWlgK4f2qhpaXlA50WzoULFy5cuNR1qXicqXjaffnLlszMzKT/6y9fAu6fpu7s7CwsLS2FTCYTAwcOFPPnzxe2trZCCCFCQkLEs88+K2bPni127Nghxo8fL6ysrIRSqZS+DwpR+/e627dvixYtWohRo0aJs2fPih9++EG0atVKAEyyG53w8HBhZmYmbGxshI2NjQAg3NzcpBFT/RfPlStXGjzP3d1dvPPOOwbrunXrJl599VUhhBAffvihaNasmcGoW3x8vJDL5UKr1UrbHjZsmPj222+Fra2t2LJli0F7FZPs999/X/j7+0uPv/nmG2FrayttQz+KW35kLTY2Vri4uNRpPwwbNkxkZ2cLpVIprl69Kq5evSosLS3FH3/8YZBkV/THH38IACI1NdVgn3388cdSnXPnzgkA4sKFCw8ca2lpqbCzsxM//PCDtA548Guyt23bJpycnKTHD7P/yjt27FiVcektX75cABBZWVlV1iufZH/++eeiXbt2oqysTCovLCwUVlZWYvfu3UIIIVq3bi02b95s0MaiRYuEWq0WQtTt9QgMDBTz58+vsV9ff/21lAQ8/fTTYvbs2ZWuA66p3+W1b99erF69Wnpc1TXZERERYtKkSQbrDh06JORyuSgoKJCe9/LLL0vlZWVlwtnZWaxbt67abZdPlJKTkwUAcfXq1VrrVuVB3vsvvfSSeO655wza+dvf/lavJLshPrPqErsQQhw9elRYWFiIt956S5ibm4tDhw7VKe4nQW37vnfv3sLW1laUlZWJsrIykZCQIH05GT58uAgPDxdyuVz6Aa78NXJ1+eLDhQsXLly41Gepy3Xqd+/elf5vZ2cn/b99+/YCgHjqqaekdfo5RMzMzISzs7O03tfXV8hkMtG9e3dhbm4usrOzpTNEDx06JFQqVaVBmtatWws3N7dK3wdr+l7373//Wzg5OUnfA4UQYt26dQLgNdmNUr9+/ZCSkoKUlBT8/PPP0Gg0GDJkCP773/9Kdbp27Sr9X6fT4fr16+jVq5dBO7169cKFCxcAABcuXEDHjh1hY2NjUF5WVoa0tDRp3fHjxzFixAh8/vnn+Nvf/lZjnOPGjcPly5dx7NgxAPdn7fvrX/9qsA1ra2u0bt1aeuzm5obs7Ow674sWLVogNDQUcXFx2LBhA0JDQ6XrOfQuXbqEl156Ca1atYJKpULLli0BABkZGQb1goKCDOIAYBBLbbFmZWVh4sSJaNOmDezt7aFSqZCfn19pO3W1d+9eDBgwAE899RTs7OwwZswY5OTk4O7du3WOqT5ELdeh6K8nrMnp06dx+fJl2NnZwdbWFra2tnB0dMS9e/dw5coV3LlzB1euXEFERIRUbmtri7fffhtXrlwxaKum1+O1117D22+/jV69emHevHk4c+ZMpVjCwsJw/fp1fP/99xg8eDD279+Pzp07Iy4ursY+5Ofn44033oC/v780U+iFCxdqfR1Pnz6NuLg4g35pNBqUlZUhPT29yn7JZDK4urrW+TXr2LEjBgwYgMDAQIwYMQIfffQRbt68WW19Y7z3L1y4gB49ehjUV6vVdYpXryE+s+oSuz7WN954A4sWLcLrr7+O3r171yv2x11N+/7mzZvIz8+HXC6HXC7HwIEDUVpaCgDIy8tDUVERysrKDF4H/TVvMpkMzZs3N7imVT8TLBER0YOoeJ16Vcpf15+fny/938nJCQBQWloKa2trWFhYSN+Zy8rKDL4bXL58GUIItG7dWprZXu/06dPIz8+Hk5MTFAqFdGy7cuUKMjMza/wOVfF73YULFxAUFARLS0upTn2/QwG8hdcjY2NjA19fX/j6+qJbt274+OOPcefOHXz00UcGdRpC69at4efnh08//bTWyYmcnZ0xdOhQbNiwAVlZWfjxxx8xfvx4gzoVJ7uRyWT1nnRg/PjxiIuLw8aNGyu1DwBDhw5Fbm4uPvroIxw/fhzHjx8HUHnihPKx6L8olp/op7ZYw8PDkZKSglWrVuHo0aNISUmBk5NTpe3UxdWrV/GXv/wFQUFB+Oabb5CcnIzY2NhKcRtj/+lvZVExedG7cOECWrRoId0WpGL75d8H+fn56NKli/SlXr/8+uuvGDVqlPRh+NFHHxmUnz17Vvoxpqq+VXw9JkyYgN9++w1jxoxBamoqunbtitWrV1eK3dLSEgMHDsRbb72Fo0ePYty4cZg3b16N++ONN97A9u3b8e677+LQoUNISUlBYGBgra9jfn4+/v73vxv06/Tp07h06ZLBDyFVvWbl32c1MTMzQ0JCAn788UcEBARg9erVaNeunUESX56x3vsPqyE/s2qLvaysDEeOHIGZmRkuX778gD14fNW074uLi6FSqbB3714cOHAAFy5cwIULF9C/f3/pB4vyioqKIJfLpR/cdDqdwY+aERER6Nix4yPrGxERPVn0E1zWZO/evdL/9YMHFVlYWEAIgczMTAB/fsd44YUXpHIA+PLLLytN7pufnw83NzcMHToUrq6uWLNmDXbs2IG9e/eiffv2NX6HAur3va6umGSbiP7eg+Vn2S5PpVLB3d0dR44cMVh/5MgRBAQEAAD8/f1x+vRp3Llzx6BcLpejXbt20rrmzZtj3759uHz5Mv7617/WmmhPmDABW7duxYcffojWrVtXGpkyhsGDB6OoqAjFxcXQaDQGZTk5OUhLS8OcOXMwYMAA+Pv71zjy9zCOHDmC1157Dc899xzat28PpVIpzayrZ2FhIY0U6SkUikrrkpOTUVZWhmXLlqFnz55o27Ytrl+/3iBxOzk5YeDAgVi7dm2l95BWq8WmTZukmXdbtGghfWAB90dKy4+sd+7cGZcuXYKzs7P0xV6/2Nvbw8XFBe7u7vjtt98qletnGa4rT09PTJ48Gd9++y1ef/11g4StOgEBAQbv8apejyNHjmDcuHF44YUXEBgYCFdXV1y9etWgTlWvWefOnXH+/PlK/dLf79VYZDIZevXqhQULFuDUqVNQKBTYvn17pXrGeu/7+/tLyblexR9E6ssYn1l19cEHH+DixYs4cOAAdu3ahQ0bNjxw3E+C8vveyckJBQUF6NatG/r06QM/Pz/4+vqic+fOOHv2rHTPWP3rn5OTAysrKxQVFUl/OydOnJAS8pycHIMvH/rZZImIiOqiLt+Xyo8c5+bmSon57du3AdwfkBBCoKSkRJq938rKCgAM7nhhZmYGuVxe6btR586dodVq8csvv2DixIl49dVXERoaih49euD333+vV3/8/f1x5swZg9nRH+Q7FJPsR6SwsBBarRZarRYXLlzA1KlTkZ+fj6FDh1b7nBkzZuD999/H1q1bkZaWhjfffBMpKSmYNm0aAGD06NGwtLREeHg4zp49i59++glTp07FmDFj4OLiYtCWs7Mz9u3bh4sXL+Kll16q8dQOjUYDlUqFt99+G6+88opxdkAFZmZmuHDhAs6fP1/pVhjNmjWDk5MTPvzwQ1y+fBn79u1DTExMg8TRpk0bfP7557hw4QKOHz+O0aNHS3/Uei1btkRiYiK0Wq30R92yZUukp6cjJSUFN27cQGFhIXx9fVFcXIzVq1fjt99+w+eff47169c3SNwAsGbNGhQWFkKj0eDgwYO4du0adu3ahYEDB6Jt27aYO3cuAKB///5Ys2YNTp06hZMnT2Ly5MkGv+CNHj0azZs3x7Bhw3Do0CGkp6dj//79eO2116QPpgULFmDx4sX417/+hV9//RWpqanYsGEDli9fXud4o6OjsXv3bqSnp+OXX37BTz/9BH9/f6k8JycH/fv3xxdffIEzZ84gPT0d27Ztw5IlSzBs2DCpXlWvR5s2bfDtt99KI9GjRo2q9Itky5YtcfDgQfzvf/+TPrBnzZqFo0ePIioqCikpKbh06RL+85//ICoqqp6vRvWOHz+Od999FydPnkRGRga+/fZb/PHHHwZ91zPWe/+1117Drl27sHTpUly6dAlr1qzBrl276tVGQ3xm1cWpU6cwd+5cfPzxx+jVqxeWL1+OadOm4bfffqtX/I+zmvZ9q1atoFAoKv29ZmdnIy0tDcePH8dTTz2Fd955B6+88grS09Olz7SSkhI4ODigpKQEWq0WAPD1118bnBFTl9P+iIiI9Mqf/l2d8mda5eXlSWdYnjp1CsD9yzfv3LkDmUwmDYjo84PDhw8D+HO0uaysDEIIg1tXhoSEQK1WIysrC3Fxcdi5cyc2btyITp061fsWo6NGjYJMJsPEiRNx/vx57Ny5E0uXLq1XGwDAic8egfDwcIOL/+3s7ES3bt3E119/LYSo/gbnpaWlYv78+eKpp54SFhYWRrmF1/Xr10Xbtm3FX//6V1FSUlLtBF5vvfWWMDMzq3Rrqapu+r59+3ZRl7dSbRM8lZ/4LCEhQfj7+wulUimCgoLE/v37BfDnhFdV7TP9LaB++umnOsf6yy+/iK5duwpLS0vRpk0bsW3btkoTZH3//ffC19dXmJubS7eMunfvnggLCxMODg4C+PMWXsuXLxdubm7CyspKaDQa8dlnnwkA4ubNmw+9/6qSnp4uwsPDhYuLi3RLhBdffFHcuXNHqvO///1PDBo0SNjY2Ig2bdqInTt3VrqFV2Zmphg7dqxo3ry5UCqVolWrVmLixIkGMzpv2rRJBAcHC4VCIZo1ayb69Okjvv32WymO2l6PqKgo0bp1a6FUKkWLFi3EmDFjxI0bN6T69+7dE2+++abo3LmzsLe3F9bW1qJdu3Zizpw5Brcpq+r1SE9PF/369RNWVlbC09NTrFmzRjz77LNi2rRp0vOSkpJEUFCQNEmU3s8//ywGDhwobG1thY2NjQgKCjKYvKuqCdM6duwo5s2bV+3rUv69fv78eaHRaESLFi2EUqkUbdu2NZiAo+LfhTHe+0II8cknnwgPDw9hZWUlhg4dWu9beDXEZ1ZtsRcUFIiAgIBKk9Hpb0lVUlJSp/gfZ7Xt+/DwcKHRaKr8e923b59wc3OTZhc3MzMT5ubmonXr1sLDw8Pkk+Nw4cKFCxcu5W/hVX4m8arKAQhbW9sq2/H29harVq2SvtvodDrpDhv6trt16yZ69Ohh8H2wLt/rkpKSRMeOHYVCoRDBwcHim2++EQBnFycjGD9+vBg6dKipw6B6mjt3rrC1tRVJSUmmDoWIGqHafuwUQlT6gaqud1NoqFg8PT3Fyy+/LNLT04VcLheffPKJAP68S0N18d2+fVvIZDLxyiuvVNt+fn6+sLe3F23btjXo8/jx4wVQ+U4G+nX5+fnSl8OePXtK5XPnzhUWFhYiKChIWnft2jUBQHh4eAiVSmXQXufOnQ3uCFKffaNvVyaTibt374rS0lLRtm1b4ePjI82ce/v2baFSqURQUJDQaDQCgOjVq5cICQkRwJ8/AFfl9u3bwszMTHTv3l0A92+x88033wgh7r8uERERAoDYu3ev+Oyzz4STk5MoLCwUhw8fFgDEsmXLhIWFhfQjqX5fR0RESHWFEOLtt9+WbrEYGBgoysrKhKOjo8GPgl26dBHW1tZCCMMvyPo+z5kzp1L8Bw8eFBYWFmLUqFEiKCjI4D0jROUfvfX7c+/evQbthoSECFtbW7Fs2TKD9vXxVny+tbW16N+/v/j73/8uVCqV+Oabb8Tbb79d6f30xRdfGOwf/fO7du0qIiMjK/Wn/PMXLFggFAqF1O9nnnlGeh9UVFZWJhwcHIRMJjO4s0NtKvavov79+4upU6dKr/eZM2eEra2tkMlkwtzcvMpYqqN/b1SMr2IyBEC888470l0R9K9nSEiIwWzReh4eHsLNzc1gXVhYmAAgxVfxdahJVd+Ny8rKROvWrcWyZcuk95z+7/nixYsCQJU/yut/dE5OThZt27YVM2fOrHIf6N25c0dYWloa/JhuLM8++6zo2bOnaNWqlUH81fn8888FAPHee+/VWC8kJEQ4OztLn63V/UD/pOLFV2QgLy8Pqamp2Lx5M77//ntTh0P1tGDBArRs2RLHjh1D9+7dIZfzihAienzcvXsX69evh0ajgZmZGa5evYpr167B29sb0dHR8PPzw7Jly9CrVy+DyQnLKysrw40bN7Bs2TLI5XK0b99eKjt16hQuXryI7t27Iy8vDwsXLgQAaTK48sfA8k6dOiUdE7/55hvMnDlTOqWxTZs2OH36NGxsbNC8eXOUlpZCpVKhf//+6NevH7Zu3Qpra2v8/vvvGDt2LID7c2f88MMP+OWXX/CXv/yl0iVeVdm3bx++//57PP3007h79y5mz54NAHjqqaewa9cubNmyBZcvX0ZZWRkGDhyId955BwcOHMC9e/dw5swZ/PHHH/D09MSRI0ewdOlSg4mIyu/7gQMHQqfTYcaMGSgtLZUuL7K0tIRMJkN6ejp0Oh127twJLy8vnD9/HsuWLUPHjh2xdu1axMbGws/PD++//z66d++O69evIy8vD3PnzkVpaSl++OEHDB06FL///juOHDmCJUuWIDAwECtXrsTkyZMxduxY5ObmYsyYMTh9+jS2bNmC5ORkjBkzBv/973+Rn5+P7OxspKamYs2aNUhPT8eoUaOkfrz33nsoKCjAtm3b4Ofnh61bt8LZ2bnSe+b8+fMoKSlBeno6Tp06hZkzZ8LNzQ3x8fFYv349fvvtN/zvf//D3r17YWlpKV0+l5+fj6tXr2L58uUYPXo00tPTcebMGcyYMQMA8Oyzz+LHH3+U7tih0+nwwQcfSNvs2LEjTp8+jejoaDz99NPQarXIzMxETEwMnJ2dkZqain/+858Gr43+rg6//fYbvv32W7z99tsoLS1Fnz598N133yE5ORlPPfWUdGmI/n3u5uaGjRs34tatW7C0tDS49Ko6+v6tWbMGb7/9dqXyzz//XLqcydfXF2FhYWjdujUiIyNx9+5dKJVKhIWFVbr0rrzq/g6ri2/79u3Sdb9r1qxBWVkZPD09UVxcjHnz5mHv3r1ISEjA0qVLMXDgQJSUlODDDz/E77//jv79++Pw4cNwcHBAYmIivv32WwQEBECr1eL06dOYNWsW/vrXv9YYb3Xfjf/44w9s2bIFmZmZGDRoEMaOHQu1Wo38/HycPHkSf//732FmZoZZs2ZJz/nvf/+LPXv2SKdL/+Mf/8Bvv/2GkydP1rgPfvrpJ/Tv3x99+/atNs4HkZ+fj9u3b+P8+fNo2bIlRowYUenz6LPPPkOrVq3w1FNP4eDBg5g2bRrMzMwwadIkqU7Fz+4vv/wSe/fuNbgWu8kxdZZPjcuzzz4rrKysRHR0tKlDISIiI2vsI9l3794VAwYMEI6OjsLa2lrY2tpK90yVyWTC2dlZhIeHG1xqUjE+/WiJh4eHcHFxMRgJ++WXX0Tnzp2FjY2NaNasmQgJCRFnzpyR+lz+GIhyI4e//PKLaNu2rcGpiubm5mLZsmVixIgRokWLFsLS0lIEBASIqVOnivbt2xuc8qhQKMRLL70kxeHk5CSA+/eG/f333+u0b3bt2mVwaRD+/6ip/rFcLhdt2rQRmzdvrnR/dP3oYmBgoPjmm2/ETz/9VGkkW7/v7e3tpf6Vb+Pll18W7du3F1ZWVsLCwkK0atVKTJs2TZiZmQkrKythZmYmzMzMhFwuF15eXmLUqFEiODhY2tc+Pj7C3NxceHp6ChcXF6FUKkWbNm1EcHCwkMvlwtLSUuqHh4eHaNGihZDL5UImk4kuXbqIkpISkZGRIZRKpVAqlcLOzk6o1Wpx4MABg/3UrVs3g7gdHBwqvWeEECImJkbI5XJhZWUlmjdvLhwdHYWNjY10mYU+Hjs7O7Fp0yaD10ahUIg+ffqIgIAAYWVlJb0G5ubm0qmtcrlcWFhYiDZt2oiFCxcKANJlQy1bthTDhw8X/v7+wsrKSjg7Ows3Nzfh6uoq/vGPf4iysjKDWDMyMgxOrbW2tpb2YcuWLYW/v78IDQ2t9D7X7wOVSlXn0UN9//SXFVbk5OQk5HK5MDMzExYWFtKosr7/EyZMMLhkrSrV/R1WpB/J3rhxo3BxcZG2o1QqhYODg7C2thadOnWSzrDQ/y3K5XJhbm4uBg8eLN577z3h7e0txenk5CS8vLykfRcdHV1rvNV9NwYgmjdvLiZNmiTkcrnw9fUVbdu2ld47lpaWBu8dIe6/lk8//bSwtraW3ie2trbV7oOGVv4Spc6dO1f5efT+++8Lb29v6XI7S0tL8emnnxrUqfjZrX9dyh9PmtpItkyIet47iIiIiIiIiIiqxHNJiYiIiIiIiIyESTYRERERERGRkTDJJiIiIiIiIjISJtlERERERERERsIkm4iIiIgeK/Pnz0dwcHC9ntO3b19ER0fXWEcmk+G777574LgeRlxcHBwcHEyy7XHjxmH48OEm2TbRk4hJNlE98cBuXDywExFRfb3xxhtITEw0dRhERFVikk1UTzywExERmZatrS2cnJxMHYbRFBUVmToEIjIiJtlE9cQD++PlSe8fEdHjqG/fvnjttdcwc+ZMODo6wtXVFfPnz5fKb926hQkTJqBFixZQqVTo378/Tp8+LZVXPKuspKQEr732GhwcHODk5IRZs2YhPDy80plSZWVl1W5TLzMzE0OGDIGVlRVatWqFr7/+2qA8NTUV/fv3h5WVFZycnDBp0iTk5+cb9K3i2WvDhw/HuHHjpMctW7bEokWLMHbsWKhUKkyaNEkq2717N/z9/WFra4vBgwcjMzPTIP6FCxfCw8MDSqUSwcHB2LVrV73iKy0tRUxMjLSvZs6cCSFEpf1ARA+OSTY1OTywP74H9tu3b2P06NGwsbGBm5sbVqxYUanP1fXvm2++Qfv27aFUKtGyZUssW7bMoO2qTtd3cHBAXFwcAODq1auQyWTYsmULnn76aVhaWqJDhw44cOBAneMnIqI/bdy4ETY2Njh+/DiWLFmChQsXIiEhAQAwYsQIZGdn48cff0RycjI6d+6MAQMGIDc3t8q23n//fWzatAkbNmzAkSNHoNPpqrwEq6Zt6r311lsICwvD6dOnMXr0aIwcORIXLlwAANy5cwcajQbNmjXDiRMnsG3bNuzduxdRUVH17v/SpUvRsWNHnDp1Cm+99RYA4O7du1i6dCk+//xzHDx4EBkZGXjjjTek56xatQrLli3D0qVLcebMGWg0Gjz//PO4dOlSneNbtmwZ4uLi8Omnn+Lw4cPIzc3F9u3b6x0/EdVAEDUxzz77rFCpVGL+/Pni119/FRs3bhQymUzs2bNHCCFESEiIGDp0qDhx4oT49ddfxeuvvy6cnJxETk6OEEKIefPmiY4dO0rtvf3228LR0VF8++234sKFC2Ly5MlCpVKJYcOG1XmbQggBQDg5OYmPPvpIpKWliTlz5ggzMzNx/vx5IYQQ+fn5ws3NTbz44osiNTVVJCYmCh8fHxEeHm6wnWnTphn0d9iwYQZ1vL29hUqlEkuXLhWXL18Wly9fFhs2bBAWFhYiJCREnDhxQiQnJwt/f38xatQo6XnLly8XKpVKfPnll+LixYti5syZwsLCQvz66691ju/9998XzZo1E9988404f/68iIiIEHZ2dgb7qiYTJkwQ3t7eYu/evSI1NVW88MILws7OzqDPVfXv5MmTQi6Xi4ULF4q0tDSxYcMGYWVlJTZs2GCw/7dv326wPXt7e6lOenq6ACA8PDzE119/Lc6fPy8mTJgg7OzsxI0bN+oUPxER3ffss8+K3r17G6zr1q2bmDVrljh06JBQqVTi3r17BuWtW7cW//73v4UQlY/FLi4u4oMPPpAel5SUCC8vr0rH4uq2qQdATJ482aBOjx49xJQpU4QQQnz44YeiWbNmIj8/XyqPj48XcrlcaLVaaTt1ORYPHz7coM6GDRsEAHH58mVpXWxsrHBxcZEeu7u7i3feeadSH1599dU6x+fm5iaWLFkilRcXFwsPD486H4uJqHYcyaYmKSgoCPPmzUObNm0wduxYdO3aFYmJiTh8+DB+/vlnbNu2DV27dkWbNm2wdOlSODg4VBpV1lu9ejVmz56NF154AX5+flizZk2Vk4hVt83yRowYgQkTJqBt27ZYtGgRunbtitWrVwMANm/ejHv37uGzzz5Dhw4d0L9/f6xZswaff/45srKy6tX//v374/XXX0fr1q3RunVrAEBxcTHWr1+Prl27onPnzoiKijKIb+nSpZg1axZGjhyJdu3a4f3330dwcDBWrlxZ5/hWrlyJ2bNn48UXX4S/vz/Wr18Pe3v7OsV8+/ZtbNy4EUuXLsWAAQPQoUMHbNiwAaWlpbX2b/ny5RgwYADeeusttG3bFuPGjUNUVBQ++OCDeu03AIiKikJYWBj8/f2xbt062Nvb45NPPql3O0RETV1QUJDBYzc3N2RnZ+P06dPIz8+Hk5MTbG1tpSU9PR1Xrlyp1E5eXh6ysrLQvXt3aZ2ZmRm6dOlS522Wp1arKz3Wj2RfuHABHTt2hI2NjVTeq1cvlJWVIS0trY49v69r166V1llbW0vH5Yrx6XQ6XL9+Hb169TJ4Tq9eveocX15eHjIzM9GjRw+p3NzcvMpYiOjBmZs6ACJTqMuBvbyCgoJ6H9jLysrqtM3yqjqwp6SkAKj9wOni4lJLr/9kzAO7/lT62uKztLSs9sAu6nDK+G+//Ybi4mKDfW1vb4927drV2r8LFy5g2LBhlWJfuXIlSktLYWZmVuv29cq/Rvr49V9uiIio7iwsLAwey2QylJWVIT8/H25ubti/f3+l5zzsnTCq26YxyeXySse14uLiSvXKHy9riq8ux0gialw4kk1NUm0H9pSUFIMlLS0NM2bMaJBtGhMP7PdV1b/aVNXfqvYdERE1rM6dO0Or1cLc3By+vr4GS/PmzSvVt7e3h4uLC06cOCGtKy0txS+//PJA2z927Filx/7+/gAAf39/nD59Gnfu3JHKjxw5ArlcLv3o26JFC4M5TUpLS3H27NkHiqU8lUoFd3d3HDlyxGD9kSNHEBAQUKf47O3t4ebmhuPHj0vlJSUlSE5Ofuj4iOhPTLKJyuGBvWqN4cDeqlUrWFhYGOzrvLw8/Prrr7U+19/fv8rY27ZtK41iV9x3ly5dwt27dyu1Vf410sevf42IiOjhhYSEQK1WY/jw4dizZw+uXr2Ko0eP4p///CdOnjxZ5XOmTp2KxYsX4z//+Q/S0tIwbdo03Lx5EzKZrN7b37ZtGz799FP8+uuvmDdvHn7++Wdp4rDRo0fD0tIS4eHhOHv2LH766SdMnToVY8aMkc4o69+/P+Lj4xEfH4+LFy9iypQpuHXr1gPvj/JmzJiB999/H1u3bkVaWhrefPNNpKSkYNq0aXWOb9q0aXjvvffw3Xff4eLFi3j11VeNFh8R3cfTxYnKKX9gX7JkCdq2bYvr168jPj4eL7zwQpWnWesP7L6+vvDz88Pq1asf6sDetWtX9O7dG5s2bcLPP/8sXe87evRozJs3D+Hh4Zg/fz7++OOPKg/sMTExiI+Pl65FNuaBfd68eWjdujWCg4OxYcMGpKSkYNOmTXWOT39gb9OmDfz8/OoVn52dHcLDwzFjxgw4OjrC2dkZ8+bNg1wur3Vfv/766+jWrRsWLVqEv/3tb0hKSsKaNWuwdu1aqY7+GnK1Wo3S0lLMmjWr0ug+AMTGxqJNmzbw9/fHihUrcPPmTYwfP76Oe5GIiGojk8mwc+dO/POf/8Qrr7yCP/74A66urujTp0+1l0bNmjULWq0WY8eOhZmZGSZNmgSNRlOvy4H0FixYgC1btuDVV1+Fm5sbvvzyS+kHZWtra+zevRvTpk1Dt27dYG1tjbCwMCxfvlx6/vjx43H69GmMHTsW5ubmmD59Ovr16/dgO6OC1157DXl5eXj99deRnZ2NgIAAfP/992jTpk2d43v99deRmZmJ8PBwyOVyjB8/Hi+88ALy8vKMEiMRgbOLU9NT26yfOp1OTJ06Vbi7uwsLCwvh6ekpRo8eLTIyMoQQlWc0LS4uFlFRUUKlUolmzZqJWbNmiREjRoiRI0fWeZtC3J/RNDY2VgwcOFAolUrRsmVLsXXrVoPnnDlzRvTr109YWloKR0dHMXHiRHH79m2pvKioSEyZMkU4OjoKZ2dnsXjx4ipnNF2xYoVBuxs2bBD29vYG67Zv3y7Kf0SUlpaK+fPni6eeekpYWFiIjh07ih9//LFe8RUXF4tp06YJlUolHBwcRExMjBg7dmydZzTV6XRi1KhRwtraWri6uorly5eL7t27izfffLPG/gkhxNdffy0CAgKEhYWF8PLyMpiFVggh/ve//4lBgwYJGxsb0aZNG7Fz584qZxffvHmz6N69u1AoFCIgIEDs27evTrETEdGjU1paKtq2bSvmzJlj6lCIqAmSCfGYXnRJ1EiVlZXB398ff/3rX7Fo0SJTh/NEu3PnDp566iksW7YMERERDbqtq1evwsfHB6dOnTK4TzoREZnef//7X+zZswfPPvssCgsLsWbNGmzYsAGnT5/mJT1E9MjxdHGih1TVgT09PR2jRo0ydWhPnFOnTuHixYvo3r078vLysHDhQgCoNHM4ERE1LXK5HHFxcXjjjTcghECHDh2wd+9eJthEZBJMsokeEg/sxpGRkSFd81aV8+fPA7h/v+60tDQoFAp06dIFhw4dqnJSOiIiajo8PT0rTXBJRGQqPF2ciBqFkpISXL16tdryli1bwtycvwsSERERUePGJJuIiIiIiIjISHifbCIiIiIiIiIjYZJNREREREREZCRMsomIiIiIiIiMhEk2ERERERERkZEwySYiIiIiIiIyEibZREREREREREbCJJuIiIiIiIjISJhkExERERERERkJk2wiIiIiIiIiI2GSTURERERERGQkTLKJiIiIiIiIjIRJNhEREREREZGRmJs6AFMqKyvD9evXYWdnB5lMZupwiIjoMSGEwO3bt+Hu7g65/Mn+vZrHSiIiehBN6VhZUZNOsq9fvw5PT09Th0FERI+pa9euwcPDw9RhNCgeK4mI6GE0hWNlRU06ybazswNw/4VXqVQmjoaIiB4XOp0Onp6e0nHkScZjJRERPYimdKysqEkn2frT3lQqFb84EBFRvTWF06d5rCQioofRFI6VFTWtk+OJiIiIiIiIGhCTbCIiIiIiIiIjYZJNREREREREZCRMsomIiIiIiIiMhEk2ERERERERkZEwySYiIiIiIiIyEibZREREREREREbCJJuIiIiIiIjISOqVZC9evBjdunWDnZ0dnJ2dMXz4cKSlpRnU6du3L2QymcEyefJkgzoZGRkIDQ2FtbU1nJ2dMWPGDJSUlBjU2b9/Pzp37gylUglfX1/ExcVViic2NhYtW7aEpaUlevTogZ9//rk+3SEiIiIiIiIyKvP6VD5w4AAiIyPRrVs3lJSU4B//+AcGDRqE8+fPw8bGRqo3ceJELFy4UHpsbW0t/b+0tBShoaFwdXXF0aNHkZmZibFjx8LCwgLvvvsuACA9PR2hoaGYPHkyNm3ahMTEREyYMAFubm7QaDQAgK1btyImJgbr169Hjx49sHLlSmg0GqSlpcHZ2fmhdgpRVTIyMnDjxg1Th0ENqHnz5vDy8jJ1GET0/5WVlSE7OxsA4OzsDLmcJ+AREVHjJxNCiAd98h9//AFnZ2ccOHAAffr0AXB/JDs4OBgrV66s8jk//vgj/vKXv+D69etwcXEBAKxfvx6zZs3CH3/8AYVCgVmzZiE+Ph5nz56Vnjdy5EjcunULu3btAgD06NED3bp1w5o1awDcPxB7enpi6tSpePPNN+sUv06ng729PfLy8qBSqR50N1ATkJGRAT8/fxQU3DV1KNSArKyscfHiBSbaVKumdPwwZV+1Wi3GrU0AAMS9OhCurq6PdPtERPTgmtKxsqJ6jWRXlJeXBwBwdHQ0WL9p0yZ88cUXcHV1xdChQ/HWW29Jo9lJSUkIDAyUEmwA0Gg0mDJlCs6dO4dOnTohKSkJISEhBm1qNBpER0cDAIqKipCcnIzZs2dL5XK5HCEhIUhKSqo23sLCQhQWFkqPdTrdg3WcmpwbN26goOAueoyfB5VbS1OHQw1Al3kVxz9dgBs3bjDJJmpElHbNTB0CERFRvTxwkl1WVobo6Gj06tULHTp0kNaPGjUK3t7ecHd3x5kzZzBr1iykpaXh22+/BXD/V+nyCTYA6bFWq62xjk6nQ0FBAW7evInS0tIq61y8eLHamBcvXowFCxY8aJeJoHJrCUevdqYOg4iIiIiIGqkHTrIjIyNx9uxZHD582GD9pEmTpP8HBgbCzc0NAwYMwJUrV9C6desHj9QIZs+ejZiYGOmxTqeDp6enCSMiIiIiIiKiJ8kDJdlRUVHYsWMHDh48CA8Pjxrr9ujRAwBw+fJltG7dGq6urpVmAc/KygIA6VorV1dXaV35OiqVClZWVjAzM4OZmVmVdWq6XkupVEKpVNatk0RERERERET1VK9pOoUQiIqKwvbt27Fv3z74+PjU+pyUlBQAgJubGwBArVYjNTVVmi0UABISEqBSqRAQECDVSUxMNGgnISEBarUaAKBQKNClSxeDOmVlZUhMTJTqEBERERERET1q9RrJjoyMxObNm/Gf//wHdnZ20jXU9vb2sLKywpUrV7B582Y899xzcHJywpkzZzB9+nT06dMHQUFBAIBBgwYhICAAY8aMwZIlS6DVajFnzhxERkZKo8yTJ0/GmjVrMHPmTIwfPx779u3DV199hfj4eCmWmJgYhIeHo2vXrujevTtWrlyJO3fu4JVXXjHWviEiIiIiIiKql3ol2evWrQNw/zZd5W3YsAHjxo2DQqHA3r17pYTX09MTYWFhmDNnjlTXzMwMO3bswJQpU6BWq2FjY4Pw8HCD+2r7+PggPj4e06dPx6pVq+Dh4YGPP/5Yukc2APztb3/DH3/8gblz50Kr1SI4OBi7du2qNBkaERERERER0aNSryS7tltqe3p64sCBA7W24+3tjZ07d9ZYp2/fvjh16lSNdaKiohAVFVXr9oiIiIiIiIgehXpdk01ERERERERE1XvgW3gRERERPS7KysoMJl11dnaGXM6xBiIiMj4m2URERPTEy87Oxri1CVDaNUPh7ZuIe3Vgjbf9JCIielBMsomIiKhJUNo1g5W9k6nDICKiJxzPkyIiIiIiIiIyEibZREREREREREbCJJuIiMgE1q1bh6CgIKhUKqhUKqjVavz4449S+b179xAZGQknJyfY2toiLCwMWVlZBm1kZGQgNDQU1tbWcHZ2xowZM1BSUmJQZ//+/ejcuTOUSiV8fX0RFxf3KLpHRETUZDHJJiIiMgEPDw+89957SE5OxsmTJ9G/f38MGzYM586dAwBMnz4dP/zwA7Zt24YDBw7g+vXrePHFF6Xnl5aWIjQ0FEVFRTh69Cg2btyIuLg4zJ07V6qTnp6O0NBQ9OvXDykpKYiOjsaECROwe/fuR95fIiKipoITnxEREZnA0KFDDR6/8847WLduHY4dOwYPDw988skn2Lx5M/r37w8A2LBhA/z9/XHs2DH07NkTe/bswfnz57F37164uLggODgYixYtwqxZszB//nwoFAqsX78ePj4+WLZsGQDA398fhw8fxooVK6DRaB55n4mIiJoCjmQTERGZWGlpKbZs2YI7d+5ArVYjOTkZxcXFCAkJker4+fnBy8sLSUlJAICkpCQEBgbCxcVFqqPRaKDT6aTR8KSkJIM29HX0bRAREZHxcSSbiIjIRFJTU6FWq3Hv3j3Y2tpi+/btCAgIQEpKChQKBRwcHAzqu7i4QKvVAgC0Wq1Bgq0v15fVVEen06GgoABWVlaVYiosLERhYaH0WKfTPXQ/iYiImhKOZBMREZlIu3btkJKSguPHj2PKlCkIDw/H+fPnTRrT4sWLYW9vLy2enp4mjYeIiOhxwySbiIjIRBQKBXx9fdGlSxcsXrwYHTt2xKpVq+Dq6oqioiLcunXLoH5WVhZcXV0BAK6urpVmG9c/rq2OSqWqchQbAGbPno28vDxpuXbtmjG6SkRE1GQwySYiImokysrKUFhYiC5dusDCwgKJiYlSWVpaGjIyMqBWqwEAarUaqampyM7OluokJCRApVIhICBAqlO+DX0dfRtVUSqV0m3F9AsRERHVHa/JJiIiMoHZs2djyJAh8PLywu3bt7F582bs378fu3fvhr29PSIiIhATEwNHR0eoVCpMnToVarUaPXv2BAAMGjQIAQEBGDNmDJYsWQKtVos5c+YgMjISSqUSADB58mSsWbMGM2fOxPjx47Fv3z589dVXiI+PN2XXiYiInmhMsomIiEwgOzsbY8eORWZmJuzt7REUFITdu3dj4MCBAIAVK1ZALpcjLCwMhYWF0Gg0WLt2rfR8MzMz7NixA1OmTIFarYaNjQ3Cw8OxcOFCqY6Pjw/i4+Mxffp0rFq1Ch4eHvj44495+y4iIqIGxCSbiIjIBD755JMayy0tLREbG4vY2Nhq63h7e2Pnzp01ttO3b1+cOnXqgWIkIiKi+uM12URERERERERGwiSbiIiIiIiIyEiYZBMREREREREZCZNsIiIiIiIiIiNhkk1ERERERERkJJxd3EgyMjJw48YNU4dBDeTChQumDoGIiIiIiB4DTLKNICMjA35+/igouGvqUKiBFRcWmToEIiIiIiJqxJhkG8GNGzdQUHAXPcbPg8qtpanDoQaQmZqEs99/iJKSElOHQkREREREjRiTbCNSubWEo1c7U4dBDUCXedXUIRARERER0WOAE58RERERERERGQmTbCIiIiIiIiIjYZJNREREREREZCRMsomIiIiIiIiMhEk2ERERERERkZEwySYiIiIiIiIyEibZREREREREREbCJJuIiIiIiIjISJhkExERERERERkJk2wiIiIiIiIiI2GSTURERERERGQkTLKJiIiIiIiIjIRJNhEREREREZGRMMkmIiIiIiIiMhIm2URE9P/au/O4qMr+f/yvYZlhWGYAkS0FMU1xV0wkTS0XUD6mX/1455JLkt4ZmEqh2c8FtfK+MbcU9dZSrMDMFr1dQlFTTHFDyTVcwhsrATdAUNa5fn/4mXNz2NGBGeT1fDzOI8+53uea61wzzeE955zrIiIiIiIDYZJNREREREREZCBMsomIiIiIiIgMpEZJ9uLFi/Hiiy/Czs4Ozs7OGDp0KJKTk2UxeXl5CA4ORqNGjWBra4vhw4cjPT1dFpOamorAwEBYW1vD2dkZYWFhKCoqksUcOnQIXbp0gUqlQosWLRAVFVWmPZGRkWjWrBmsrKzg6+uLkydP1uRwiIiIiIiIiAyqRkn24cOHERwcjOPHjyMuLg6FhYUYMGAAcnNzpZgZM2Zg586d2LZtGw4fPoy//voLw4YNk8qLi4sRGBiIgoICHDt2DJs3b0ZUVBTmzZsnxaSkpCAwMBCvvPIKkpKSMH36dLz11lvYu3evFLN161aEhoZi/vz5OHPmDDp27Ah/f39kZGQ8TX8QERERERERPTGLmgTHxsbK1qOiouDs7IzExET06tULWVlZ+OKLLxATE4NXX30VALBp0yZ4e3vj+PHj6N69O/bt24dLly5h//79cHFxQadOnbBo0SLMmjUL4eHhUCqVWLduHby8vLB06VIAgLe3N3755RcsX74c/v7+AIBly5Zh0qRJePPNNwEA69atw+7du7Fx40Z88MEHT90xRERERERERDX1VM9kZ2VlAQAcHR0BAImJiSgsLES/fv2kmNatW8PDwwMJCQkAgISEBLRv3x4uLi5SjL+/P7Kzs3Hx4kUppmQd+hh9HQUFBUhMTJTFmJmZoV+/flJMefLz85GdnS1biIiIiIiIiAzliZNsnU6H6dOno0ePHmjXrh0AIC0tDUqlEvb29rJYFxcXpKWlSTElE2x9ub6sspjs7Gw8evQId+7cQXFxcbkx+jrKs3jxYmi1Wmlp2rRpzQ+ciIiIiIiIqAJPnGQHBwfjwoUL+OabbwzZnlo1e/ZsZGVlScvNmzeN3SQiImqgqjOYaJ8+faBQKGTL22+/LYsx1GCiREREZBhPlGSHhIRg165d+Pnnn9GkSRNpu6urKwoKCpCZmSmLT09Ph6urqxRTerRx/XpVMRqNBmq1Gk5OTjA3Ny83Rl9HeVQqFTQajWwhIiIyhuoMJgoAkyZNwq1bt6QlIiJCKjPUYKJERERkODVKsoUQCAkJwY8//oiDBw/Cy8tLVu7j4wNLS0scOHBA2pacnIzU1FT4+fkBAPz8/HD+/HnZKOBxcXHQaDRo06aNFFOyDn2Mvg6lUgkfHx9ZjE6nw4EDB6QYIiIiUxYbG4sJEyagbdu26NixI6KiopCamorExERZnLW1NVxdXaWl5A/E+sFEv/76a3Tq1AkDBw7EokWLEBkZiYKCAgCQDSbq7e2NkJAQ/O///i+WL19ep8dLRETUUNQoyQ4ODsbXX3+NmJgY2NnZIS0tDWlpaXj06BEAQKvVIigoCKGhofj555+RmJiIN998E35+fujevTsAYMCAAWjTpg3Gjh2LX3/9FXv37sWcOXMQHBwMlUoFAHj77bfx+++/Y+bMmfjtt9+wZs0afPvtt5gxY4bUltDQUGzYsAGbN2/G5cuXMWXKFOTm5kqjjRMREdUnpQcT1YuOjoaTkxPatWuH2bNn4+HDh1KZIQYTJSIiIsOq0RRea9euBfD4GbGSNm3ahAkTJgAAli9fDjMzMwwfPhz5+fnw9/fHmjVrpFhzc3Ps2rULU6ZMgZ+fH2xsbDB+/HgsXLhQivHy8sLu3bsxY8YMrFy5Ek2aNMHnn38uTd8FAK+//jpu376NefPmIS0tDZ06dUJsbGyZwdCIiIhMXXmDiQLA6NGj4enpCXd3d5w7dw6zZs1CcnIyfvjhBwCGGUxUrVbLyvLz85Gfny+tcyYOIiKimqlRki2EqDLGysoKkZGRiIyMrDDG09MTe/bsqbSePn364OzZs5XGhISEICQkpMo2ERERmTL9YKK//PKLbPvkyZOlf7dv3x5ubm7o27cvrl+/jueff75W2rJ48WIsWLCgVuomIiJqCJ5qnmwiIiJ6OhUNJloeX19fAMC1a9cAGGYw0dI4EwcREdHTYZJNRERkBFUNJlqepKQkAICbmxsAwwwmWhpn4iAiIno6TLKJiIiMoKrBRK9fv45FixYhMTERN27cwL///W+MGzcOvXr1QocOHQAYbjBRIiIiMhwm2UREREawdu1aZGVloU+fPnBzc5OWrVu3Ang8XeX+/fsxYMAAtG7dGu+99x6GDx+OnTt3SnXoBxM1NzeHn58f3njjDYwbN67cwUTj4uLQsWNHLF26tMxgolRzOp1O+mFEp9MZuzlERGRCajTwGRERERlGVYOJNm3aFIcPH66yHkMNJko1k5GRgQlr4gAAUe/0l56BJyIiYpJNREREzwydTic9o+7s7Awzs9q7aU9l51BrdRMRUf3F28WJiIjomaG/wjxhTZxsQDgiIqK6wivZRERE9EzhFWYiIjImXskmIiIiIiIiMhAm2UREREREREQGwiSbiIiIiIiIyED4TDYRERER6nZkciIienbx7EFEREQEjkxORESGwSvZRERERP+HI5MTEdHT4pVsIiIiIiIiIgNhkk1ERERERERkIEyyiYiIiIiIiAyESTYRERERERGRgTDJJiIiIiIiIjIQJtlEREREREREBsIkm4iIiIiIiMhAmGQTERERERERGYiFsRtAREREVF06nQ4ZGRkAAGdnZ5iZ8XoBERGZFp6ZiIiIqN7IyMjAhDVxmLAmTkq2iYiITAmvZBMREVG9orJzMHYTiIiIKsQr2UREREREREQGwiSbiIiIiIiIyECYZBMREREREREZCJNsIiIiIiIiIgNhkk1ERERERERkIEyyiYiIiIiIiAyESTYRERERERGRgTDJJiIiIiIiIjIQJtlEREREREREBsIkm4iIiIiIiMhAmGQTERERERERGQiTbCIiIiNYvHgxXnzxRdjZ2cHZ2RlDhw5FcnKyLCYvLw/BwcFo1KgRbG1tMXz4cKSnp8tiUlNTERgYCGtrazg7OyMsLAxFRUWymEOHDqFLly5QqVRo0aIFoqKiavvwiIiIGiwm2UREREZw+PBhBAcH4/jx44iLi0NhYSEGDBiA3NxcKWbGjBnYuXMntm3bhsOHD+Ovv/7CsGHDpPLi4mIEBgaioKAAx44dw+bNmxEVFYV58+ZJMSkpKQgMDMQrr7yCpKQkTJ8+HW+99Rb27t1bp8dLRETUUFgYuwFEREQNUWxsrGw9KioKzs7OSExMRK9evZCVlYUvvvgCMTExePXVVwEAmzZtgre3N44fP47u3btj3759uHTpEvbv3w8XFxd06tQJixYtwqxZsxAeHg6lUol169bBy8sLS5cuBQB4e3vjl19+wfLly+Hv71/nx11bdDodMjIykJGRAQgACmO3iIiIGipeySYiIjIBWVlZAABHR0cAQGJiIgoLC9GvXz8ppnXr1vDw8EBCQgIAICEhAe3bt4eLi4sU4+/vj+zsbFy8eFGKKVmHPkZfx7MiIyMDE9bEYVrUYRQWFRi7OURE1IDxSjYREZGR6XQ6TJ8+HT169EC7du0AAGlpaVAqlbC3t5fFuri4IC0tTYopmWDry/VllcVkZ2fj0aNHUKvVsrL8/Hzk5+dL69nZ2U9/gHVEZecAYexGEBFRg8cr2UREREYWHByMCxcu4JtvvjF2U7B48WJotVppadq0qbGbREREVK/UOMmOj4/H4MGD4e7uDoVCge3bt8vKJ0yYAIVCIVsCAgJkMffu3cOYMWOg0Whgb2+PoKAg5OTkyGLOnTuHl19+GVZWVmjatCkiIiLKtGXbtm1o3bo1rKys0L59e+zZs6emh0NERGRUISEh2LVrF37++Wc0adJE2u7q6oqCggJkZmbK4tPT0+Hq6irFlB5tXL9eVYxGoylzFRsAZs+ejaysLGm5efPmUx9jbdLpdEhLS/vvs9hERERGVuMkOzc3Fx07dkRkZGSFMQEBAbh165a0bNmyRVY+ZswYXLx4EXFxcdi1axfi4+MxefJkqTw7OxsDBgyAp6cnEhMTsWTJEoSHh2P9+vVSzLFjxzBq1CgEBQXh7NmzGDp0KIYOHYoLFy7U9JCIiIjqnBACISEh+PHHH3Hw4EF4eXnJyn18fGBpaYkDBw5I25KTk5Gamgo/Pz8AgJ+fH86fP/84wfw/cXFx0Gg0aNOmjRRTsg59jL6O0lQqFTQajWwxZXwWm4iITE2Nn8keOHAgBg4cWGmMSqWSfkEv7fLly4iNjcWpU6fQtWtXAMCqVaswaNAgfPrpp3B3d0d0dDQKCgqwceNGKJVKtG3bFklJSVi2bJmUjK9cuRIBAQEICwsDACxatAhxcXFYvXo11q1bV9PDIiIiqlPBwcGIiYnBjh07YGdnJz1DrdVqoVarodVqERQUhNDQUDg6OkKj0WDq1Knw8/ND9+7dAQADBgxAmzZtMHbsWERERCAtLQ1z5sxBcHAwVCoVAODtt9/G6tWrMXPmTEycOBEHDx7Et99+i927dxvt2A2Nz2ITEZEpqZVnsg8dOgRnZ2e0atUKU6ZMwd27d6WyhIQE2NvbSwk2APTr1w9mZmY4ceKEFNOrVy8olUopxt/fH8nJybh//74U0xBGSyUiomfT2rVrkZWVhT59+sDNzU1atm7dKsUsX74c//M//4Phw4ejV69ecHV1xQ8//CCVm5ubY9euXTA3N4efnx/eeOMNjBs3DgsXLpRivLy8sHv3bsTFxaFjx45YunQpPv/882dq+q76Sn+re1paGnQ6nbGbQ0REBmLw0cUDAgIwbNgweHl54fr16/jwww8xcOBAJCQkwNzcHGlpaXB2dpY3wsICjo6OspFQS982V3K0VAcHhwpHS9XXUZ76PGIqERE9W4So+tqrlZUVIiMjK31Ey9PTs8oxSfr06YOzZ8/WuI1Uu/S3ugNA1Dv9K7wLkIiI6heDJ9kjR46U/t2+fXt06NABzz//PA4dOoS+ffsa+uVqZPHixViwYIFR20BERESkp7JzMHYTiIjIwGp9Cq/mzZvDyckJ165dA/B4lNOSA7QAQFFREe7du2eQ0VIr+xW4vo2YSkRERERERPVLrSfZf/zxB+7evQs3NzcAj0c5zczMRGJiohRz8OBB6HQ6+Pr6SjHx8fEoLCyUYuLi4tCqVSs4ODhIMTUZLRWofyOmEhERERERUf1S4yQ7JycHSUlJSEpKAgCkpKQgKSkJqampyMnJQVhYGI4fP44bN27gwIEDGDJkCFq0aCENsOLt7Y2AgABMmjQJJ0+exNGjRxESEoKRI0fC3d0dADB69GgolUoEBQXh4sWL2Lp1K1auXInQ0FCpHdOmTUNsbCyWLl2K3377DeHh4Th9+jRCQkIM0C1ERERERERENVfjJPv06dPo3LkzOnfuDAAIDQ1F586dMW/ePJibm+PcuXN47bXX8MILLyAoKAg+Pj44cuSINJUIAERHR6N169bo27cvBg0ahJ49e8rmwNZqtdi3bx9SUlLg4+OD9957D/PmzZPNpf3SSy8hJiYG69evR8eOHfHdd99h+/btaNeu3dP0BxEREREREdETq/HAZ3369Kl0RNS9e/dWWYejoyNiYmIqjenQoQOOHDlSacyIESMwYsSIKl+PiIiIiIiIqC7U+jPZRERERERERA0Fk2wiIiIiIiIiA2GSTURERERERGQgTLKJiIiIiIiIDIRJNhEREREREZGBMMkmIiIiIiIiMhAm2UREREREREQGwiSbiIiIiIiIyECYZBMREREREREZCJNsIiIiIiIiIgOxMHYDiIiIiAxN6HTIyMgAADg7Oxu5NURE1JAwySYiIqJnTn5uFmZsOQ1LS0tEvdPf2M0hIqIGhEk2ERERPZNUdvawtFQauxlERNTA8JlsIiIiIiIiIgNhkk1ERERERERkIEyyiYiIiIiIiAyESTYRERERERGRgTDJJiIiIiIiIjIQJtlEREREREREBsIkm4iIiIiIiMhAmGQTERERERERGQiTbCIiIiIiIiIDsTB2A4iIiIhqSuh0yMjI+L8V47aFiIioJCbZREREVO/k52ZhxpbT0OXnQu30nLGbQ0REJGGSTURERPWSys4exZaWxm4GERGRDJ/JJiIiMoL4+HgMHjwY7u7uUCgU2L59u6x8woQJUCgUsiUgIEAWc+/ePYwZMwYajQb29vYICgpCTk6OLObcuXN4+eWXYWVlhaZNmyIiIqK2D42IiKhBY5JNRERkBLm5uejYsSMiIyMrjAkICMCtW7ekZcuWLbLyMWPG4OLFi4iLi8OuXbsQHx+PyZMnS+XZ2dkYMGAAPD09kZiYiCVLliA8PBzr16+vteMiIiJq6Hi7OBERkREMHDgQAwcOrDRGpVLB1dW13LLLly8jNjYWp06dQteuXQEAq1atwqBBg/Dpp5/C3d0d0dHRKCgowMaNG6FUKtG2bVskJSVh2bJlsmSciIiIDIdXsomIiEzUoUOH4OzsjFatWmHKlCm4e/euVJaQkAB7e3spwQaAfv36wczMDCdOnJBievXqBaVSKcX4+/sjOTkZ9+/fL/c18/PzkZ2dLVuIiIio+phkExERmaCAgAB8+eWXOHDgAP75z3/i8OHDGDhwIIqLiwEAaWlpcHZ2lu1jYWEBR0dHpKWlSTEuLi6yGP26Pqa0xYsXQ6vVSkvTpk0NfWhERETPNN4uTkREZIJGjhwp/bt9+/bo0KEDnn/+eRw6dAh9+/attdedPXs2QkNDpfXs7Ow6T7R1/zcHdkZGBiAAIf47J7Z+GxERkalikk1ERFQPNG/eHE5OTrh27Rr69u0LV1dXKfHUKyoqwr1796TnuF1dXZGeni6L0a9X9Ky3SqWCSqWqhSOovoyMDExYE4f8nEyonZ5DcV4uZmw5DVtHZ2TfSuG82EREZNJ4uzgREVE98Mcff+Du3btwc3MDAPj5+SEzMxOJiYlSzMGDB6HT6eDr6yvFxMfHo7CwUIqJi4tDq1at4ODgULcHUEMqOwcobe1LrNtDrW0k20ZERGSKmGQTEREZQU5ODpKSkpCUlAQASElJQVJSElJTU5GTk4OwsDAcP34cN27cwIEDBzBkyBC0aNEC/v7+AABvb28EBARg0qRJOHnyJI4ePYqQkBCMHDkS7u7uAIDRo0dDqVQiKCgIFy9exNatW7Fy5UrZ7eBERERkWEyyiYiIjOD06dPo3LkzOnfuDAAIDQ1F586dMW/ePJibm+PcuXN47bXX8MILLyAoKAg+Pj44cuSI7Fbu6OhotG7dGn379sWgQYPQs2dP2RzYWq0W+/btQ0pKCnx8fPDee+9h3rx5nL6LiIioFvGZbCIiIiPo06cPhKh4BK+9e/dWWYejoyNiYmIqjenQoQOOHDlS4/YRERHRk+GVbCIiIiIiIiIDYZJNREREREREZCBMsomIiIiIiIgMhEk2ERERERERkYEwySYiIiIiIiIyECbZRERERERERAbCJJuIiIiIiIjIQGqcZMfHx2Pw4MFwd3eHQqHA9u3bZeVCCMybNw9ubm5Qq9Xo168frl69Kou5d+8exowZA41GA3t7ewQFBSEnJ0cWc+7cObz88suwsrJC06ZNERERUaYt27ZtQ+vWrWFlZYX27dtjz549NT0cIiIiIiIiIoOpcZKdm5uLjh07IjIystzyiIgIfPbZZ1i3bh1OnDgBGxsb+Pv7Iy8vT4oZM2YMLl68iLi4OOzatQvx8fGYPHmyVJ6dnY0BAwbA09MTiYmJWLJkCcLDw7F+/Xop5tixYxg1ahSCgoJw9uxZDB06FEOHDsWFCxdqekhEREREREREBmFR0x0GDhyIgQMHllsmhMCKFSswZ84cDBkyBADw5ZdfwsXFBdu3b8fIkSNx+fJlxMbG4tSpU+jatSsAYNWqVRg0aBA+/fRTuLu7Izo6GgUFBdi4cSOUSiXatm2LpKQkLFu2TErGV65ciYCAAISFhQEAFi1ahLi4OKxevRrr1q17os4gIiIiIiIiehoGfSY7JSUFaWlp6Nevn7RNq9XC19cXCQkJAICEhATY29tLCTYA9OvXD2ZmZjhx4oQU06tXLyiVSinG398fycnJuH//vhRT8nX0MfrXKU9+fj6ys7NlCxEREREREZGhGDTJTktLAwC4uLjItru4uEhlaWlpcHZ2lpVbWFjA0dFRFlNeHSVfo6IYfXl5Fi9eDK1WKy1Nmzat6SESERERERERVahBjS4+e/ZsZGVlScvNmzeN3SQiIiIiIiJ6hhg0yXZ1dQUApKeny7anp6dLZa6ursjIyJCVFxUV4d69e7KY8uoo+RoVxejLy6NSqaDRaGQLERERERERkaEYNMn28vKCq6srDhw4IG3Lzs7GiRMn4OfnBwDw8/NDZmYmEhMTpZiDBw9Cp9PB19dXiomPj0dhYaEUExcXh1atWsHBwUGKKfk6+hj96xARERERERHVtRon2Tk5OUhKSkJSUhKAx4OdJSUlITU1FQqFAtOnT8dHH32Ef//73zh//jzGjRsHd3d3DB06FADg7e2NgIAATJo0CSdPnsTRo0cREhKCkSNHwt3dHQAwevRoKJVKBAUF4eLFi9i6dStWrlyJ0NBQqR3Tpk1DbGwsli5dit9++w3h4eE4ffo0QkJCnr5XiIiIiIiIiJ5AjafwOn36NF555RVpXZ/4jh8/HlFRUZg5cyZyc3MxefJkZGZmomfPnoiNjYWVlZW0T3R0NEJCQtC3b1+YmZlh+PDh+Oyzz6RyrVaLffv2ITg4GD4+PnBycsK8efNkc2m/9NJLiImJwZw5c/Dhhx+iZcuW2L59O9q1a/dEHUFERERERET0tGqcZPfp0wdCiArLFQoFFi5ciIULF1YY4+joiJiYmEpfp0OHDjhy5EilMSNGjMCIESMqbzARERERERFRHWlQo4sTERERERER1aYaX8kmIiIiItOi0+mk2VucnZ1hZsbrKERExsJvYCIiIqJ6LiMjAxPWxGHCmrgyU6USEVHd4pVsIiIiomeAys7B2E0gIiLwSjYRERERERGRwTDJJiIiIiIiIjIQJtlEREREREREBsIkm4iIiIiIiMhAmGQTERERERERGQiTbCIiIiIiIiIDYZJNREREREREZCBMsomIiIiIiIgMxMLYDSAiIiIyBp1Oh4yMDACAs7OzkVtDRETPCl7JJiIiMoL4+HgMHjwY7u7uUCgU2L59u6xcCIF58+bBzc0NarUa/fr1w9WrV2Ux9+7dw5gxY6DRaGBvb4+goCDk5OTIYs6dO4eXX34ZVlZWaNq0KSIiImr70OqNjIwMTFgThwlr4qRkm4iI6GkxySYiIjKC3NxcdOzYEZGRkeWWR0RE4LPPPsO6detw4sQJ2NjYwN/fH3l5eVLMmDFjcPHiRcTFxWHXrl2Ij4/H5MmTpfLs7GwMGDAAnp6eSExMxJIlSxAeHo7169fX+vHVFyo7B6jsHIzdDCIieobwdnEiIiIjGDhwIAYOHFhumRACK1aswJw5czBkyBAAwJdffgkXFxds374dI0eOxOXLlxEbG4tTp06ha9euAIBVq1Zh0KBB+PTTT+Hu7o7o6GgUFBRg48aNUCqVaNu2LZKSkrBs2TJZMk5ERESGwyvZREREJiYlJQVpaWno16+ftE2r1cLX1xcJCQkAgISEBNjb20sJNgD069cPZmZmOHHihBTTq1cvKJVKKcbf3x/Jycm4f/9+ua+dn5+P7Oxs2UJERETVxySbiIjIxKSlpQEAXFxcZNtdXFyksrS0tDKDdVlYWMDR0VEWU14dJV+jtMWLF0Or1UpL06ZNn/6AiIiIGhAm2URERCSZPXs2srKypOXmzZvGbhIREVG9wmeyiYiITIyrqysAID09HW5ubtL29PR0dOrUSYopPSJ2UVER7t27J+3v6uqK9PR0WYx+XR9TmkqlgkqlMshx1JR+Sq2MjAxAGKUJAABRamovMzNekyAiourjWYOIiMjEeHl5wdXVFQcOHJC2ZWdn48SJE/Dz8wMA+Pn5ITMzE4mJiVLMwYMHodPp4OvrK8XEx8ejsLBQiomLi0OrVq3g4GB6I2rrp9SaFnUYhUUFBqlTPEHinp+bhRlbTnNqLyIieiK8kk1ERGQEOTk5uHbtmrSekpKCpKQkODo6wsPDA9OnT8dHH32Eli1bwsvLC3PnzoW7uzuGDh0KAPD29kZAQAAmTZqEdevWobCwECEhIRg5ciTc3d0BAKNHj8aCBQsQFBSEWbNm4cKFC1i5ciWWL19ujEOuFpWdg0EvYusTZl1+LtROz0Fd7XbYw9JSWXUgERFRKUyyiYiIjOD06dN45ZVXpPXQ0FAAwPjx4xEVFYWZM2ciNzcXkydPRmZmJnr27InY2FhYWVlJ+0RHRyMkJAR9+/aFmZkZhg8fjs8++0wq12q12LdvH4KDg+Hj4wMnJyfMmzevwU3fpbKzR7GlpbGbQUREDQSTbCIiIiPo06cPhKj4mq1CocDChQuxcOHCCmMcHR0RExNT6et06NABR44ceeJ2EhERUc0wySYiIiJ6QhwkjYiISuOZgIiIiOgJcZA0IiIqjVeyiYiIiJ4CB0kjIqKSeCWbiIiIiIiIyEB4JZuIiIjIwHR8VpuIqMFikk1ERERUiSdJmDMyMjBhTRwAIOqd/nB1da3VNhIRkelgkk1ERERUiSdNmFV2DrXZLCIiMlFMsomIiIiqwISZiIiqiw8IERERERERERkIr2QTERFRgyZKPHMNYdy2EBFR/cckm4iIiBq0/NwszNhyGrr8XKidnjN2c4iIqJ5jkk1EREQNnsrOHsWWlsZuBhERPQP4TDYRERERERGRgTDJJiIiIiIiIjIQJtlEREREREREBsJnsomIiIhqScmRy52dnWFmxusbRETPOn7TExEREdUS/cjlE9bE/XeaMCIieqbxSjYRERFRLVLZ2cPSUmnsZhARUR3hlWwiIiIiIiIiAzF4kh0eHg6FQiFbWrduLZXn5eUhODgYjRo1gq2tLYYPH4709HRZHampqQgMDIS1tTWcnZ0RFhaGoqIiWcyhQ4fQpUsXqFQqtGjRAlFRUYY+FCIiIiIiIqIaqZUr2W3btsWtW7ek5ZdffpHKZsyYgZ07d2Lbtm04fPgw/vrrLwwbNkwqLy4uRmBgIAoKCnDs2DFs3rwZUVFRmDdvnhSTkpKCwMBAvPLKK0hKSsL06dPx1ltvYe/evbVxOERERERERETVUivPZFtYWMDV1bXM9qysLHzxxReIiYnBq6++CgDYtGkTvL29cfz4cXTv3h379u3DpUuXsH//fri4uKBTp05YtGgRZs2ahfDwcCiVSqxbtw5eXl5YunQpAMDb2xu//PILli9fDn9//9o4JCIiIiIiIqIq1cqV7KtXr8Ld3R3NmzfHmDFjkJqaCgBITExEYWEh+vXrJ8W2bt0aHh4eSEhIAAAkJCSgffv2cHFxkWL8/f2RnZ2NixcvSjEl69DH6OuoSH5+PrKzs2ULERERERERkaEYPMn29fVFVFQUYmNjsXbtWqSkpODll1/GgwcPkJaWBqVSCXt7e9k+Li4uSEtLAwCkpaXJEmx9ub6sspjs7Gw8evSowrYtXrwYWq1WWpo2bfq0h0tERERUIzqdDmlpaY+n9BLGbg0RERmawW8XHzhwoPTvDh06wNfXF56envj222+hVqsN/XI1Mnv2bISGhkrr2dnZTLSJiIioTmVkZGDCmjjk52RC7fQcp/ciInrG1PoUXvb29njhhRdw7do1uLq6oqCgAJmZmbKY9PR06RluV1fXMqON69eritFoNJUm8iqVChqNRrYQERER1TWVnQOUtvbGbka59Ffa09LSoNPpjN0cIqJ6p9aT7JycHFy/fh1ubm7w8fGBpaUlDhw4IJUnJycjNTUVfn5+AAA/Pz+cP3/+8S1U/ycuLg4ajQZt2rSRYkrWoY/R10FERET1h6nePi10OmRkZJhcu2qb/kr7hDVxsr/HiIioegx+u/j777+PwYMHw9PTE3/99Rfmz58Pc3NzjBo1ClqtFkFBQQgNDYWjoyM0Gg2mTp0KPz8/dO/eHQAwYMAAtGnTBmPHjkVERATS0tIwZ84cBAcHQ6VSAQDefvttrF69GjNnzsTEiRNx8OBBfPvtt9i9e7ehD4eIiIhqWenbp01Ffm4WZmw5DV1+boO7rVtl52DsJhAR1VsGT7L/+OMPjBo1Cnfv3kXjxo3Rs2dPHD9+HI0bNwYALF++HGZmZhg+fDjy8/Ph7++PNWvWSPubm5tj165dmDJlCvz8/GBjY4Px48dj4cKFUoyXlxd2796NGTNmYOXKlWjSpAk+//xzTt9FRERUT6nsHEzyYrHKzh7FlpbGbgYREdUjBk+yv/nmm0rLraysEBkZicjIyApjPD09sWfPnkrr6dOnD86ePftEbSQiIiKqL3T/d9s6ADg7O8PMrNaf9iMioqfAb2kiIiITFR4eDoVCIVtat24tlefl5SE4OBiNGjWCra0thg8fXmZg0NTUVAQGBsLa2hrOzs4ICwtDUVFRXR+KSalvz1rzGWkiovrF4FeyiYiIyHDatm2L/fv3S+sWFv89dc+YMQO7d+/Gtm3boNVqERISgmHDhuHo0aMAgOLiYgQGBsLV1RXHjh3DrVu3MG7cOFhaWuKTTz6p82MxFaWfta4P+Iw0EVH9wSSbiIjIhFlYWEhTWJaUlZWFL774AjExMXj11VcBAJs2bYK3tzeOHz+O7t27Y9++fbh06RL2798PFxcXdOrUCYsWLcKsWbMQHh4OpbLhDORVGp+1JiKi2sLbxYmIiEzY1atX4e7ujubNm2PMmDFITU0FACQmJqKwsBD9+vWTYlu3bg0PDw8kJCQAABISEtC+fXu4uLhIMf7+/sjOzsbFixfr9kAaCFOdjoyIiOoOr2QTERGZKF9fX0RFRaFVq1a4desWFixYgJdffhkXLlxAWloalEol7O3tZfu4uLggLS0NAJCWliZLsPXl+rLy5OfnIz8/X1rPzs424BE9+0x1OjIiIqo7TLKJiIhM1MCBA6V/d+jQAb6+vvD09MS3334LtVpdK6+5ePFiLFiwoFbqbihMdToyIiKqG7xdnIiIqJ6wt7fHCy+8gGvXrsHV1RUFBQXIzMyUxaSnp0vPcLu6upYZbVy/Xt5z3gAwe/ZsZGVlScvNmzcNfyBERETPMCbZRERE9UROTg6uX78ONzc3+Pj4wNLSEgcOHJDKk5OTkZqaCj8/PwCAn58fzp8/L5v2KS4uDhqNBm3atCn3NVQqFTQajWyhx/RTf/GZayIiqgxvFyciIjJR77//PgYPHgxPT0/89ddfmD9/PszNzTFq1ChotVoEBQUhNDQUjo6O0Gg0mDp1Kvz8/NC9e3cAwIABA9CmTRuMHTsWERERSEtLw5w5cxAcHAyVSmXko6t/9FN/2To6I/tWSo2eudYn6ACYoBMRPeOYZBMREZmoP/74A6NGjcLdu3fRuHFj9OzZE8ePH0fjxo0BAMuXL4eZmRmGDx+O/Px8+Pv7Y82aNdL+5ubm2LVrF6ZMmQI/Pz/Y2Nhg/PjxWLhwobEOqd5T2dlDrW2EvAf3a7Tf0yTo9ZGuxI8Kzs7OMDPjzZNE1HAwySYiIjJR33zzTaXlVlZWiIyMRGRkZIUxnp6e2LNnj6GbRk/gSRP0+kg/yjoARL3Tv8IxAIiInkVMsomIiIieUsnbwXkr+GMqOwdjN4GIyCiYZBMRERE9Jf3t4Lr83Gf+VnAiIqock2wiIiIiA1DZ2aPY0tLYzSAiIiPjKBREREREREREBsIkm4iIiIiIiMhAeLs4ERERkQnST4MlzautMHaLiIioOphkExEREZkg/TRY+TmZUDs9B0tLpbGbRERE1cAkm4iIiMhEqewcOCMYEVE9wySbiIiIiEyWrsQc5M7OzjAz45BCRGTa+C1FRERERCZLf9v8hDVxUrJNRGTKeCWbiIiIiEx6oDWVnYOxm0BEVG1MsomIiIiecdW55ZoDrRERGQaTbCIiIqJnnD6BBoCod/rD1dW13DgOtEZE9PSYZBMRERE1ALzl2jA4EBsRVYVJNhEREVE9UzrRo7pT3bsCiKjhYpJNREREZAJqkjiXTvSobvGuACKqDJNsIiIiIhNQ08SZiR4RkWlikk1ERERkIipLnEWJK92mOM0WERE9xiSbiIiIqB7Iz83CjC2nYevojOxbKZxmi4jIRDHJJiIiIqPQP4MsXZWlKqns7KHWNkLeg/vGbgoREVWASTYREREZhf4Z5PycTKidnjN2c4iIiAyCSTYREREZjcrOgRexqc5wjmsiqgtMsomISrh8+bKxm0C1yMnJCR4eHsZuBlGlSg5w9rS/QJS5Jb+BD5TGOa6JqC4wySYiAvAo6y4ABd544w1jN4VqkVptjd9+u8xEm0yafoAzXX5ulbfRl0nI/y+JLplcz9z2K/JzH9+Sb2Fu8d94mMbV3Lq+usypz4iotjHJJiICUPjwAQCBTqNnobFXa2M3h2pB9q0bOLFxAe7cucMkm0yeys4exZaWVcaVTsj1o42Xft5dqZDH2zo6I//B/Se6mlsyKQaePjHm1WUietYwySYiKsHW2QOOHq2M3QwiomqrKCGv6Hl3/QjlejUd5V2fFKvsHJ44US+vrfRk+Jw5kelhkk1ERETUgD3JKO8qOwdZok7GwzsBiEwPk2wiIiIiIzLkQGdPiqO812+8E4DItDDJJiIiIjKimgx0ZkimkNzTs423stcvfL8Mh0k2ERERkZFVd6CzqtQkcTZWck+m61kf1I5JZOVM7f2qz5hkExERUZ2q6UBbVH01TZyrk9zr3y+dTgcAuHPnjvS+iVJJCwCDzctdkzm+62vyZGrtNsVB7QzZR0wiq8ZHDwyj3ifZkZGRWLJkCdLS0tCxY0esWrUK3bp1M3aziIiITIopnS+fZKAtqj5DXxUvOde2mcpGSuDV+G9Sb2lpiah3+gOA7L3VTylWOlECIK2XTqIrmuNbX1d56mvyZIrtNrVB7QzdR0wiqS7U6yR769atCA0Nxbp16+Dr64sVK1bA398fycnJ0hc4ERFRQ2cq58uSyZPKlgNtmbrSV8WVCsDcyqZMAq+ys4eFuYWUNJf33pZOlABIV0yzb6VUa47v0kom7vrP1NNcOS+v3rq4usykr2rsI6pv6nWSvWzZMkyaNAlvvvkmAGDdunXYvXs3Nm7ciA8++MDIrSMiIjINpnK+5BXs+qe6V8Uruk295O3kKlsHCCFfV2sbIe/B/fJjK3it0le6VZr/Juolk/2SCXJNbj3Xf06F0GHJiM5wcnKSlUu3y9fR7eumdku5qbXHWAzRD+zLZ1e9TbILCgqQmJiI2bNnS9vMzMzQr18/JCQkGLFlREREpsPUzpecKurZVV5CXjr5Ls7Lla2rK4ktrbzb19VOz8kSdX0dFhbmsgT5zp07sn30ybj+OXMzMzPZM+cqWwfk5dyX2qO/Tb7k7fJV1TFz268QKD9R1ysvYS+deD1N0l/6eXo9MzOzMrftV/eulopu365OwlhVTHkDr9VUyTpKH3dVP5BU1r6K3heg5rexl/6hCIonvxW+qve4smNgUl976m2SfefOHRQXF8PFxUW23cXFBb/99lu5++Tn5yM/P19az8rKAgBkZ2c/VVtycnIAAPf+k4yi/EdPVReZpuxb/wEAZP15FZYWBrgXjUwO3+NnX3ZaKoDH39lP+72v318I008Xa3q+rK1zJQA8ePAAuXf+Qn5OZpmkpTr/RXERHt699UT7mkodxn5949XxCLl3bpVZL7+O0rH//e/k1eehK3gEtaNbpXUUZOdi8uqd0BU8gplSXWafknWZKdWwsW+EBxl/lIr9b3vMYCb7b03qKN2O0v9VO7rB0tISv//+Ox48eIDbt29j5te/AAAi3ugJACjKf4T8nMwK6ypdh56+roKH2bJ9LCwspbpLv1bunb9QmPcQBTmZZerT16n/e7dkeel2N27cGLdv30bunb+k2N9//71MTOm6Z379C1S2GuTnZMvaVPr1KlKyjpLvR1V9VdExVFSmf1+q267yXqfgYXal7alpXeW9x5UdQ3n9r+/rBw8ewNrausbtKak+nSsNTtRTf/75pwAgjh07JtseFhYmunXrVu4+8+fPF3j8+xUXLly4cOHy1MvNmzfr4pT3VGp6vuS5kgsXLly4GHKpD+dKQ6u3V7KdnJxgbm6O9PR02fb09PQKb7WYPXs2QkNDpXWdTod79+6hUaNGUCh45aq6srOz0bRpU9y8eRMajcbYzaFawvf52cf3+MkJIfDgwQO4u7sbuylVqun50pDnSn7GqsY+qh72U9XYR9XDfqqaofqoPp0rDa3eJtlKpRI+Pj44cOAAhg4dCuDxHwIHDhxASEhIufuoVCqoVCrZNnt7+1pu6bNLo9Hwy6kB4Pv87ON7/GS0Wq2xm1AtNT1f1sa5kp+xqrGPqof9VDX2UfWwn6pmiD6qL+dKQ6u3STYAhIaGYvz48ejatSu6deuGFStWIDc3Vxo9lYiIiHi+JCIiqkv1Osl+/fXXcfv2bcybNw9paWno1KkTYmNjywzuQkRE1JDxfElERFR36nWSDQAhISEV3h5OtUOlUmH+/PllbiekZwvf52cf3+OGxRjnS37GqsY+qh72U9XYR9XDfqoa++jpKYRoiGOqExERERERERkeZyAnIiIiIiIiMhAm2UREREREREQGwiT7GdCsWTOsWLHC2M2gWtCnTx9Mnz7d4PWGh4ejU6dOBq+XqkehUGD79u3GboZkwoQJ0tRORERERPR0mGSbkAkTJkChUEChUECpVKJFixZYuHAhioqKKt3v1KlTmDx5ssHacePGDSgUCiQlJRmszmdZyfet5BIQEFDtOg4dOgSFQoHMzEzZ9h9++AGLFi0ycIvrh//85z9Qq9XIyckxSH119bm+ffs2pkyZAg8PD6hUKri6usLf3x9Hjx6t1dclMjWRkZFo1qwZrKys4Ovri5MnTxq7SXVm8eLFePHFF2FnZwdnZ2cMHToUycnJspi8vDwEBwejUaNGsLW1xfDhw5Geni6LSU1NRWBgIKytreHs7IywsLAq/yaor/7xj39AoVDIflhmHz32559/4o033kCjRo2gVqvRvn17nD59WioXQmDevHlwc3ODWq1Gv379cPXqVVkd9+7dw5gxY6DRaGBvb4+goCCDnV9NQXFxMebOnQsvLy+o1Wo8//zzWLRoEUoOPdXQ+ik+Ph6DBw+Gu7t7uT/uG6o/zp07h5dffhlWVlZo2rQpIiIiavvQ6gUm2SYmICAAt27dwtWrV/Hee+8hPDwcS5YsKTe2oKAAANC4cWNYW1vXZTOfmL7Nzxr9+1Zy2bJly1PX6+joCDs7uwrLn9X+BIAdO3bglVdega2trbGbUiPDhw/H2bNnsXnzZly5cgX//ve/0adPH9y9e7dWX7cuPwvFxcXQ6XR19npU/2zduhWhoaGYP38+zpw5g44dO8Lf3x8ZGRnGblqdOHz4MIKDg3H8+HHExcWhsLAQAwYMQG5urhQzY8YM7Ny5E9u2bcPhw4fx119/YdiwYVJ5cXExAgMDUVBQgGPHjmHz5s2IiorCvHnzjHFIterUqVP417/+hQ4dOsi2s4+A+/fvo0ePHrC0tMRPP/2ES5cuYenSpXBwcJBiIiIi8Nlnn2HdunU4ceIEbGxs4O/vj7y8PClmzJgxuHjxIuLi4rBr1y7Ex8cb9AKNsf3zn//E2rVrsXr1aly+fBn//Oc/ERERgVWrVkkxDa2fcnNz0bFjR0RGRpZbboj+yM7OxoABA+Dp6YnExEQsWbIE4eHhWL9+fa0fn8kTZDLGjx8vhgwZItvWv39/0b17d1n5Rx99JNzc3ESzZs2EEEJ4enqK5cuXCyGEGDVqlPjb3/4mq6OgoEA0atRIbN68WQghxE8//SR69OghtFqtcHR0FIGBgeLatWtSPADZ0rt3b6lsw4YNonXr1kKlUolWrVqJyMjISo+pd+/eIjg4WEybNk00atRI9OnTRwghxKFDh8SLL74olEqlcHV1FbNmzRKFhYXSfnl5eWLq1KmicePGQqVSiR49eoiTJ09K5T///LMAIGJjY0WnTp2ElZWVeOWVV0R6errYs2ePaN26tbCzsxOjRo0Subm51ej9J1fe+1YaALFhwwYxdOhQoVarRYsWLcSOHTuEEEKkpKSU6fPx48cLIR7337Rp06R6PD09xcKFC8XYsWOFnZ2dFHfkyBHRs2dPYWVlJZo0aSKmTp0qcnJyKmzP/PnzRceOHcWXX34pPD09hUajEa+//rrIzs6WYmrrPSguLhaffPKJaNasmbCyshIdOnQQ27ZtK9PGV199Vaxdu1YIIcTJkydFv379RKNGjYRGoxG9evUSiYmJZfp4zZo1IiAgQFhZWQkvLy9ZvZV9rg3l/v37AoA4dOhQpXGVfR6EEKKoqEhMnDhR6qMXXnhBrFixQlZHRd8HqampYsSIEUKr1QoHBwfx2muviZSUFFndM2bMkP7/DwsLE+PGjav0M7xp0yah1WrFjh07hLe3tzA3NxcpKSni3r17YuzYscLe3l6o1WoREBAgrly5Itv3u+++E23atBFKpVJ4enqKTz/9VFbu6ekpFi1aJMaOHStsbGyEh4eH2LFjh8jIyBCvvfaasLGxEe3btxenTp2qtE/JtHTr1k0EBwdL68XFxcLd3V0sXrzYiK0ynoyMDAFAHD58WAghRGZmprC0tJR9R12+fFkAEAkJCUIIIfbs2SPMzMxEWlqaFLN27Vqh0WhEfn5+3R5ALXrw4IFo2bKliIuLk53z2EePzZo1S/Ts2bPCcp1OJ1xdXcWSJUukbZmZmUKlUoktW7YIIYS4dOmSACD7Hv3pp5+EQqEQf/75Z+01vg4FBgaKiRMnyrYNGzZMjBkzRgjBfgIgfvzxR2ndUP2xZs0a4eDgIPv/bdasWaJVq1a1fESmj0m2CSkvWXvttddEly5dpHJbW1sxduxYceHCBXHhwgUhhDzJ3rVrl1Cr1eLBgwdSHTt37hRqtVpKoL777jvx/fffi6tXr4qzZ8+KwYMHi/bt24vi4mIhxOOEBoDYv3+/uHXrlrh7964QQoivv/5auLm5ie+//178/vvv4vvvvxeOjo4iKiqqwmPq3bu3sLW1FWFhYeK3334Tv/32m/jjjz+EtbW1eOedd8Tly5fFjz/+KJycnMT8+fOl/d59913h7u4u9uzZIy5evCjGjx8vHBwcpLboE7zu3buLX375RZw5c0a0aNFC9O7dWwwYMECcOXNGxMfHi0aNGol//OMfT/6mVEN1k+wmTZqImJgYcfXqVfHuu+8KW1tbcffuXVFUVCS+//57AUAkJyeLW7duiczMTCFE+Um2RqMRn376qbh27Zq02NjYiOXLl4srV66Io0ePis6dO4sJEyZU2J758+cLW1tbMWzYMHH+/HkRHx8vXF1dxYcffijF1NZ78NFHH4nWrVuL2NhYcf36dbFp0yahUqlkien9+/eFUqmUvsQPHDggvvrqK3H58mVx6dIlERQUJFxcXGQ/CgAQjRo1Ehs2bBDJyclizpw5wtzcXFy6dEkIUfHn2pAKCwuFra2tmD59usjLy6swrrLPgxCPfxibN2+eOHXqlPj999/F119/LaytrcXWrVulOsr7PigoKBDe3t5i4sSJ4ty5c+LSpUti9OjRolWrVtIJ8J///KdwcHAQ33//vdSXdnZ2VSbZlpaW4qWXXhJHjx4Vv/32m8jNzRWvvfaa8Pb2FvHx8SIpKUn4+/uLFi1aiIKCAiGEEKdPnxZmZmZi4cKFIjk5WWzatEmo1WqxadMmqW5PT0/h6Ogo1q1bJ65cuSKmTJkiNBqNCAgIEN9++61ITk4WQ4cOFd7e3kKn0z3Fu0N1JT8/X5ibm8v+oBNCiHHjxonXXnvNOI0ysqtXrwoA4vz580KIx99pAMT9+/dlcR4eHmLZsmVCCCHmzp0rOnbsKCv//fffBQBx5syZumh2nRg3bpyYPn26EEJ+zmMfPebt7S2mT58u/vd//1c0btxYdOrUSaxfv14qv379ugAgzp49K9uvV69e4t133xVCCPHFF18Ie3t7WXlhYaEwNzcXP/zwQ60fQ134+OOPhaenp0hOThZCCJGUlCScnZ3F119/LYRgP5VOsg3VH2PHji3z98PBgwcFAHHv3j2DH0d9wiTbhJRM1nQ6nYiLixMqlUq8//77UrmLi0uZX2dLJtmFhYXCyclJfPnll1L5qFGjxOuvv17h696+fVt28tdfWS39P97zzz8vYmJiZNsWLVok/Pz8Kqy7d+/eonPnzrJtH374oWjVqpXsD+bIyEhha2sriouLRU5OjrC0tBTR0dFSeUFBgXB3dxcRERFCiP8mePv375diFi9eLACI69evS9v+/ve/C39//wrbZwjjx48X5ubmwsbGRrZ8/PHHUgwAMWfOHGk9JydHABA//fST7HhK/zFRXpI9dOhQWUxQUJCYPHmybNuRI0eEmZmZePToUbltnj9/vrC2tpYlqWFhYcLX11dqX228B3l5ecLa2locO3aszDGMGjVKWo+OjhZdu3Ytt+1CPL4qZmdnJ3bu3CltAyDefvttWZyvr6+YMmWKEKLiz7Whfffdd8LBwUFYWVmJl156ScyePVv8+uuvspiqPg/lCQ4OFsOHD5fWy/s++Oqrr8r8v5Wfny/UarXYu3evEEIINzc36T0U4vF3RpMmTapMsgGIpKQkaduVK1cEAHH06FFp2507d4RarRbffvutEEKI0aNHi/79+8vqCgsLE23atJHWPT09xRtvvCGt37p1SwAQc+fOlbYlJCQIAOLWrVsVtpFMx59//ikAlPn/PCwsTHTr1s1IrTKe4uJiERgYKHr06CFti46OFkqlskzsiy++KGbOnCmEEGLSpEliwIABsvLc3FwBQOzZs6d2G11HtmzZItq1ayedq0qe89hHj6lUKqFSqcTs2bPFmTNnxL/+9S9hZWUlXeA4evSoACD++usv2X4jRoyQ7mz8+OOPxQsvvFCm7saNG4s1a9bU/kHUgeLiYjFr1iyhUCiEhYWFUCgU4pNPPpHKG3o/lU6yDdUf/fv3L/M36MWLFwUA6SJHQ2XxdDebk6Ht2rULtra2KCwshE6nw+jRoxEeHi6Vt2/fHkqlssL9LSws8Le//Q3R0dEYO3YscnNzsWPHDnzzzTdSzNWrVzFv3jycOHECd+7ckZ6tTE1NRbt27cqtNzc3F9evX0dQUBAmTZokbS8qKoJWq630mHx8fGTrly9fhp+fHxQKhbStR48eyMnJwR9//IHMzEwUFhaiR48eUrmlpSW6deuGy5cvy+oq+fyWi4sLrK2t0bx5c9m2uhhs55VXXsHatWtl2xwdHWXrJdtqY2MDjUbzRM8ndu3aVbb+66+/4ty5c4iOjpa2CSGg0+mQkpICb2/vcutp1qyZ7HlvNzc3qT3Xr1+vlffg2rVrePjwIfr37y+ro6CgAJ07d5bWd+zYgddee01aT09Px5w5c3Do0CFkZGSguLgYDx8+RGpqqqwePz+/Mut1PYDf8OHDERgYiCNHjuD48eP46aefEBERgc8//xwTJkyQ4qr6PERGRmLjxo1ITU3Fo0ePUFBQUGZE+NLfB7/++iuuXbtW5jn+vLw8XL9+HVlZWbh16xZ8fX2lMgsLC3Tt2lU2OEx5lEqlrM2XL1+GhYWFrK5GjRqhVatW0mfk8uXLGDJkiKyeHj16YMWKFSguLoa5uXmZvnBxcZGOrfS2jIwMuLq6VtpOIlMTHByMCxcu4JdffjF2U0zKzZs3MW3aNMTFxcHKysrYzTFZOp0OXbt2xSeffAIA6Ny5My5cuIB169Zh/PjxRm6d6fj2228RHR2NmJgYtG3bFklJSZg+fTrc3d3ZT2QUTLJNjD5ZUyqVcHd3h4WF/C2ysbGpso4xY8agd+/eyMjIQFxcHNRqtWyk68GDB8PT0xMbNmyAu7s7dDod2rVrV+nASfqRBDds2CD7oxqA9IdyRarT5idlaWkp/VuhUMjW9dvqYoAmGxsbtGjRotIYQ7WtdH/m5OTg73//O959990ysR4eHrXenpq8B/rP0e7du/Hcc8/J4lQqFYDHCXdsbCw+/PBDqWz8+PG4e/cuVq5cCU9PT6hUKvj5+ZnswG9WVlbo378/+vfvj7lz5+Ktt97C/PnzZUl2Zf30zTff4P3338fSpUvh5+cHOzs7LFmyBCdOnJDtU95nwcfHR/aDi17jxo2f6pjUarXshzFDKv0ZqmgbB1urH5ycnGBubl5mFOj09PQG9yNJSEiINFhQkyZNpO2urq4oKChAZmYm7O3tpe0l+8jV1bXMj8T6Pn0W+jExMREZGRno0qWLtK24uBjx8fFYvXo19u7d2+D7CHj8A3ibNm1k27y9vfH9998D+O9xpqenw83NTYpJT0+Xfph1dXUt86N+UVER7t2798z0U1hYGD744AOMHDkSwOMfav/zn/9g8eLFGD9+PPupFEP1h6ura7nf9SVfo6Hi6OImRp+seXh4lEmwq+ull15C06ZNsXXrVkRHR2PEiBHSH6x3795FcnIy5syZg759+8Lb2xv379+X7a+/MlZcXCxtc3Fxgbu7O37//Xe0aNFCtnh5edWofd7e3khISJBdOTt69Cjs7OzQpEkTPP/881AqlbIpjwoLC3Hq1KkyJ5pnRXl9Xl1dunTBpUuXyrwvLVq0qPSuh8rU1nvQpk0bqFQqpKamlmlr06ZNATyezszBwQEdO3aU9jt69CjeffddDBo0CG3btoVKpcKdO3fK1H/8+PEy6/or+U/Tx0+rTZs2slGFq3L06FG89NJLeOedd9C5c2e0aNEC169fr3K/Ll264OrVq3B2di7Tv1qtFlqtFm5ubrJkvaioCImJiTU+Jm9vbxQVFcnq0n+/6D8j3t7eZaYuO3r0KF544YUqf5yj+kupVMLHxwcHDhyQtul0Ohw4cKDM3SbPKiEEQkJC8OOPP+LgwYNlzpM+Pj6wtLSU9VFycjJSU1OlPvLz88P58+dlf+TGxcVBo9E8E+fCvn374vz580hKSpKWrl27YsyYMdK/G3ofAY/v/ik9/duVK1fg6ekJAPDy8oKrq6usn7Kzs3HixAlZP2VmZsq+6w8ePAidTlfmwkl99fDhQ5iZydMac3Nz6cdZ9pOcofrDz88P8fHxKCwslGLi4uLQqlUr2Qj4DRGvZD+jRo8ejXXr1uHKlSv4+eefpe0ODg5o1KgR1q9fDzc3N6SmpuKDDz6Q7evs7Ay1Wo3Y2Fg0adIEVlZW0Gq1WLBgAd59911otVoEBAQgPz8fp0+fxv379xEaGlrttr3zzjtYsWIFpk6dipCQECQnJ2P+/PkIDQ2FmZkZbGxsMGXKFISFhcHR0REeHh6IiIjAw4cPERQUZLA+MqT8/HykpaXJtllYWMDJyala+3t6ekKhUGDXrl0YNGgQ1Gp1taeumjVrFrp3746QkBC89dZbsLGxwaVLlxAXF4fVq1fX+FgA1Np7YGdnh/fffx8zZsyATqdDz549kZWVhaNHj0Kj0WD8+PH497//LbtVHABatmyJr776Cl27dkV2djbCwsKgVqvL1L9t2zZ07doVPXv2RHR0NE6ePIkvvvgCQMWfa0O6e/cuRowYgYkTJ6JDhw6ws7PD6dOnERERUea26cq0bNkSX375Jfbu3QsvLy989dVXOHXqVJU/aI0ZMwZLlizBkCFDsHDhQjRp0gT/+c9/8MMPP2DmzJlo0qQJpk2bhn/84x9o2bIlWrdujWXLlpWZn726bRwyZAgmTZqEf/3rX7Czs8MHH3yA5557TjrW9957Dy+++CIWLVqE119/HQkJCVi9ejXWrFlT49ej+iU0NBTjx49H165d0a1bN6xYsQK5ubl48803jd20OhEcHIyYmBjs2LEDdnZ20vlBq9VCrVZDq9UiKCgIoaGhcHR0hEajwdSpU+Hn54fu3bsDAAYMGIA2bdpg7NixiIiIQFpaGubMmYPg4GDpzp/6zM7OrswjajY2NmjUqJG0vaH3EfB4GrOXXnoJn3zyCf72t7/h5MmTWL9+vTRFkn5u8Y8++ggtW7aEl5cX5s6dC3d3dwwdOhTA4x88AwICMGnSJKxbtw6FhYUICQnByJEj4e7ubsSjM5zBgwfj448/hoeHB9q2bYuzZ89i2bJlmDhxIoCG2U85OTm4du2atJ6SkoKkpCTp7zpD9Mfo0aOxYMECBAUFYdasWbhw4QJWrlyJ5cuXG+OQTYtxHwmnkqoapbqi8pIDn+nph9339PQsMyJvXFyc8Pb2FiqVSnTo0EEcOnSozIAIGzZsEE2bNhVmZmayqY6io6NFp06dhFKpFA4ODqJXr16VjrhYeuAuvaqm8Hr06JGYOnWqcHJyqnT6qJIDhemnGSpJP1VVbRo/fnyZ6aEAyKYvKN2/Qgih1WploywvXLhQuLq6CoVCUekUXqXfayEej5zdv39/YWtrK2xsbESHDh1kA6+VVl6/LF++XHh6ekrrtfUe6HQ6sWLFCtGqVSthaWkpGjduLPz9/aWpbZo2bSri4uJkdZw5c0Z07dpVWFlZiZYtW4pt27aV6QsAIjIyUvTv31+oVCrRrFkz2WjcQlT8uTaUvLw88cEHH4guXboIrVYrrK2tRatWrcScOXPEw4cPZW2t7POQl5cnJkyYILRarbC3txdTpkwRH3zwgawfK/o+uHXrlhg3bpz0vjVv3lxMmjRJZGVlCSEeD3Q2bdo0odFohL29vQgNDa32FF6l6afw0mq1Qq1WC39//wqn8LK0tBQeHh6y6UKEKP8zXbp/6mrQOjKsVatWCQ8PD6FUKkW3bt3E8ePHjd2kOlPeOQGA7Dv/0aNH4p133hEODg7C2tpa/L//9//KDO5348YNMXDgQKFWq4WTk5N47733ZOfKZ03pcx776LGdO3eKdu3aCZVKJVq3bi0bXVyIx+fVuXPnChcXF6FSqUTfvn2lUbb17t69K0aNGiVsbW2FRqMRb775pmwmmvouOztbTJs2TXh4eAgrKyvRvHlz8f/9f/+fbHDQhtZP+r/TSi/6vzEN1R+//vqr6Nmzp1CpVOK5556r9Vl96guFEFWMdkNEVEfOnDmDV199Fbdv3y7zzHJVFAoFfvzxR+kXWCIiIiIiY+Az2URkMoqKirBq1aoaJ9hERERERKaCz2QTkcno1q0bunXrZuxmEBERERE9MSbZRPRM4JMvRERERGQKeLs4ERERERERkYEwySYiIiIiIiIyECbZRERERERERAbCJJuIiIiIiIjIQJhkExERERERERkIk2wiIiIiohq4ceMGFAoFkpKSjN0UIjJBCsF5b4iohvr06YNOnTphxYoVxm4KERFRnSsuLsbt27fh5OQECwvOiEtEcrySTWTCCgoKjN0EIiIiKqGgoADm5uZwdXVlgk1E5WKSTWRC+vTpg5CQEEyfPh1OTk7w9/fH4cOH0a1bN6hUKri5ueGDDz5AUVGRtE9+fj7effddODs7w8rKCj179sSpU6ek8kOHDkGhUGDv3r3o3Lkz1Go1Xn31VWRkZOCnn36Ct7c3NBoNRo8ejYcPH1bZxgkTJuDw4cNYuXIlFAoFFAoFUlJS0KJFC3z66aey2KSkJCgUCly7dg0AoFAosHbtWgwcOBBqtRrNmzfHd999J9vn5s2b+Nvf/gZ7e3s4OjpiyJAhuHHjxlP0KhERUcX0596QkBBotVo4OTlh7ty50N/s2axZMyxatAjjxo2DRqPB5MmTy71d/OLFi/if//kfaDQa2NnZ4eWXX8b169el8s8//xze3t6wsrJC69atsWbNmro+VCKqI0yyiUzM5s2boVQqcfToUYSHh2PQoEF48cUX8euvv2Lt2rX44osv8NFHH0nxM2fOxPfff4/NmzfjzJkzaNGiBfz9/XHv3j1ZveHh4Vi9ejWOHTsmJbIrVqxATEwMdu/ejX379mHVqlVVtm/lypXw8/PDpEmTcOvWLdy6dQseHh6YOHEiNm3aJIvdtGkTevXqhRYtWkjb5s6di+HDh+PXX3/FmDFjMHLkSFy+fBkAUFhYCH9/f9jZ2eHIkSM4evQobG1tERAQwKv6RERUazZv3gwLCwucPHkSK1euxLJly/D5559L5Z9++ik6duyIs2fPYu7cuWX2//PPP9GrVy+oVCocPHgQiYmJmDhxovSjeHR0NObNm4ePP/4Yly9fxieffIK5c+di8+bNdXaMRFSHBBGZjN69e4vOnTtL6x9++KFo1aqV0Ol00rbIyEhha2sriouLRU5OjrC0tBTR0dFSeUFBgXB3dxcRERFCCCF+/vlnAUDs379film8eLEAIK5fvy5t+/vf/y78/f2r3c5p06bJtv3555/C3NxcnDhxQmqHk5OTiIqKkmIAiLffflu2n6+vr5gyZYoQQoivvvqqzPHm5+cLtVot9u7dW622ERER1UTv3r2Ft7e37Nwza9Ys4e3tLYQQwtPTUwwdOlS2T0pKigAgzp49K4QQYvbs2cLLy0sUFBSU+xrPP/+8iImJkW1btGiR8PPzM+CREJGp4JVsIhPj4+Mj/fvy5cvw8/ODQqGQtvXo0QM5OTn4448/cP36dRQWFqJHjx5SuaWlJbp16yZdHdbr0KGD9G8XFxdYW1ujefPmsm0ZGRlP3G53d3cEBgZi48aNAICdO3ciPz8fI0aMkMX5+fmVWde39ddff8W1a9dgZ2cHW1tb2NrawtHREXl5ebJb7oiIiAype/fusnOtn58frl69iuLiYgBA165dK90/KSkJL7/8MiwtLcuU5ebm4vr16wgKCpLObba2tvjoo494biN6RnG0BiITY2NjUyv1ljzxKxSKMn8IKBQK6HS6p3qNt956C2PHjsXy5cuxadMmvP7667C2tq72/jk5OfDx8UF0dHSZssaNGz9V24iIiJ5UVedmtVpdYVlOTg4AYMOGDfD19ZWVmZubP33jiMjk8Eo2kQnz9vZGQkKCNPgKABw9ehR2dnZo0qQJnn/+een5bb3CwkKcOnUKbdq0qbV2KZVK6df9kgYNGgQbGxusXbsWsbGxmDhxYpmY48ePl1n39vYGAHTp0gVXr16Fs7MzWrRoIVu0Wm3tHAwRETV4J06ckK0fP34cLVu2rHYS3KFDBxw5cgSFhYVlylxcXODu7o7ff/+9zLnNy8vLIO0nItPCJJvIhL3zzju4efMmpk6dit9++w07duzA/PnzERoaCjMzM9jY2GDKlCkICwtDbGwsLl26hEmTJuHhw4cICgqqtXY1a9YMJ06cwI0bN3Dnzh3pCri5uTkmTJiA2bNno2XLlmVuDQeAbdu2YePGjbhy5Qrmz5+PkydPIiQkBAAwZswYODk5YciQIThy5AhSUlJw6NAhvPvuu/jjjz9q7XiIiKhhS01NRWhoKJKTk7FlyxasWrUK06ZNq/b+ISEhyM7OxsiRI3H69GlcvXoVX331FZKTkwEACxYswOLFi/HZZ5/hypUrOH/+PDZt2oRly5bV1iERkRExySYyYc899xz27NmDkydPomPHjnj77bcRFBSEOXPmSDH/+Mc/MHz4cIwdOxZdunTBtWvXsHfvXjg4ONRau95//32Ym5ujTZs2aNy4MVJTU6WyoKAgFBQU4M033yx33wULFuCbb75Bhw4d8OWXX2LLli3SVXdra2vEx8fDw8MDw4YNg7e3N4KCgpCXlweNRlNrx0NERA3buHHj8OjRI3Tr1g3BwcGYNm0aJk+eXO39GzVqhIMHDyInJwe9e/eGj48PNmzYID2a9dZbb+Hzzz/Hpk2b0L59e/Tu3RtRUVG8kk30jFKIkvehEhE9pSNHjqBv3764efMmXFxcZGUKhQI//vgjhg4dapzGERERldKnTx906tQJK1asMHZTiOgZwYHPiMgg8vPzcfv2bYSHh2PEiBFlEmwiIiIiooaAt4sTkUxqaqpsipHSS8lbw0vasmULPD09kZmZiYiIiDpuNRERERGRaeDt4kQkU1RUhBs3blRY3qxZM1hY8CYYIiIiIqLyMMkmIiIiIiIiMhDeLk5ERERERERkIEyyiYiIiIiIiAyESTYRERERERGRgTDJJiIiIiIiIjIQJtlEREREREREBsIkm4iIiIiIiMhAmGQTERERERERGQiTbCIiIiIiIiID+f8B6ca4iVlxZVwAAAAASUVORK5CYII=",
                        "text/plain": [
                            "<Figure size 1000x700 with 4 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "fig, axis = plt.subplots(2, 2, figsize = (10, 7))\n",
                "\n",
                "# histograma múltiple\n",
                "sns.histplot(ax = axis[0, 0], data = data, x = \"neighbourhood_group\").set(ylabel=None)\n",
                "sns.histplot(ax = axis[0, 1], data = data, x = \"neighbourhood\").set(ylabel = None)\n",
                "sns.histplot(ax = axis[1, 0], data = data, x = \"room_type\").set(ylabel = None)\n",
                "sns.histplot(ax = axis[1, 1], data = data, x = \"price\").set(ylabel = None)\n",
                "\n",
                "# Rotar nombres del eje x en el subplot neighbourhood\n",
                "\n",
                "#axis[0, 1].set_xticklabels(axis[0, 1].get_xticklabels(), rotation=45)\n",
                "\n",
                "# Ajustar el layout\n",
                "plt.tight_layout()\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 1000x500 with 2 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
                "\n",
                "ax[0].hist(data['price'], bins=30, color='blue')\n",
                "ax[0].set_title(\"Histrograma Precios\")\n",
                "ax[0].set_xlabel('Precio')\n",
                "ax[0].set_ylabel('Frecuencia')\n",
                "\n",
                "ax[1].boxplot(data['price'], vert=False)\n",
                "ax[1].set_title(\"Boxplot Precio\")\n",
                "ax[1].set_xlabel(\"Precio\")\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 1000x500 with 2 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "data['price_log'] = np.log(data.price)\n",
                "\n",
                "# figura -subplots (histograma y boxplot)\n",
                "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
                "\n",
                "ax[0].hist(data['price_log'], bins=30, color='blue', edgecolor='black')\n",
                "ax[0].set_title('Histograma de precios')\n",
                "ax[0].set_xlabel('Precio')\n",
                "ax[0].set_ylabel('Frecuencia')\n",
                "\n",
                "ax[1].boxplot(data['price_log'], vert=False)\n",
                "ax[1].set_title('Boxplot de precios')\n",
                "ax[1].set_xlabel('Precio')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0         Brooklyn\n",
                            "1        Manhattan\n",
                            "2        Manhattan\n",
                            "3         Brooklyn\n",
                            "4        Manhattan\n",
                            "           ...    \n",
                            "48640     Brooklyn\n",
                            "48641     Brooklyn\n",
                            "48642    Manhattan\n",
                            "48643    Manhattan\n",
                            "48644    Manhattan\n",
                            "Name: neighbourhood_group, Length: 48645, dtype: object"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# data.info()\n",
                "# data.nunique()\n",
                "data['neighbourhood_group']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# * OneHotEncoder: es una clase de scikit-learn que se utiliza para convertir variables categóricas en representaciones numéricas.\n",
                "# Crea columnas de variables dummy para cada categoría única en la variable categórica original.\n",
                "\n",
                "# * drop='first': este parámetro se utiliza para evitar la multicolinealidad (cuando dos o más variables predictoras están altamente correlacionadas entre sí).\n",
                "# En la codificación one-hot, se produce cuando una columna de variables dummy se puede predecir linealmente a partir de las otras columnas de variables dummy. Al especificar drop='first', le decimos a OneHotEncoder que elimine la primera columna de variables dummy para cada característica categórica.\n",
                "# Esto elimina la multicolinealidad, ya que la primera columna de variables dummy se puede deducir de las otras columnas.\n",
                "\n",
                "# * sparse=False: eeste parámetro sparse=False se utiliza para indicar que no queremos que el resultado sea una matriz dispersa (sparse matrix)\n",
                "# Por defecto, OneHotEncoder devuelve una matriz dispersa, que es eficiente en cuanto al uso de memoria cuando hay muchas categorías únicas.\n",
                "# Sin embargo, en este caso, especificamos sparse=False para obtener una matriz densa, que es más fácil de manejar y manipular en el contexto del análisis y modelado de datos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>price</th>\n",
                            "      <th>minimum_nights</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "      <th>price_log</th>\n",
                            "      <th>neighbourhood</th>\n",
                            "      <th>neighbourhood_group</th>\n",
                            "      <th>room_type</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>40.65</td>\n",
                            "      <td>-73.97</td>\n",
                            "      <td>149</td>\n",
                            "      <td>1</td>\n",
                            "      <td>6</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>108</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>40.75</td>\n",
                            "      <td>-73.98</td>\n",
                            "      <td>225</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>355</td>\n",
                            "      <td>5.42</td>\n",
                            "      <td>127</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>150</td>\n",
                            "      <td>3</td>\n",
                            "      <td>1</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.01</td>\n",
                            "      <td>94</td>\n",
                            "      <td>2</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>40.69</td>\n",
                            "      <td>-73.96</td>\n",
                            "      <td>89</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>194</td>\n",
                            "      <td>4.49</td>\n",
                            "      <td>41</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>40.80</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>80</td>\n",
                            "      <td>10</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>4.38</td>\n",
                            "      <td>61</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48640</th>\n",
                            "      <td>40.68</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>70</td>\n",
                            "      <td>2</td>\n",
                            "      <td>2</td>\n",
                            "      <td>9</td>\n",
                            "      <td>4.25</td>\n",
                            "      <td>13</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48641</th>\n",
                            "      <td>40.70</td>\n",
                            "      <td>-73.93</td>\n",
                            "      <td>40</td>\n",
                            "      <td>4</td>\n",
                            "      <td>2</td>\n",
                            "      <td>36</td>\n",
                            "      <td>3.69</td>\n",
                            "      <td>28</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48642</th>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>115</td>\n",
                            "      <td>10</td>\n",
                            "      <td>1</td>\n",
                            "      <td>27</td>\n",
                            "      <td>4.74</td>\n",
                            "      <td>94</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48643</th>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.99</td>\n",
                            "      <td>55</td>\n",
                            "      <td>1</td>\n",
                            "      <td>6</td>\n",
                            "      <td>2</td>\n",
                            "      <td>4.01</td>\n",
                            "      <td>95</td>\n",
                            "      <td>2</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48644</th>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.99</td>\n",
                            "      <td>90</td>\n",
                            "      <td>7</td>\n",
                            "      <td>1</td>\n",
                            "      <td>23</td>\n",
                            "      <td>4.50</td>\n",
                            "      <td>95</td>\n",
                            "      <td>2</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>48645 rows × 10 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       latitude  longitude  price  minimum_nights  \\\n",
                            "0         40.65     -73.97    149               1   \n",
                            "1         40.75     -73.98    225               1   \n",
                            "2         40.81     -73.94    150               3   \n",
                            "3         40.69     -73.96     89               1   \n",
                            "4         40.80     -73.94     80              10   \n",
                            "...         ...        ...    ...             ...   \n",
                            "48640     40.68     -73.95     70               2   \n",
                            "48641     40.70     -73.93     40               4   \n",
                            "48642     40.81     -73.95    115              10   \n",
                            "48643     40.76     -73.99     55               1   \n",
                            "48644     40.76     -73.99     90               7   \n",
                            "\n",
                            "       calculated_host_listings_count  availability_365  price_log  \\\n",
                            "0                                   6               365       5.00   \n",
                            "1                                   2               355       5.42   \n",
                            "2                                   1               365       5.01   \n",
                            "3                                   1               194       4.49   \n",
                            "4                                   1                 0       4.38   \n",
                            "...                               ...               ...        ...   \n",
                            "48640                               2                 9       4.25   \n",
                            "48641                               2                36       3.69   \n",
                            "48642                               1                27       4.74   \n",
                            "48643                               6                 2       4.01   \n",
                            "48644                               1                23       4.50   \n",
                            "\n",
                            "       neighbourhood  neighbourhood_group  room_type  \n",
                            "0                108                    1          1  \n",
                            "1                127                    2          0  \n",
                            "2                 94                    2          1  \n",
                            "3                 41                    1          0  \n",
                            "4                 61                    2          0  \n",
                            "...              ...                  ...        ...  \n",
                            "48640             13                    1          1  \n",
                            "48641             28                    1          1  \n",
                            "48642             94                    2          0  \n",
                            "48643             95                    2          2  \n",
                            "48644             95                    2          1  \n",
                            "\n",
                            "[48645 rows x 10 columns]"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "\n",
                "# Columnas a codificar con OneHotEncoder:\n",
                "# Convertir la Serie en un DataFrame de una sola columna\n",
                "\n",
                "# columna_onehot = pd.DataFrame(data['room_type'])\n",
                "\n",
                "# OH_encoder = OneHotEncoder()  # Inicializa el codificador OneHotEncoder\n",
                "\n",
                "# columna_OH = OH_encoder.fit_transform(columna_onehot) # Columnas que nos interesan codificadas\n",
                "\n",
                "# nombre_columna_OH = OH_encoder.get_feature_names_out(['room_type'])  # Nombre de las columnas codificadas\n",
                "\n",
                "# oh_data = pd.DataFrame(columna_OH.toarray(), columns=nombre_columna_OH)  # método toarray() convierte la matriz dispersa resultado de fit_transform()\n",
                "                                                                            # en una matriz densa, para crear el DataFrame oh_data con la forma correcta.\n",
                "\n",
                "\n",
                "# Columna a codificar con LabelEncoder:\n",
                "\n",
                "columnas_etiqueta = ['neighbourhood', 'neighbourhood_group', 'room_type']\n",
                "\n",
                "label_encoder = LabelEncoder() # Inicializa el codificador LabelEncoder\n",
                "\n",
                "for columna in columnas_etiqueta:\n",
                "    data[columna] = label_encoder.fit_transform(data[columna])  # Aplica LabelEncoder a las columnas seleccionadas\n",
                "\n",
                "# Añadir la columna codificada al DataFrame original\n",
                "# (dataframe original sin las columnas colificadas + dataframe de las columnas onehot + columnas etiquetada\n",
                "data_encoded = pd.concat([data.drop(columnas_etiqueta, axis=1), data[columnas_etiqueta]], axis=1)\n",
                "data_encoded\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Variables independientes/dependiente\n",
                "X = data_encoded.drop(['price', 'price_log'], axis=1)\n",
                "y = data_encoded['price_log']\n",
                "\n",
                "# Ajusta el modelo\n",
                "X = sm.add_constant(X)\n",
                "model = sm.OLS(y, X).fit()\n",
                "\n",
                "# Instancia de la influencia y obtención de la distancia de cook para cada observación\n",
                "cooks_distance = model.get_influence().cooks_distance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 1000x500 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "plt.figure(figsize=(10, 5))\n",
                "plt.scatter(data.price, cooks_distance[0])\n",
                "plt.xlabel('x')\n",
                "plt.ylabel('Cooks Distance')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>neighbourhood_group</th>\n",
                            "      <th>neighbourhood</th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>room_type</th>\n",
                            "      <th>price</th>\n",
                            "      <th>minimum_nights</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "      <th>price_log</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>2843</th>\n",
                            "      <td>2</td>\n",
                            "      <td>6</td>\n",
                            "      <td>40.71</td>\n",
                            "      <td>-74.02</td>\n",
                            "      <td>0</td>\n",
                            "      <td>400</td>\n",
                            "      <td>1000</td>\n",
                            "      <td>1</td>\n",
                            "      <td>362</td>\n",
                            "      <td>5.99</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5727</th>\n",
                            "      <td>2</td>\n",
                            "      <td>92</td>\n",
                            "      <td>40.73</td>\n",
                            "      <td>-74.00</td>\n",
                            "      <td>0</td>\n",
                            "      <td>180</td>\n",
                            "      <td>1250</td>\n",
                            "      <td>1</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.19</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>13334</th>\n",
                            "      <td>2</td>\n",
                            "      <td>94</td>\n",
                            "      <td>40.83</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>0</td>\n",
                            "      <td>99</td>\n",
                            "      <td>999</td>\n",
                            "      <td>1</td>\n",
                            "      <td>42</td>\n",
                            "      <td>4.60</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>26211</th>\n",
                            "      <td>1</td>\n",
                            "      <td>214</td>\n",
                            "      <td>40.72</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>1</td>\n",
                            "      <td>79</td>\n",
                            "      <td>999</td>\n",
                            "      <td>6</td>\n",
                            "      <td>249</td>\n",
                            "      <td>4.37</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>38476</th>\n",
                            "      <td>2</td>\n",
                            "      <td>92</td>\n",
                            "      <td>40.73</td>\n",
                            "      <td>-74.00</td>\n",
                            "      <td>2</td>\n",
                            "      <td>110</td>\n",
                            "      <td>999</td>\n",
                            "      <td>1</td>\n",
                            "      <td>365</td>\n",
                            "      <td>4.70</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       neighbourhood_group  neighbourhood  latitude  longitude  room_type  \\\n",
                            "2843                     2              6     40.71     -74.02          0   \n",
                            "5727                     2             92     40.73     -74.00          0   \n",
                            "13334                    2             94     40.83     -73.94          0   \n",
                            "26211                    1            214     40.72     -73.95          1   \n",
                            "38476                    2             92     40.73     -74.00          2   \n",
                            "\n",
                            "       price  minimum_nights  calculated_host_listings_count  \\\n",
                            "2843     400            1000                               1   \n",
                            "5727     180            1250                               1   \n",
                            "13334     99             999                               1   \n",
                            "26211     79             999                               6   \n",
                            "38476    110             999                               1   \n",
                            "\n",
                            "       availability_365  price_log  \n",
                            "2843                362       5.99  \n",
                            "5727                365       5.19  \n",
                            "13334                42       4.60  \n",
                            "26211               249       4.37  \n",
                            "38476               365       4.70  "
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.where(cooks_distance[0]>0.05)\n",
                "data.iloc[[2843, 5727, 13334, 26211, 38476,]]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>minimum_nights</th>\n",
                            "      <th>price</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>minimum_nights</th>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.02</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>price</th>\n",
                            "      <td>0.02</td>\n",
                            "      <td>1.00</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                minimum_nights  price\n",
                            "minimum_nights            1.00   0.02\n",
                            "price                     0.02   1.00"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data_encoded.corr()\n",
                "data[['minimum_nights', 'price']].corr()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>neighbourhood_group</th>\n",
                            "      <th>neighbourhood</th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>room_type</th>\n",
                            "      <th>price</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "      <th>price_log</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1</td>\n",
                            "      <td>108</td>\n",
                            "      <td>40.65</td>\n",
                            "      <td>-73.97</td>\n",
                            "      <td>1</td>\n",
                            "      <td>149</td>\n",
                            "      <td>6</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2</td>\n",
                            "      <td>127</td>\n",
                            "      <td>40.75</td>\n",
                            "      <td>-73.98</td>\n",
                            "      <td>0</td>\n",
                            "      <td>225</td>\n",
                            "      <td>2</td>\n",
                            "      <td>355</td>\n",
                            "      <td>5.42</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>2</td>\n",
                            "      <td>94</td>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>1</td>\n",
                            "      <td>150</td>\n",
                            "      <td>1</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.01</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>1</td>\n",
                            "      <td>41</td>\n",
                            "      <td>40.69</td>\n",
                            "      <td>-73.96</td>\n",
                            "      <td>0</td>\n",
                            "      <td>89</td>\n",
                            "      <td>1</td>\n",
                            "      <td>194</td>\n",
                            "      <td>4.49</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>2</td>\n",
                            "      <td>61</td>\n",
                            "      <td>40.80</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>0</td>\n",
                            "      <td>80</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>4.38</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48640</th>\n",
                            "      <td>1</td>\n",
                            "      <td>13</td>\n",
                            "      <td>40.68</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>1</td>\n",
                            "      <td>70</td>\n",
                            "      <td>2</td>\n",
                            "      <td>9</td>\n",
                            "      <td>4.25</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48641</th>\n",
                            "      <td>1</td>\n",
                            "      <td>28</td>\n",
                            "      <td>40.70</td>\n",
                            "      <td>-73.93</td>\n",
                            "      <td>1</td>\n",
                            "      <td>40</td>\n",
                            "      <td>2</td>\n",
                            "      <td>36</td>\n",
                            "      <td>3.69</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48642</th>\n",
                            "      <td>2</td>\n",
                            "      <td>94</td>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>0</td>\n",
                            "      <td>115</td>\n",
                            "      <td>1</td>\n",
                            "      <td>27</td>\n",
                            "      <td>4.74</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48643</th>\n",
                            "      <td>2</td>\n",
                            "      <td>95</td>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.99</td>\n",
                            "      <td>2</td>\n",
                            "      <td>55</td>\n",
                            "      <td>6</td>\n",
                            "      <td>2</td>\n",
                            "      <td>4.01</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48644</th>\n",
                            "      <td>2</td>\n",
                            "      <td>95</td>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.99</td>\n",
                            "      <td>1</td>\n",
                            "      <td>90</td>\n",
                            "      <td>1</td>\n",
                            "      <td>23</td>\n",
                            "      <td>4.50</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>48645 rows × 9 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       neighbourhood_group  neighbourhood  latitude  longitude  room_type  \\\n",
                            "0                        1            108     40.65     -73.97          1   \n",
                            "1                        2            127     40.75     -73.98          0   \n",
                            "2                        2             94     40.81     -73.94          1   \n",
                            "3                        1             41     40.69     -73.96          0   \n",
                            "4                        2             61     40.80     -73.94          0   \n",
                            "...                    ...            ...       ...        ...        ...   \n",
                            "48640                    1             13     40.68     -73.95          1   \n",
                            "48641                    1             28     40.70     -73.93          1   \n",
                            "48642                    2             94     40.81     -73.95          0   \n",
                            "48643                    2             95     40.76     -73.99          2   \n",
                            "48644                    2             95     40.76     -73.99          1   \n",
                            "\n",
                            "       price  calculated_host_listings_count  availability_365  price_log  \n",
                            "0        149                               6               365       5.00  \n",
                            "1        225                               2               355       5.42  \n",
                            "2        150                               1               365       5.01  \n",
                            "3         89                               1               194       4.49  \n",
                            "4         80                               1                 0       4.38  \n",
                            "...      ...                             ...               ...        ...  \n",
                            "48640     70                               2                 9       4.25  \n",
                            "48641     40                               2                36       3.69  \n",
                            "48642    115                               1                27       4.74  \n",
                            "48643     55                               6                 2       4.01  \n",
                            "48644     90                               1                23       4.50  \n",
                            "\n",
                            "[48645 rows x 9 columns]"
                        ]
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data.drop('minimum_nights', axis=1, inplace=True)\n",
                "data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>price</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "      <th>price_log</th>\n",
                            "      <th>neighbourhood</th>\n",
                            "      <th>neighbourhood_group</th>\n",
                            "      <th>room_type</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>40.65</td>\n",
                            "      <td>-73.97</td>\n",
                            "      <td>149</td>\n",
                            "      <td>6</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>108</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>40.75</td>\n",
                            "      <td>-73.98</td>\n",
                            "      <td>225</td>\n",
                            "      <td>2</td>\n",
                            "      <td>355</td>\n",
                            "      <td>5.42</td>\n",
                            "      <td>127</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>150</td>\n",
                            "      <td>1</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.01</td>\n",
                            "      <td>94</td>\n",
                            "      <td>2</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>40.69</td>\n",
                            "      <td>-73.96</td>\n",
                            "      <td>89</td>\n",
                            "      <td>1</td>\n",
                            "      <td>194</td>\n",
                            "      <td>4.49</td>\n",
                            "      <td>41</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>40.80</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>80</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>4.38</td>\n",
                            "      <td>61</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48640</th>\n",
                            "      <td>40.68</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>70</td>\n",
                            "      <td>2</td>\n",
                            "      <td>9</td>\n",
                            "      <td>4.25</td>\n",
                            "      <td>13</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48641</th>\n",
                            "      <td>40.70</td>\n",
                            "      <td>-73.93</td>\n",
                            "      <td>40</td>\n",
                            "      <td>2</td>\n",
                            "      <td>36</td>\n",
                            "      <td>3.69</td>\n",
                            "      <td>28</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48642</th>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>115</td>\n",
                            "      <td>1</td>\n",
                            "      <td>27</td>\n",
                            "      <td>4.74</td>\n",
                            "      <td>94</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48643</th>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.99</td>\n",
                            "      <td>55</td>\n",
                            "      <td>6</td>\n",
                            "      <td>2</td>\n",
                            "      <td>4.01</td>\n",
                            "      <td>95</td>\n",
                            "      <td>2</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48644</th>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.99</td>\n",
                            "      <td>90</td>\n",
                            "      <td>1</td>\n",
                            "      <td>23</td>\n",
                            "      <td>4.50</td>\n",
                            "      <td>95</td>\n",
                            "      <td>2</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>48645 rows × 9 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       latitude  longitude  price  calculated_host_listings_count  \\\n",
                            "0         40.65     -73.97    149                               6   \n",
                            "1         40.75     -73.98    225                               2   \n",
                            "2         40.81     -73.94    150                               1   \n",
                            "3         40.69     -73.96     89                               1   \n",
                            "4         40.80     -73.94     80                               1   \n",
                            "...         ...        ...    ...                             ...   \n",
                            "48640     40.68     -73.95     70                               2   \n",
                            "48641     40.70     -73.93     40                               2   \n",
                            "48642     40.81     -73.95    115                               1   \n",
                            "48643     40.76     -73.99     55                               6   \n",
                            "48644     40.76     -73.99     90                               1   \n",
                            "\n",
                            "       availability_365  price_log  neighbourhood  neighbourhood_group  \\\n",
                            "0                   365       5.00            108                    1   \n",
                            "1                   355       5.42            127                    2   \n",
                            "2                   365       5.01             94                    2   \n",
                            "3                   194       4.49             41                    1   \n",
                            "4                     0       4.38             61                    2   \n",
                            "...                 ...        ...            ...                  ...   \n",
                            "48640                 9       4.25             13                    1   \n",
                            "48641                36       3.69             28                    1   \n",
                            "48642                27       4.74             94                    2   \n",
                            "48643                 2       4.01             95                    2   \n",
                            "48644                23       4.50             95                    2   \n",
                            "\n",
                            "       room_type  \n",
                            "0              1  \n",
                            "1              0  \n",
                            "2              1  \n",
                            "3              0  \n",
                            "4              0  \n",
                            "...          ...  \n",
                            "48640          1  \n",
                            "48641          1  \n",
                            "48642          0  \n",
                            "48643          2  \n",
                            "48644          1  \n",
                            "\n",
                            "[48645 rows x 9 columns]"
                        ]
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data_encoded.drop('minimum_nights', axis=1, inplace=True)\n",
                "data_encoded"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "latitude                         0.24\n",
                            "longitude                        1.29\n",
                            "price                            2.94\n",
                            "calculated_host_listings_count   7.92\n",
                            "availability_365                 0.77\n",
                            "price_log                        0.31\n",
                            "neighbourhood                    0.26\n",
                            "neighbourhood_group              0.38\n",
                            "room_type                        0.42\n",
                            "dtype: float64"
                        ]
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Aplicamos la función skew() a cada columna del DataFrame para calcular su sesgo:\n",
                "\n",
                "data_encoded.apply(lambda x: x.skew())   # La función skew() calcula el sesgo (skewness) de una distribución de datos.\n",
                "                                         # El sesgo es una medida de la asimetría de la distribución de datos con respecto a la media.\n",
                "\n",
                "# Si el sesgo es cero, significa que la distribución es simétrica. \n",
                "# Si el sesgo es positivo, la distribución tiene una cola larga hacia la derecha,\n",
                "# Si es negativo, la cola larga se encuentra hacia la izquierda."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Windsorización: técnica de preprocesamiento de datos que se utiliza para tratar los valores atípicos mediante SU modificación\n",
                "#  * para que caigan dentro de un rango predefinido, en lugar de eliminarlos por completo.\n",
                "# Esto ayuda a suavizar la distribución de los datos y a mitigar el efecto de los valores extremos en el análisis estadístico."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convertimos las columnas binarias a int32: 0 y 1 son los únicos valores que contendrán y están dentro del rango de int32\n",
                "# Ocupa menos memoria\n",
                "\n",
                "# dtype_c = ['room_type_Entire home/apt',\n",
                "#           'room_type_Private room',\n",
                "#          'room_type_Shared room']\n",
                "\n",
                "# data_encoded[dtype_c] = data_encoded[dtype_c].astype(np.int32)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "False"
                        ]
                    },
                    "execution_count": 28,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data_encoded.isnull().any().any()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>price</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "      <th>price_log</th>\n",
                            "      <th>neighbourhood</th>\n",
                            "      <th>neighbourhood_group</th>\n",
                            "      <th>room_type</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>40.65</td>\n",
                            "      <td>-73.97</td>\n",
                            "      <td>149</td>\n",
                            "      <td>6</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>108</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>40.75</td>\n",
                            "      <td>-73.98</td>\n",
                            "      <td>225</td>\n",
                            "      <td>2</td>\n",
                            "      <td>355</td>\n",
                            "      <td>5.42</td>\n",
                            "      <td>127</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>150</td>\n",
                            "      <td>1</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.01</td>\n",
                            "      <td>94</td>\n",
                            "      <td>2</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>40.69</td>\n",
                            "      <td>-73.96</td>\n",
                            "      <td>89</td>\n",
                            "      <td>1</td>\n",
                            "      <td>194</td>\n",
                            "      <td>4.49</td>\n",
                            "      <td>41</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>40.80</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>80</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>4.38</td>\n",
                            "      <td>61</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48640</th>\n",
                            "      <td>40.68</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>70</td>\n",
                            "      <td>2</td>\n",
                            "      <td>9</td>\n",
                            "      <td>4.25</td>\n",
                            "      <td>13</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48641</th>\n",
                            "      <td>40.70</td>\n",
                            "      <td>-73.93</td>\n",
                            "      <td>40</td>\n",
                            "      <td>2</td>\n",
                            "      <td>36</td>\n",
                            "      <td>3.69</td>\n",
                            "      <td>28</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48642</th>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>115</td>\n",
                            "      <td>1</td>\n",
                            "      <td>27</td>\n",
                            "      <td>4.74</td>\n",
                            "      <td>94</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48643</th>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.99</td>\n",
                            "      <td>55</td>\n",
                            "      <td>6</td>\n",
                            "      <td>2</td>\n",
                            "      <td>4.01</td>\n",
                            "      <td>95</td>\n",
                            "      <td>2</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48644</th>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.99</td>\n",
                            "      <td>90</td>\n",
                            "      <td>1</td>\n",
                            "      <td>23</td>\n",
                            "      <td>4.50</td>\n",
                            "      <td>95</td>\n",
                            "      <td>2</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>48645 rows × 9 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       latitude  longitude  price  calculated_host_listings_count  \\\n",
                            "0         40.65     -73.97    149                               6   \n",
                            "1         40.75     -73.98    225                               2   \n",
                            "2         40.81     -73.94    150                               1   \n",
                            "3         40.69     -73.96     89                               1   \n",
                            "4         40.80     -73.94     80                               1   \n",
                            "...         ...        ...    ...                             ...   \n",
                            "48640     40.68     -73.95     70                               2   \n",
                            "48641     40.70     -73.93     40                               2   \n",
                            "48642     40.81     -73.95    115                               1   \n",
                            "48643     40.76     -73.99     55                               6   \n",
                            "48644     40.76     -73.99     90                               1   \n",
                            "\n",
                            "       availability_365  price_log  neighbourhood  neighbourhood_group  \\\n",
                            "0                   365       5.00            108                    1   \n",
                            "1                   355       5.42            127                    2   \n",
                            "2                   365       5.01             94                    2   \n",
                            "3                   194       4.49             41                    1   \n",
                            "4                     0       4.38             61                    2   \n",
                            "...                 ...        ...            ...                  ...   \n",
                            "48640                 9       4.25             13                    1   \n",
                            "48641                36       3.69             28                    1   \n",
                            "48642                27       4.74             94                    2   \n",
                            "48643                 2       4.01             95                    2   \n",
                            "48644                23       4.50             95                    2   \n",
                            "\n",
                            "       room_type  \n",
                            "0              1  \n",
                            "1              0  \n",
                            "2              1  \n",
                            "3              0  \n",
                            "4              0  \n",
                            "...          ...  \n",
                            "48640          1  \n",
                            "48641          1  \n",
                            "48642          0  \n",
                            "48643          2  \n",
                            "48644          1  \n",
                            "\n",
                            "[48645 rows x 9 columns]"
                        ]
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Seleccionamos las columnas no binarias: \n",
                "# Se identifican las columnas del DataFrame que contienen valores binarios (0 o 1) y se eliminan del DataFrame.\n",
                "# La windsorización se aplica típicamente a datos numéricos continuos, y las columnas binarias no requieren windsorización.\n",
                "\n",
                "binarias = data_encoded.columns[data_encoded.isin([0, 1]).all()]\n",
                "\n",
                "windsorizar_datos = data_encoded.drop(binarias, axis=1)\n",
                "windsorizar_datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Función para calcular IQR (rango intercuartílico) y aplicar winsorización\n",
                "\n",
                "def windsorizar_columnas(column, lower, upper):   # lower, upper: estos parámetro especifican los percentiles inferior y superior usados para calcular el rango intercuartílico (IQR)\n",
                "    q1 = column.quantile(lower)  # Se calculan los percentiles lower y upper de la columna utilizando el método quantile() de Pandas.\n",
                "    q3 = column.quantile(upper)\n",
                "    iqr_value = q3-q1   # El IQR se calcula restando el primer cuartil (q1) del tercer cuartil (q3)\n",
                "\n",
                "    # Calculamos los límites de windsorizacion: los valores extremos, que están más allá de 1.5 veces el IQR de los cuartiles,\n",
                "    # se recorten para mitigar su influencia en el análisis estadístico\n",
                "    lower_limit = q1 - 1.5 * iqr_value    # 1.5 veces el rango intercuartílico (IQR) como criterio para calcular los límites de winsorización \n",
                "    upper_limit = q3 + 1.5 * iqr_value    # es un estándar comúnmente aceptado en análisis estadístico \n",
                "    \n",
                "    column = column.clip(lower=lower_limit, upper=upper_limit)  # método clip() de Pandas para recortar los valores de la columna\n",
                "    return column\n",
                "\n",
                "# Calcular el IQR y aplicar winsorización a cada columna del dataframe:\n",
                "\n",
                "for columna in windsorizar_datos.columns:\n",
                "    windsorizar_datos[columna] = windsorizar_columnas(windsorizar_datos[columna], 0.25, 0.75)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "latitude                         0.24\n",
                            "longitude                        0.53\n",
                            "price                            1.03\n",
                            "calculated_host_listings_count   1.15\n",
                            "availability_365                 0.77\n",
                            "price_log                        0.28\n",
                            "neighbourhood                    0.26\n",
                            "neighbourhood_group              0.28\n",
                            "room_type                        0.42\n",
                            "dtype: float64"
                        ]
                    },
                    "execution_count": 31,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "windsorizar_datos.apply(lambda x: x.skew())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>price</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "      <th>price_log</th>\n",
                            "      <th>neighbourhood</th>\n",
                            "      <th>neighbourhood_group</th>\n",
                            "      <th>room_type</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>40.65</td>\n",
                            "      <td>-73.97</td>\n",
                            "      <td>149</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>108</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>40.75</td>\n",
                            "      <td>-73.98</td>\n",
                            "      <td>225</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>355</td>\n",
                            "      <td>5.42</td>\n",
                            "      <td>127</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>150</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.01</td>\n",
                            "      <td>94</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>40.69</td>\n",
                            "      <td>-73.96</td>\n",
                            "      <td>89</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>194</td>\n",
                            "      <td>4.49</td>\n",
                            "      <td>41</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>40.80</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>80</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0</td>\n",
                            "      <td>4.38</td>\n",
                            "      <td>61</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48640</th>\n",
                            "      <td>40.68</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>70</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>9</td>\n",
                            "      <td>4.25</td>\n",
                            "      <td>13</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48641</th>\n",
                            "      <td>40.70</td>\n",
                            "      <td>-73.93</td>\n",
                            "      <td>40</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>36</td>\n",
                            "      <td>3.69</td>\n",
                            "      <td>28</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48642</th>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>115</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>27</td>\n",
                            "      <td>4.74</td>\n",
                            "      <td>94</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48643</th>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.99</td>\n",
                            "      <td>55</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>2</td>\n",
                            "      <td>4.01</td>\n",
                            "      <td>95</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48644</th>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.99</td>\n",
                            "      <td>90</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>23</td>\n",
                            "      <td>4.50</td>\n",
                            "      <td>95</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>48645 rows × 9 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       latitude  longitude  price  calculated_host_listings_count  \\\n",
                            "0         40.65     -73.97    149                            3.50   \n",
                            "1         40.75     -73.98    225                            2.00   \n",
                            "2         40.81     -73.94    150                            1.00   \n",
                            "3         40.69     -73.96     89                            1.00   \n",
                            "4         40.80     -73.94     80                            1.00   \n",
                            "...         ...        ...    ...                             ...   \n",
                            "48640     40.68     -73.95     70                            2.00   \n",
                            "48641     40.70     -73.93     40                            2.00   \n",
                            "48642     40.81     -73.95    115                            1.00   \n",
                            "48643     40.76     -73.99     55                            3.50   \n",
                            "48644     40.76     -73.99     90                            1.00   \n",
                            "\n",
                            "       availability_365  price_log  neighbourhood  neighbourhood_group  \\\n",
                            "0                   365       5.00            108                 1.00   \n",
                            "1                   355       5.42            127                 2.00   \n",
                            "2                   365       5.01             94                 2.00   \n",
                            "3                   194       4.49             41                 1.00   \n",
                            "4                     0       4.38             61                 2.00   \n",
                            "...                 ...        ...            ...                  ...   \n",
                            "48640                 9       4.25             13                 1.00   \n",
                            "48641                36       3.69             28                 1.00   \n",
                            "48642                27       4.74             94                 2.00   \n",
                            "48643                 2       4.01             95                 2.00   \n",
                            "48644                23       4.50             95                 2.00   \n",
                            "\n",
                            "       room_type  \n",
                            "0              1  \n",
                            "1              0  \n",
                            "2              1  \n",
                            "3              0  \n",
                            "4              0  \n",
                            "...          ...  \n",
                            "48640          1  \n",
                            "48641          1  \n",
                            "48642          0  \n",
                            "48643          2  \n",
                            "48644          1  \n",
                            "\n",
                            "[48645 rows x 9 columns]"
                        ]
                    },
                    "execution_count": 32,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data_p = pd.concat([windsorizar_datos, data_encoded[binarias]], axis=1)\n",
                "data_p"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "neighbourhood_group\n",
                            "2    21488\n",
                            "1    20041\n",
                            "3     5656\n",
                            "0     1089\n",
                            "4      371\n",
                            "Name: count, dtype: int64"
                        ]
                    },
                    "execution_count": 33,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data['neighbourhood_group'].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>price</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "      <th>price_log</th>\n",
                            "      <th>neighbourhood</th>\n",
                            "      <th>neighbourhood_group</th>\n",
                            "      <th>room_type</th>\n",
                            "      <th>demanda</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>40.65</td>\n",
                            "      <td>-73.97</td>\n",
                            "      <td>149</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>108</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>40.75</td>\n",
                            "      <td>-73.98</td>\n",
                            "      <td>225</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>355</td>\n",
                            "      <td>5.42</td>\n",
                            "      <td>127</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>150</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.01</td>\n",
                            "      <td>94</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>40.69</td>\n",
                            "      <td>-73.96</td>\n",
                            "      <td>89</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>194</td>\n",
                            "      <td>4.49</td>\n",
                            "      <td>41</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>40.80</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>80</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0</td>\n",
                            "      <td>4.38</td>\n",
                            "      <td>61</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48640</th>\n",
                            "      <td>40.68</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>70</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>9</td>\n",
                            "      <td>4.25</td>\n",
                            "      <td>13</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48641</th>\n",
                            "      <td>40.70</td>\n",
                            "      <td>-73.93</td>\n",
                            "      <td>40</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>36</td>\n",
                            "      <td>3.69</td>\n",
                            "      <td>28</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48642</th>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>115</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>27</td>\n",
                            "      <td>4.74</td>\n",
                            "      <td>94</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48643</th>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.99</td>\n",
                            "      <td>55</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>2</td>\n",
                            "      <td>4.01</td>\n",
                            "      <td>95</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>2</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48644</th>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.99</td>\n",
                            "      <td>90</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>23</td>\n",
                            "      <td>4.50</td>\n",
                            "      <td>95</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>48645 rows × 10 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       latitude  longitude  price  calculated_host_listings_count  \\\n",
                            "0         40.65     -73.97    149                            3.50   \n",
                            "1         40.75     -73.98    225                            2.00   \n",
                            "2         40.81     -73.94    150                            1.00   \n",
                            "3         40.69     -73.96     89                            1.00   \n",
                            "4         40.80     -73.94     80                            1.00   \n",
                            "...         ...        ...    ...                             ...   \n",
                            "48640     40.68     -73.95     70                            2.00   \n",
                            "48641     40.70     -73.93     40                            2.00   \n",
                            "48642     40.81     -73.95    115                            1.00   \n",
                            "48643     40.76     -73.99     55                            3.50   \n",
                            "48644     40.76     -73.99     90                            1.00   \n",
                            "\n",
                            "       availability_365  price_log  neighbourhood  neighbourhood_group  \\\n",
                            "0                   365       5.00            108                 1.00   \n",
                            "1                   355       5.42            127                 2.00   \n",
                            "2                   365       5.01             94                 2.00   \n",
                            "3                   194       4.49             41                 1.00   \n",
                            "4                     0       4.38             61                 2.00   \n",
                            "...                 ...        ...            ...                  ...   \n",
                            "48640                 9       4.25             13                 1.00   \n",
                            "48641                36       3.69             28                 1.00   \n",
                            "48642                27       4.74             94                 2.00   \n",
                            "48643                 2       4.01             95                 2.00   \n",
                            "48644                23       4.50             95                 2.00   \n",
                            "\n",
                            "       room_type demanda  \n",
                            "0              1       1  \n",
                            "1              0       1  \n",
                            "2              1       1  \n",
                            "3              0       2  \n",
                            "4              0       1  \n",
                            "...          ...     ...  \n",
                            "48640          1       1  \n",
                            "48641          1       1  \n",
                            "48642          0       1  \n",
                            "48643          2       1  \n",
                            "48644          1       1  \n",
                            "\n",
                            "[48645 rows x 10 columns]"
                        ]
                    },
                    "execution_count": 34,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# demanda muy alta - 1\n",
                "# damanda alta - 2\n",
                "# demanda media - 3\n",
                "# demanda baja - 4\n",
                "# demanda muy baja - 5\n",
                "\n",
                "\n",
                "def demanda(n_huespedes, barrio):\n",
                "    if barrio == 2 and n_huespedes >= 1:\n",
                "        return 1\n",
                "    elif barrio == 1 and n_huespedes >= 2:\n",
                "        return 1\n",
                "    elif barrio == 1 and n_huespedes == 1:\n",
                "        return 2\n",
                "    elif (barrio == 3 or \n",
                "          barrio == 0 or \n",
                "          barrio == 4) and n_huespedes > 2:\n",
                "        return \"3\"\n",
                "    elif barrio == 3 and n_huespedes <= 2:\n",
                "        return \"4\"\n",
                "    elif (barrio == 4 or \n",
                "          barrio == 0) and n_huespedes <= 2:\n",
                "        return \"5\"\n",
                "\n",
                "# Aplicar la función a cada fila del DataFrame\n",
                "data_p['demanda'] = data_p.apply(lambda row: demanda(row['calculated_host_listings_count'], row['neighbourhood_group']), axis=1)\n",
                "data_p\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>price</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "      <th>price_log</th>\n",
                            "      <th>neighbourhood</th>\n",
                            "      <th>neighbourhood_group</th>\n",
                            "      <th>room_type</th>\n",
                            "      <th>demanda</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>169</th>\n",
                            "      <td>40.65</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>70</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>312</td>\n",
                            "      <td>4.25</td>\n",
                            "      <td>186</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>1</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>249</th>\n",
                            "      <td>40.64</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>36</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>360</td>\n",
                            "      <td>3.58</td>\n",
                            "      <td>194</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>1</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>250</th>\n",
                            "      <td>40.64</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>37</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>0</td>\n",
                            "      <td>3.61</td>\n",
                            "      <td>194</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>1</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>251</th>\n",
                            "      <td>40.64</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>37</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>320</td>\n",
                            "      <td>3.61</td>\n",
                            "      <td>194</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>1</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>256</th>\n",
                            "      <td>40.63</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>36</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>340</td>\n",
                            "      <td>3.58</td>\n",
                            "      <td>194</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>1</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48193</th>\n",
                            "      <td>40.58</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>40</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>341</td>\n",
                            "      <td>3.69</td>\n",
                            "      <td>142</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>1</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48198</th>\n",
                            "      <td>40.64</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>100</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>342</td>\n",
                            "      <td>4.61</td>\n",
                            "      <td>186</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>0</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48284</th>\n",
                            "      <td>40.63</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>334</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>88</td>\n",
                            "      <td>6.11</td>\n",
                            "      <td>187</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>0</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48400</th>\n",
                            "      <td>40.61</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>54</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>89</td>\n",
                            "      <td>3.99</td>\n",
                            "      <td>176</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>1</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48549</th>\n",
                            "      <td>40.58</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>235</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>87</td>\n",
                            "      <td>5.46</td>\n",
                            "      <td>90</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>1</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>371 rows × 10 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       latitude  longitude  price  calculated_host_listings_count  \\\n",
                            "169       40.65     -74.05     70                            1.00   \n",
                            "249       40.64     -74.05     36                            3.50   \n",
                            "250       40.64     -74.05     37                            3.50   \n",
                            "251       40.64     -74.05     37                            3.50   \n",
                            "256       40.63     -74.05     36                            3.50   \n",
                            "...         ...        ...    ...                             ...   \n",
                            "48193     40.58     -74.05     40                            2.00   \n",
                            "48198     40.64     -74.05    100                            1.00   \n",
                            "48284     40.63     -74.05    334                            1.00   \n",
                            "48400     40.61     -74.05     54                            1.00   \n",
                            "48549     40.58     -74.05    235                            1.00   \n",
                            "\n",
                            "       availability_365  price_log  neighbourhood  neighbourhood_group  \\\n",
                            "169                 312       4.25            186                 3.50   \n",
                            "249                 360       3.58            194                 3.50   \n",
                            "250                   0       3.61            194                 3.50   \n",
                            "251                 320       3.61            194                 3.50   \n",
                            "256                 340       3.58            194                 3.50   \n",
                            "...                 ...        ...            ...                  ...   \n",
                            "48193               341       3.69            142                 3.50   \n",
                            "48198               342       4.61            186                 3.50   \n",
                            "48284                88       6.11            187                 3.50   \n",
                            "48400                89       3.99            176                 3.50   \n",
                            "48549                87       5.46             90                 3.50   \n",
                            "\n",
                            "       room_type demanda  \n",
                            "169            1    None  \n",
                            "249            1    None  \n",
                            "250            1    None  \n",
                            "251            1    None  \n",
                            "256            1    None  \n",
                            "...          ...     ...  \n",
                            "48193          1    None  \n",
                            "48198          0    None  \n",
                            "48284          0    None  \n",
                            "48400          1    None  \n",
                            "48549          1    None  \n",
                            "\n",
                            "[371 rows x 10 columns]"
                        ]
                    },
                    "execution_count": 35,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data_p.isnull().any()\n",
                "data_p[data_p['demanda'].isnull()]\n",
                "unique_values = data_p['neighbourhood_group'].unique()\n",
                "anomalous_values = [0, 1, 2, 3, 4]\n",
                "filtered_data = data_p[~data_p['neighbourhood_group'].isin(anomalous_values)]\n",
                "filtered_data\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([1., 2., 3., 4., 0.])"
                        ]
                    },
                    "execution_count": 36,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Error al codificar: en lugar de 4 se introdujo 3.5\n",
                "# En lugar de adaptar el código a esta cifra, la modificaremos en el dataframe a 4\n",
                "\n",
                "data_p['neighbourhood_group'] = data_p['neighbourhood_group'].replace(3.5, 4)\n",
                "valores = data_p['neighbourhood_group'].unique()\n",
                "valores"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>price</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "      <th>price_log</th>\n",
                            "      <th>neighbourhood</th>\n",
                            "      <th>neighbourhood_group</th>\n",
                            "      <th>room_type</th>\n",
                            "      <th>demanda</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>169</th>\n",
                            "      <td>40.65</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>70</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>312</td>\n",
                            "      <td>4.25</td>\n",
                            "      <td>186</td>\n",
                            "      <td>4.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>249</th>\n",
                            "      <td>40.64</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>36</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>360</td>\n",
                            "      <td>3.58</td>\n",
                            "      <td>194</td>\n",
                            "      <td>4.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>250</th>\n",
                            "      <td>40.64</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>37</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>0</td>\n",
                            "      <td>3.61</td>\n",
                            "      <td>194</td>\n",
                            "      <td>4.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>251</th>\n",
                            "      <td>40.64</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>37</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>320</td>\n",
                            "      <td>3.61</td>\n",
                            "      <td>194</td>\n",
                            "      <td>4.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>256</th>\n",
                            "      <td>40.63</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>36</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>340</td>\n",
                            "      <td>3.58</td>\n",
                            "      <td>194</td>\n",
                            "      <td>4.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48193</th>\n",
                            "      <td>40.58</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>40</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>341</td>\n",
                            "      <td>3.69</td>\n",
                            "      <td>142</td>\n",
                            "      <td>4.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48198</th>\n",
                            "      <td>40.64</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>100</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>342</td>\n",
                            "      <td>4.61</td>\n",
                            "      <td>186</td>\n",
                            "      <td>4.00</td>\n",
                            "      <td>0</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48284</th>\n",
                            "      <td>40.63</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>334</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>88</td>\n",
                            "      <td>6.11</td>\n",
                            "      <td>187</td>\n",
                            "      <td>4.00</td>\n",
                            "      <td>0</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48400</th>\n",
                            "      <td>40.61</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>54</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>89</td>\n",
                            "      <td>3.99</td>\n",
                            "      <td>176</td>\n",
                            "      <td>4.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48549</th>\n",
                            "      <td>40.58</td>\n",
                            "      <td>-74.05</td>\n",
                            "      <td>235</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>87</td>\n",
                            "      <td>5.46</td>\n",
                            "      <td>90</td>\n",
                            "      <td>4.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>371 rows × 10 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       latitude  longitude  price  calculated_host_listings_count  \\\n",
                            "169       40.65     -74.05     70                            1.00   \n",
                            "249       40.64     -74.05     36                            3.50   \n",
                            "250       40.64     -74.05     37                            3.50   \n",
                            "251       40.64     -74.05     37                            3.50   \n",
                            "256       40.63     -74.05     36                            3.50   \n",
                            "...         ...        ...    ...                             ...   \n",
                            "48193     40.58     -74.05     40                            2.00   \n",
                            "48198     40.64     -74.05    100                            1.00   \n",
                            "48284     40.63     -74.05    334                            1.00   \n",
                            "48400     40.61     -74.05     54                            1.00   \n",
                            "48549     40.58     -74.05    235                            1.00   \n",
                            "\n",
                            "       availability_365  price_log  neighbourhood  neighbourhood_group  \\\n",
                            "169                 312       4.25            186                 4.00   \n",
                            "249                 360       3.58            194                 4.00   \n",
                            "250                   0       3.61            194                 4.00   \n",
                            "251                 320       3.61            194                 4.00   \n",
                            "256                 340       3.58            194                 4.00   \n",
                            "...                 ...        ...            ...                  ...   \n",
                            "48193               341       3.69            142                 4.00   \n",
                            "48198               342       4.61            186                 4.00   \n",
                            "48284                88       6.11            187                 4.00   \n",
                            "48400                89       3.99            176                 4.00   \n",
                            "48549                87       5.46             90                 4.00   \n",
                            "\n",
                            "       room_type demanda  \n",
                            "169            1    None  \n",
                            "249            1    None  \n",
                            "250            1    None  \n",
                            "251            1    None  \n",
                            "256            1    None  \n",
                            "...          ...     ...  \n",
                            "48193          1    None  \n",
                            "48198          0    None  \n",
                            "48284          0    None  \n",
                            "48400          1    None  \n",
                            "48549          1    None  \n",
                            "\n",
                            "[371 rows x 10 columns]"
                        ]
                    },
                    "execution_count": 37,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "filas_especificas = data_p.iloc[filtered_data.index]\n",
                "filas_especificas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>price</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "      <th>price_log</th>\n",
                            "      <th>neighbourhood</th>\n",
                            "      <th>neighbourhood_group</th>\n",
                            "      <th>room_type</th>\n",
                            "      <th>demanda</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>40.65</td>\n",
                            "      <td>-73.97</td>\n",
                            "      <td>149</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>108</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>40.75</td>\n",
                            "      <td>-73.98</td>\n",
                            "      <td>225</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>355</td>\n",
                            "      <td>5.42</td>\n",
                            "      <td>127</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>150</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.01</td>\n",
                            "      <td>94</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>40.69</td>\n",
                            "      <td>-73.96</td>\n",
                            "      <td>89</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>194</td>\n",
                            "      <td>4.49</td>\n",
                            "      <td>41</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>40.80</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>80</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0</td>\n",
                            "      <td>4.38</td>\n",
                            "      <td>61</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48640</th>\n",
                            "      <td>40.68</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>70</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>9</td>\n",
                            "      <td>4.25</td>\n",
                            "      <td>13</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48641</th>\n",
                            "      <td>40.70</td>\n",
                            "      <td>-73.93</td>\n",
                            "      <td>40</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>36</td>\n",
                            "      <td>3.69</td>\n",
                            "      <td>28</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48642</th>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.95</td>\n",
                            "      <td>115</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>27</td>\n",
                            "      <td>4.74</td>\n",
                            "      <td>94</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48643</th>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.99</td>\n",
                            "      <td>55</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>2</td>\n",
                            "      <td>4.01</td>\n",
                            "      <td>95</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>2</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>48644</th>\n",
                            "      <td>40.76</td>\n",
                            "      <td>-73.99</td>\n",
                            "      <td>90</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>23</td>\n",
                            "      <td>4.50</td>\n",
                            "      <td>95</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>48645 rows × 10 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       latitude  longitude  price  calculated_host_listings_count  \\\n",
                            "0         40.65     -73.97    149                            3.50   \n",
                            "1         40.75     -73.98    225                            2.00   \n",
                            "2         40.81     -73.94    150                            1.00   \n",
                            "3         40.69     -73.96     89                            1.00   \n",
                            "4         40.80     -73.94     80                            1.00   \n",
                            "...         ...        ...    ...                             ...   \n",
                            "48640     40.68     -73.95     70                            2.00   \n",
                            "48641     40.70     -73.93     40                            2.00   \n",
                            "48642     40.81     -73.95    115                            1.00   \n",
                            "48643     40.76     -73.99     55                            3.50   \n",
                            "48644     40.76     -73.99     90                            1.00   \n",
                            "\n",
                            "       availability_365  price_log  neighbourhood  neighbourhood_group  \\\n",
                            "0                   365       5.00            108                 1.00   \n",
                            "1                   355       5.42            127                 2.00   \n",
                            "2                   365       5.01             94                 2.00   \n",
                            "3                   194       4.49             41                 1.00   \n",
                            "4                     0       4.38             61                 2.00   \n",
                            "...                 ...        ...            ...                  ...   \n",
                            "48640                 9       4.25             13                 1.00   \n",
                            "48641                36       3.69             28                 1.00   \n",
                            "48642                27       4.74             94                 2.00   \n",
                            "48643                 2       4.01             95                 2.00   \n",
                            "48644                23       4.50             95                 2.00   \n",
                            "\n",
                            "       room_type demanda  \n",
                            "0              1       1  \n",
                            "1              0       1  \n",
                            "2              1       1  \n",
                            "3              0       2  \n",
                            "4              0       1  \n",
                            "...          ...     ...  \n",
                            "48640          1       1  \n",
                            "48641          1       1  \n",
                            "48642          0       1  \n",
                            "48643          2       1  \n",
                            "48644          1       1  \n",
                            "\n",
                            "[48645 rows x 10 columns]"
                        ]
                    },
                    "execution_count": 38,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Aplicar la función a cada fila del DataFrame\n",
                "data_p['demanda'] = data_p.apply(lambda row: demanda(row['calculated_host_listings_count'], row['neighbourhood_group']), axis=1)\n",
                "data_p"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "False"
                        ]
                    },
                    "execution_count": 39,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data_p.isnull().any().any()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style type=\"text/css\">\n",
                            "#T_78203_row0_col0, #T_78203_row1_col1, #T_78203_row2_col2, #T_78203_row3_col3, #T_78203_row4_col4, #T_78203_row5_col5, #T_78203_row6_col6, #T_78203_row7_col7, #T_78203_row8_col8, #T_78203_row9_col9 {\n",
                            "  background-color: #b40426;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row0_col1 {\n",
                            "  background-color: #b2ccfb;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row0_col2 {\n",
                            "  background-color: #c4d5f3;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row0_col3 {\n",
                            "  background-color: #6788ee;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row0_col4 {\n",
                            "  background-color: #4055c8;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row0_col5 {\n",
                            "  background-color: #ccd9ed;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row0_col6 {\n",
                            "  background-color: #a5c3fe;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row0_col7, #T_78203_row6_col0 {\n",
                            "  background-color: #9dbdff;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row0_col8 {\n",
                            "  background-color: #bed2f6;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row0_col9, #T_78203_row1_col2 {\n",
                            "  background-color: #6485ec;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row1_col0 {\n",
                            "  background-color: #7396f5;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row1_col3, #T_78203_row7_col6 {\n",
                            "  background-color: #7ea1fa;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row1_col4, #T_78203_row6_col3 {\n",
                            "  background-color: #5b7ae5;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row1_col5 {\n",
                            "  background-color: #6a8bef;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row1_col6, #T_78203_row5_col1, #T_78203_row5_col8, #T_78203_row5_col9, #T_78203_row6_col4, #T_78203_row8_col2, #T_78203_row8_col5, #T_78203_row8_col7, #T_78203_row9_col0, #T_78203_row9_col3 {\n",
                            "  background-color: #3b4cc0;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row1_col7, #T_78203_row4_col0, #T_78203_row5_col3, #T_78203_row9_col6 {\n",
                            "  background-color: #4e68d8;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row1_col8 {\n",
                            "  background-color: #e1dad6;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row1_col9 {\n",
                            "  background-color: #f7bca1;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row2_col0 {\n",
                            "  background-color: #688aef;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row2_col1 {\n",
                            "  background-color: #3f53c6;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row2_col3, #T_78203_row5_col7 {\n",
                            "  background-color: #5673e0;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row2_col4 {\n",
                            "  background-color: #6687ed;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row2_col5, #T_78203_row5_col2 {\n",
                            "  background-color: #bd1f2d;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row2_col6 {\n",
                            "  background-color: #85a8fc;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row2_col7, #T_78203_row4_col7 {\n",
                            "  background-color: #5875e1;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row2_col8 {\n",
                            "  background-color: #455cce;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row2_col9 {\n",
                            "  background-color: #3d50c3;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row3_col0, #T_78203_row3_col6 {\n",
                            "  background-color: #516ddb;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row3_col1 {\n",
                            "  background-color: #abc8fd;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row3_col2, #T_78203_row3_col5 {\n",
                            "  background-color: #a9c6fd;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row3_col4, #T_78203_row4_col2, #T_78203_row7_col5, #T_78203_row9_col8 {\n",
                            "  background-color: #cbd8ee;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row3_col7 {\n",
                            "  background-color: #5572df;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row3_col8, #T_78203_row4_col3 {\n",
                            "  background-color: #dcdddd;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row3_col9 {\n",
                            "  background-color: #4f69d9;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row4_col1 {\n",
                            "  background-color: #aac7fd;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row4_col5 {\n",
                            "  background-color: #cdd9ec;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row4_col6 {\n",
                            "  background-color: #536edd;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row4_col8 {\n",
                            "  background-color: #c1d4f4;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row4_col9 {\n",
                            "  background-color: #82a6fb;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row5_col0 {\n",
                            "  background-color: #6b8df0;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row5_col4, #T_78203_row6_col7 {\n",
                            "  background-color: #6180e9;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row5_col6, #T_78203_row9_col5 {\n",
                            "  background-color: #88abfd;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row6_col1 {\n",
                            "  background-color: #779af7;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row6_col2 {\n",
                            "  background-color: #cfdaea;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row6_col5 {\n",
                            "  background-color: #d6dce4;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row6_col8 {\n",
                            "  background-color: #aec9fc;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row6_col9 {\n",
                            "  background-color: #6c8ff1;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row7_col0 {\n",
                            "  background-color: #adc9fd;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row7_col1 {\n",
                            "  background-color: #a3c2fe;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row7_col2 {\n",
                            "  background-color: #c5d6f2;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row7_col3 {\n",
                            "  background-color: #7da0f9;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row7_col4 {\n",
                            "  background-color: #5d7ce6;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row7_col8 {\n",
                            "  background-color: #bad0f8;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row7_col9 {\n",
                            "  background-color: #b6cefa;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row8_col0 {\n",
                            "  background-color: #5470de;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row8_col1 {\n",
                            "  background-color: #cad8ef;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row8_col3 {\n",
                            "  background-color: #9ebeff;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row8_col4, #T_78203_row9_col4 {\n",
                            "  background-color: #4b64d5;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row8_col6 {\n",
                            "  background-color: #4961d2;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row8_col9 {\n",
                            "  background-color: #92b4fe;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row9_col1 {\n",
                            "  background-color: #f7b093;\n",
                            "  color: #000000;\n",
                            "}\n",
                            "#T_78203_row9_col2 {\n",
                            "  background-color: #81a4fb;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "#T_78203_row9_col7 {\n",
                            "  background-color: #84a7fc;\n",
                            "  color: #f1f1f1;\n",
                            "}\n",
                            "</style>\n",
                            "<table id=\"T_78203\">\n",
                            "  <thead>\n",
                            "    <tr>\n",
                            "      <th class=\"blank level0\" >&nbsp;</th>\n",
                            "      <th id=\"T_78203_level0_col0\" class=\"col_heading level0 col0\" >latitude</th>\n",
                            "      <th id=\"T_78203_level0_col1\" class=\"col_heading level0 col1\" >longitude</th>\n",
                            "      <th id=\"T_78203_level0_col2\" class=\"col_heading level0 col2\" >price</th>\n",
                            "      <th id=\"T_78203_level0_col3\" class=\"col_heading level0 col3\" >calculated_host_listings_count</th>\n",
                            "      <th id=\"T_78203_level0_col4\" class=\"col_heading level0 col4\" >availability_365</th>\n",
                            "      <th id=\"T_78203_level0_col5\" class=\"col_heading level0 col5\" >price_log</th>\n",
                            "      <th id=\"T_78203_level0_col6\" class=\"col_heading level0 col6\" >neighbourhood</th>\n",
                            "      <th id=\"T_78203_level0_col7\" class=\"col_heading level0 col7\" >neighbourhood_group</th>\n",
                            "      <th id=\"T_78203_level0_col8\" class=\"col_heading level0 col8\" >room_type</th>\n",
                            "      <th id=\"T_78203_level0_col9\" class=\"col_heading level0 col9\" >demanda</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th id=\"T_78203_level0_row0\" class=\"row_heading level0 row0\" >latitude</th>\n",
                            "      <td id=\"T_78203_row0_col0\" class=\"data row0 col0\" >1.000</td>\n",
                            "      <td id=\"T_78203_row0_col1\" class=\"data row0 col1\" >0.110</td>\n",
                            "      <td id=\"T_78203_row0_col2\" class=\"data row0 col2\" >0.075</td>\n",
                            "      <td id=\"T_78203_row0_col3\" class=\"data row0 col3\" >-0.001</td>\n",
                            "      <td id=\"T_78203_row0_col4\" class=\"data row0 col4\" >-0.011</td>\n",
                            "      <td id=\"T_78203_row0_col5\" class=\"data row0 col5\" >0.084</td>\n",
                            "      <td id=\"T_78203_row0_col6\" class=\"data row0 col6\" >0.235</td>\n",
                            "      <td id=\"T_78203_row0_col7\" class=\"data row0 col7\" >0.286</td>\n",
                            "      <td id=\"T_78203_row0_col8\" class=\"data row0 col8\" >0.006</td>\n",
                            "      <td id=\"T_78203_row0_col9\" class=\"data row0 col9\" >-0.083</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_78203_level0_row1\" class=\"row_heading level0 row1\" >longitude</th>\n",
                            "      <td id=\"T_78203_row1_col0\" class=\"data row1 col0\" >0.110</td>\n",
                            "      <td id=\"T_78203_row1_col1\" class=\"data row1 col1\" >1.000</td>\n",
                            "      <td id=\"T_78203_row1_col2\" class=\"data row1 col2\" >-0.363</td>\n",
                            "      <td id=\"T_78203_row1_col3\" class=\"data row1 col3\" >0.079</td>\n",
                            "      <td id=\"T_78203_row1_col4\" class=\"data row1 col4\" >0.075</td>\n",
                            "      <td id=\"T_78203_row1_col5\" class=\"data row1 col5\" >-0.387</td>\n",
                            "      <td id=\"T_78203_row1_col6\" class=\"data row1 col6\" >-0.125</td>\n",
                            "      <td id=\"T_78203_row1_col7\" class=\"data row1 col7\" >0.051</td>\n",
                            "      <td id=\"T_78203_row1_col8\" class=\"data row1 col8\" >0.212</td>\n",
                            "      <td id=\"T_78203_row1_col9\" class=\"data row1 col9\" >0.568</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_78203_level0_row2\" class=\"row_heading level0 row2\" >price</th>\n",
                            "      <td id=\"T_78203_row2_col0\" class=\"data row2 col0\" >0.075</td>\n",
                            "      <td id=\"T_78203_row2_col1\" class=\"data row2 col1\" >-0.363</td>\n",
                            "      <td id=\"T_78203_row2_col2\" class=\"data row2 col2\" >1.000</td>\n",
                            "      <td id=\"T_78203_row2_col3\" class=\"data row2 col3\" >-0.057</td>\n",
                            "      <td id=\"T_78203_row2_col4\" class=\"data row2 col4\" >0.109</td>\n",
                            "      <td id=\"T_78203_row2_col5\" class=\"data row2 col5\" >0.962</td>\n",
                            "      <td id=\"T_78203_row2_col6\" class=\"data row2 col6\" >0.133</td>\n",
                            "      <td id=\"T_78203_row2_col7\" class=\"data row2 col7\" >0.081</td>\n",
                            "      <td id=\"T_78203_row2_col8\" class=\"data row2 col8\" >-0.578</td>\n",
                            "      <td id=\"T_78203_row2_col9\" class=\"data row2 col9\" >-0.238</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_78203_level0_row3\" class=\"row_heading level0 row3\" >calculated_host_listings_count</th>\n",
                            "      <td id=\"T_78203_row3_col0\" class=\"data row3 col0\" >-0.001</td>\n",
                            "      <td id=\"T_78203_row3_col1\" class=\"data row3 col1\" >0.079</td>\n",
                            "      <td id=\"T_78203_row3_col2\" class=\"data row3 col2\" >-0.057</td>\n",
                            "      <td id=\"T_78203_row3_col3\" class=\"data row3 col3\" >1.000</td>\n",
                            "      <td id=\"T_78203_row3_col4\" class=\"data row3 col4\" >0.415</td>\n",
                            "      <td id=\"T_78203_row3_col5\" class=\"data row3 col5\" >-0.093</td>\n",
                            "      <td id=\"T_78203_row3_col6\" class=\"data row3 col6\" >-0.039</td>\n",
                            "      <td id=\"T_78203_row3_col7\" class=\"data row3 col7\" >0.072</td>\n",
                            "      <td id=\"T_78203_row3_col8\" class=\"data row3 col8\" >0.182</td>\n",
                            "      <td id=\"T_78203_row3_col9\" class=\"data row3 col9\" >-0.166</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_78203_level0_row4\" class=\"row_heading level0 row4\" >availability_365</th>\n",
                            "      <td id=\"T_78203_row4_col0\" class=\"data row4 col0\" >-0.011</td>\n",
                            "      <td id=\"T_78203_row4_col1\" class=\"data row4 col1\" >0.075</td>\n",
                            "      <td id=\"T_78203_row4_col2\" class=\"data row4 col2\" >0.109</td>\n",
                            "      <td id=\"T_78203_row4_col3\" class=\"data row4 col3\" >0.415</td>\n",
                            "      <td id=\"T_78203_row4_col4\" class=\"data row4 col4\" >1.000</td>\n",
                            "      <td id=\"T_78203_row4_col5\" class=\"data row4 col5\" >0.092</td>\n",
                            "      <td id=\"T_78203_row4_col6\" class=\"data row4 col6\" >-0.035</td>\n",
                            "      <td id=\"T_78203_row4_col7\" class=\"data row4 col7\" >0.080</td>\n",
                            "      <td id=\"T_78203_row4_col8\" class=\"data row4 col8\" >0.024</td>\n",
                            "      <td id=\"T_78203_row4_col9\" class=\"data row4 col9\" >0.023</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_78203_level0_row5\" class=\"row_heading level0 row5\" >price_log</th>\n",
                            "      <td id=\"T_78203_row5_col0\" class=\"data row5 col0\" >0.084</td>\n",
                            "      <td id=\"T_78203_row5_col1\" class=\"data row5 col1\" >-0.387</td>\n",
                            "      <td id=\"T_78203_row5_col2\" class=\"data row5 col2\" >0.962</td>\n",
                            "      <td id=\"T_78203_row5_col3\" class=\"data row5 col3\" >-0.093</td>\n",
                            "      <td id=\"T_78203_row5_col4\" class=\"data row5 col4\" >0.092</td>\n",
                            "      <td id=\"T_78203_row5_col5\" class=\"data row5 col5\" >1.000</td>\n",
                            "      <td id=\"T_78203_row5_col6\" class=\"data row5 col6\" >0.142</td>\n",
                            "      <td id=\"T_78203_row5_col7\" class=\"data row5 col7\" >0.079</td>\n",
                            "      <td id=\"T_78203_row5_col8\" class=\"data row5 col8\" >-0.635</td>\n",
                            "      <td id=\"T_78203_row5_col9\" class=\"data row5 col9\" >-0.251</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_78203_level0_row6\" class=\"row_heading level0 row6\" >neighbourhood</th>\n",
                            "      <td id=\"T_78203_row6_col0\" class=\"data row6 col0\" >0.235</td>\n",
                            "      <td id=\"T_78203_row6_col1\" class=\"data row6 col1\" >-0.125</td>\n",
                            "      <td id=\"T_78203_row6_col2\" class=\"data row6 col2\" >0.133</td>\n",
                            "      <td id=\"T_78203_row6_col3\" class=\"data row6 col3\" >-0.039</td>\n",
                            "      <td id=\"T_78203_row6_col4\" class=\"data row6 col4\" >-0.035</td>\n",
                            "      <td id=\"T_78203_row6_col5\" class=\"data row6 col5\" >0.142</td>\n",
                            "      <td id=\"T_78203_row6_col6\" class=\"data row6 col6\" >1.000</td>\n",
                            "      <td id=\"T_78203_row6_col7\" class=\"data row6 col7\" >0.111</td>\n",
                            "      <td id=\"T_78203_row6_col8\" class=\"data row6 col8\" >-0.071</td>\n",
                            "      <td id=\"T_78203_row6_col9\" class=\"data row6 col9\" >-0.052</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_78203_level0_row7\" class=\"row_heading level0 row7\" >neighbourhood_group</th>\n",
                            "      <td id=\"T_78203_row7_col0\" class=\"data row7 col0\" >0.286</td>\n",
                            "      <td id=\"T_78203_row7_col1\" class=\"data row7 col1\" >0.051</td>\n",
                            "      <td id=\"T_78203_row7_col2\" class=\"data row7 col2\" >0.081</td>\n",
                            "      <td id=\"T_78203_row7_col3\" class=\"data row7 col3\" >0.072</td>\n",
                            "      <td id=\"T_78203_row7_col4\" class=\"data row7 col4\" >0.080</td>\n",
                            "      <td id=\"T_78203_row7_col5\" class=\"data row7 col5\" >0.079</td>\n",
                            "      <td id=\"T_78203_row7_col6\" class=\"data row7 col6\" >0.111</td>\n",
                            "      <td id=\"T_78203_row7_col7\" class=\"data row7 col7\" >1.000</td>\n",
                            "      <td id=\"T_78203_row7_col8\" class=\"data row7 col8\" >-0.015</td>\n",
                            "      <td id=\"T_78203_row7_col9\" class=\"data row7 col9\" >0.211</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_78203_level0_row8\" class=\"row_heading level0 row8\" >room_type</th>\n",
                            "      <td id=\"T_78203_row8_col0\" class=\"data row8 col0\" >0.006</td>\n",
                            "      <td id=\"T_78203_row8_col1\" class=\"data row8 col1\" >0.212</td>\n",
                            "      <td id=\"T_78203_row8_col2\" class=\"data row8 col2\" >-0.578</td>\n",
                            "      <td id=\"T_78203_row8_col3\" class=\"data row8 col3\" >0.182</td>\n",
                            "      <td id=\"T_78203_row8_col4\" class=\"data row8 col4\" >0.024</td>\n",
                            "      <td id=\"T_78203_row8_col5\" class=\"data row8 col5\" >-0.635</td>\n",
                            "      <td id=\"T_78203_row8_col6\" class=\"data row8 col6\" >-0.071</td>\n",
                            "      <td id=\"T_78203_row8_col7\" class=\"data row8 col7\" >-0.015</td>\n",
                            "      <td id=\"T_78203_row8_col8\" class=\"data row8 col8\" >1.000</td>\n",
                            "      <td id=\"T_78203_row8_col9\" class=\"data row8 col9\" >0.079</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_78203_level0_row9\" class=\"row_heading level0 row9\" >demanda</th>\n",
                            "      <td id=\"T_78203_row9_col0\" class=\"data row9 col0\" >-0.083</td>\n",
                            "      <td id=\"T_78203_row9_col1\" class=\"data row9 col1\" >0.568</td>\n",
                            "      <td id=\"T_78203_row9_col2\" class=\"data row9 col2\" >-0.238</td>\n",
                            "      <td id=\"T_78203_row9_col3\" class=\"data row9 col3\" >-0.166</td>\n",
                            "      <td id=\"T_78203_row9_col4\" class=\"data row9 col4\" >0.023</td>\n",
                            "      <td id=\"T_78203_row9_col5\" class=\"data row9 col5\" >-0.251</td>\n",
                            "      <td id=\"T_78203_row9_col6\" class=\"data row9 col6\" >-0.052</td>\n",
                            "      <td id=\"T_78203_row9_col7\" class=\"data row9 col7\" >0.211</td>\n",
                            "      <td id=\"T_78203_row9_col8\" class=\"data row9 col8\" >0.079</td>\n",
                            "      <td id=\"T_78203_row9_col9\" class=\"data row9 col9\" >1.000</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "<pandas.io.formats.style.Styler at 0x7fd701e12620>"
                        ]
                    },
                    "execution_count": 40,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "corr = data_p.corr()\n",
                "corr.style.background_gradient(cmap='coolwarm').format(precision=3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['latitude', 'calculated_host_listings_count', 'availability_365',\n",
                            "       'neighbourhood_group'],\n",
                            "      dtype='object')"
                        ]
                    },
                    "execution_count": 41,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "corr[corr.price_log.abs()<0.1].index"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['price', 'price_log', 'room_type'], dtype='object')"
                        ]
                    },
                    "execution_count": 42,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "corr[corr.price_log.abs()>0.5].index"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "latitude                          0.08\n",
                            "longitude                        -0.39\n",
                            "price                             0.96\n",
                            "calculated_host_listings_count   -0.09\n",
                            "availability_365                  0.09\n",
                            "price_log                         1.00\n",
                            "neighbourhood                     0.14\n",
                            "neighbourhood_group               0.08\n",
                            "room_type                        -0.64\n",
                            "demanda                          -0.25\n",
                            "Name: price_log, dtype: float64"
                        ]
                    },
                    "execution_count": 43,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "corr.price_log"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "latitude                            2.72\n",
                            "longitude                           8.89\n",
                            "price                             947.52\n",
                            "calculated_host_listings_count      3.72\n",
                            "availability_365                    2.43\n",
                            "price_log                        1157.49\n",
                            "neighbourhood                       1.51\n",
                            "neighbourhood_group                 2.36\n",
                            "room_type                          13.39\n",
                            "demanda                             8.24\n",
                            "dtype: float64"
                        ]
                    },
                    "execution_count": 44,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Factor de Inflación de la Varianza (VIF) - para cada columna del dataframe\n",
                "# Medida que cuantifica el incremento de la varianza de un coeficiente de regresión por la multicolinealidad entre las variables independientes.\n",
                "# El cálculo del VIF se realiza para cada variable independiente en relación con las demás.\n",
                "\n",
                "vif = pd.Series([variance_inflation_factor(corr.values, i) for i in range(corr.shape[1])], index=data_p.columns)\n",
                "vif\n",
                "\n",
                "# Un valor alto de VIF indica una alta multicolinealidad entre esa variable y las demás."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_p.drop(['price'], axis=1, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Eliminamos una columna de cada una de las características convertidas a binarias para evitar la multicolinealidad.\n",
                "# También la de price, ya que price_log se creo en función de ésta."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "latitude                         2.63\n",
                            "longitude                        8.01\n",
                            "calculated_host_listings_count   3.28\n",
                            "availability_365                 2.44\n",
                            "price_log                        9.84\n",
                            "neighbourhood                    1.48\n",
                            "neighbourhood_group              2.35\n",
                            "room_type                        6.68\n",
                            "demanda                          7.81\n",
                            "dtype: float64"
                        ]
                    },
                    "execution_count": 47,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "corr = data_p.corr()\n",
                "vif = pd.Series([variance_inflation_factor(corr.values, i) for i in range(corr.shape[1])], index=data_p.columns)\n",
                "vif"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 48645 entries, 0 to 48644\n",
                        "Data columns (total 9 columns):\n",
                        " #   Column                          Non-Null Count  Dtype  \n",
                        "---  ------                          --------------  -----  \n",
                        " 0   latitude                        48645 non-null  float64\n",
                        " 1   longitude                       48645 non-null  float64\n",
                        " 2   calculated_host_listings_count  48645 non-null  float64\n",
                        " 3   availability_365                48645 non-null  int64  \n",
                        " 4   price_log                       48645 non-null  float64\n",
                        " 5   neighbourhood                   48645 non-null  int64  \n",
                        " 6   neighbourhood_group             48645 non-null  float64\n",
                        " 7   room_type                       48645 non-null  int64  \n",
                        " 8   demanda                         48645 non-null  int32  \n",
                        "dtypes: float64(5), int32(1), int64(3)\n",
                        "memory usage: 3.2 MB\n"
                    ]
                }
            ],
            "source": [
                "data_p['demanda'] = data_p['demanda'].astype(np.int32)\n",
                "data_p.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dividimos el dataframe en función de la variable respuesta \n",
                "\n",
                "X = data_p.drop(['price_log'], axis=1)   # Dataframe con todas las columnas menos el precio, (X (mayus.) por convención\n",
                "y = data_p['price_log']                  # Dataframe con solo el precio, que es la variable objetivo\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# train_test_split divide los datos en conjuntos de entrenamiento (X_train, y_train) y prueba (X_test, y_test), \n",
                "#  * con el 80% de los datos destinados al entrenamiento y el 20% al testeo. \n",
                "\n",
                "# random_state=42 asegura reproducibilidad en la división aleatoria, es decir, que obtengamos la misma división de datos cada vez que ejecutemos el código."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Feature: room_type, Importance: 84.07203555107117\n",
                        "Feature: longitude, Importance: 4.508120194077492\n",
                        "Feature: latitude, Importance: 3.026140294969082\n",
                        "Feature: availability_365, Importance: 2.0182136446237564\n",
                        "Feature: calculated_host_listings_count, Importance: 1.8128549680113792\n",
                        "Feature: demanda, Importance: 1.675456017255783\n",
                        "Feature: neighbourhood, Importance: 1.6431573778390884\n",
                        "Feature: neighbourhood_group, Importance: 1.2440180405974388\n"
                    ]
                }
            ],
            "source": [
                "# Vamos a usar un método embebido que nos informe de la importancia de las características\n",
                "# Crea un modelo XGBoost Regressor\n",
                "model = xgb.XGBRegressor(objective='reg:squarederror')  # objective='reg:squarederror'configura XGBoost para entrenar un modelo de regresión \n",
                "                                                         # que minimice el error cuadrático medio durante el proceso de entrenamiento. \n",
                "                                                         # Esto es adecuado cuando estamos tratando de predecir valores numéricos continuos.\n",
                "# Entrena el modelo en los datos de entrenamiento\n",
                "model.fit(X_train, y_train) \n",
                "\n",
                "# Obtención de la importancia de las características\n",
                "feature_importances = model.feature_importances_\n",
                "\n",
                "# Asociación de las importancias con los nombres de las características\n",
                "feature_names = X.columns\n",
                "feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
                "\n",
                "# Ordenación de las características por importancia (de mayor a menor)\n",
                "sorted_feature_importance = dict(sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True))\n",
                "\n",
                "# Impresión de la importancia de las características\n",
                "for feature, importance in sorted_feature_importance.items():\n",
                "    print(f'Feature: {feature}, Importance: {importance*100}')\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[]"
                        ]
                    },
                    "execution_count": 51,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "def aborrar(d_imp, corr, imp_cut=0.005, corr_cut=0.1):\n",
                "  variables_poca_corr = corr[corr.price_log.abs()<=corr_cut].index\n",
                "  return [variable for variable in variables_poca_corr if d_imp[variable]<=imp_cut]\n",
                "\n",
                "borrar_variables = aborrar(sorted_feature_importance, corr, imp_cut=0.01, corr_cut=0.1)\n",
                "borrar_variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_p.drop(borrar_variables, axis=1, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_p.drop('demanda', axis=1, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "      <th>price_log</th>\n",
                            "      <th>neighbourhood</th>\n",
                            "      <th>neighbourhood_group</th>\n",
                            "      <th>room_type</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>40.65</td>\n",
                            "      <td>-73.97</td>\n",
                            "      <td>3.50</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>108</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>40.75</td>\n",
                            "      <td>-73.98</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>355</td>\n",
                            "      <td>5.42</td>\n",
                            "      <td>127</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>40.81</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>365</td>\n",
                            "      <td>5.01</td>\n",
                            "      <td>94</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>40.69</td>\n",
                            "      <td>-73.96</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>194</td>\n",
                            "      <td>4.49</td>\n",
                            "      <td>41</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>40.80</td>\n",
                            "      <td>-73.94</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0</td>\n",
                            "      <td>4.38</td>\n",
                            "      <td>61</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   latitude  longitude  calculated_host_listings_count  availability_365  \\\n",
                            "0     40.65     -73.97                            3.50               365   \n",
                            "1     40.75     -73.98                            2.00               355   \n",
                            "2     40.81     -73.94                            1.00               365   \n",
                            "3     40.69     -73.96                            1.00               194   \n",
                            "4     40.80     -73.94                            1.00                 0   \n",
                            "\n",
                            "   price_log  neighbourhood  neighbourhood_group  room_type  \n",
                            "0       5.00            108                 1.00          1  \n",
                            "1       5.42            127                 2.00          0  \n",
                            "2       5.01             94                 2.00          1  \n",
                            "3       4.49             41                 1.00          0  \n",
                            "4       4.38             61                 2.00          0  "
                        ]
                    },
                    "execution_count": 54,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data_p.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = data_p.drop(['price_log'], axis=1)\n",
                "y = data_p['price_log']\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quitamos nuestras columnas binarias de los test para escalar los datos\n",
                "\n",
                "# binary_cols = X_train[(X_train==0)|(X_train==1)].dropna(axis=1).columns\n",
                "# X_train_num = X_train.drop(binary_cols, axis=1)\n",
                "# X_test_num = X_test.drop(binary_cols, axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train.columns = X_train.columns.astype(str)\n",
                "X_test.columns = X_test.columns.astype(str)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "Index: 38916 entries, 32520 to 15795\n",
                        "Data columns (total 7 columns):\n",
                        " #   Column                          Non-Null Count  Dtype  \n",
                        "---  ------                          --------------  -----  \n",
                        " 0   latitude                        38916 non-null  float64\n",
                        " 1   longitude                       38916 non-null  float64\n",
                        " 2   calculated_host_listings_count  38916 non-null  float64\n",
                        " 3   availability_365                38916 non-null  int64  \n",
                        " 4   neighbourhood                   38916 non-null  int64  \n",
                        " 5   neighbourhood_group             38916 non-null  float64\n",
                        " 6   room_type                       38916 non-null  int64  \n",
                        "dtypes: float64(4), int64(3)\n",
                        "memory usage: 2.4 MB\n"
                    ]
                }
            ],
            "source": [
                "X_train.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Min-Max scaling para preservar la interpretación de los datos en términos de sus unidades originales.\n",
                "scaler = MinMaxScaler().fit(X_train)\n",
                "\n",
                "X_train_sc = scaler.transform(X_train)\n",
                "X_test_sc = scaler.transform(X_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "numpy.ndarray"
                        ]
                    },
                    "execution_count": 60,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "type(X_test_sc)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(9729, 7)"
                        ]
                    },
                    "execution_count": 61,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X_test_sc.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[0. 0. 0. ... 0. 0. 0.] [0.56037887 1.         1.         ... 0.82727273 0.5        0.68636364]\n"
                    ]
                }
            ],
            "source": [
                "print(np.min(X_train_sc, axis=1), np.max(X_train_sc, axis=1))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Unimos las variables escaladas con las binarias\n",
                "X_train_scaled = pd.DataFrame(X_train_sc, columns = X_train.columns)\n",
                "X_test_scaled = pd.DataFrame(X_test_sc, columns = X_test.columns)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "      <th>neighbourhood</th>\n",
                            "      <th>neighbourhood_group</th>\n",
                            "      <th>room_type</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0.25</td>\n",
                            "      <td>0.56</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.27</td>\n",
                            "      <td>0.25</td>\n",
                            "      <td>0.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0.57</td>\n",
                            "      <td>0.36</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.60</td>\n",
                            "      <td>0.58</td>\n",
                            "      <td>0.50</td>\n",
                            "      <td>0.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>0.43</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.91</td>\n",
                            "      <td>0.48</td>\n",
                            "      <td>0.75</td>\n",
                            "      <td>0.50</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>0.61</td>\n",
                            "      <td>0.33</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.15</td>\n",
                            "      <td>0.43</td>\n",
                            "      <td>0.50</td>\n",
                            "      <td>0.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>0.51</td>\n",
                            "      <td>0.37</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.29</td>\n",
                            "      <td>0.50</td>\n",
                            "      <td>0.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>38911</th>\n",
                            "      <td>0.29</td>\n",
                            "      <td>0.85</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.74</td>\n",
                            "      <td>0.29</td>\n",
                            "      <td>0.25</td>\n",
                            "      <td>1.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>38912</th>\n",
                            "      <td>0.63</td>\n",
                            "      <td>0.41</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.97</td>\n",
                            "      <td>0.58</td>\n",
                            "      <td>0.50</td>\n",
                            "      <td>0.50</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>38913</th>\n",
                            "      <td>0.28</td>\n",
                            "      <td>0.38</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.49</td>\n",
                            "      <td>0.83</td>\n",
                            "      <td>0.25</td>\n",
                            "      <td>0.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>38914</th>\n",
                            "      <td>0.37</td>\n",
                            "      <td>0.42</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.36</td>\n",
                            "      <td>0.25</td>\n",
                            "      <td>0.50</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>38915</th>\n",
                            "      <td>0.30</td>\n",
                            "      <td>0.41</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.13</td>\n",
                            "      <td>0.69</td>\n",
                            "      <td>0.25</td>\n",
                            "      <td>0.00</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>38916 rows × 7 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       latitude  longitude  calculated_host_listings_count  availability_365  \\\n",
                            "0          0.25       0.56                            0.00              0.00   \n",
                            "1          0.57       0.36                            1.00              0.60   \n",
                            "2          0.43       1.00                            0.00              0.91   \n",
                            "3          0.61       0.33                            0.00              0.15   \n",
                            "4          0.51       0.37                            0.00              0.00   \n",
                            "...         ...        ...                             ...               ...   \n",
                            "38911      0.29       0.85                            0.00              0.74   \n",
                            "38912      0.63       0.41                            1.00              0.97   \n",
                            "38913      0.28       0.38                            0.00              0.49   \n",
                            "38914      0.37       0.42                            0.00              0.00   \n",
                            "38915      0.30       0.41                            0.00              0.13   \n",
                            "\n",
                            "       neighbourhood  neighbourhood_group  room_type  \n",
                            "0               0.27                 0.25       0.00  \n",
                            "1               0.58                 0.50       0.00  \n",
                            "2               0.48                 0.75       0.50  \n",
                            "3               0.43                 0.50       0.00  \n",
                            "4               0.29                 0.50       0.00  \n",
                            "...              ...                  ...        ...  \n",
                            "38911           0.29                 0.25       1.00  \n",
                            "38912           0.58                 0.50       0.50  \n",
                            "38913           0.83                 0.25       0.00  \n",
                            "38914           0.36                 0.25       0.50  \n",
                            "38915           0.69                 0.25       0.00  \n",
                            "\n",
                            "[38916 rows x 7 columns]"
                        ]
                    },
                    "execution_count": 64,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X_train_scaled"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        " 98%|█████████▊| 41/42 [03:38<00:08,  8.79s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000892 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 978\n",
                        "[LightGBM] [Info] Number of data points in the train set: 38916, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712752\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 42/42 [03:39<00:00,  5.22s/it]\n"
                    ]
                }
            ],
            "source": [
                "reg = LazyRegressor()\n",
                "models, predictions = reg.fit(X_train_scaled, X_test_scaled, y_train, y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                               Adjusted R-Squared  R-Squared  RMSE  Time Taken\n",
                        "Model                                                                         \n",
                        "LGBMRegressor                                0.62       0.62  0.41        0.37\n",
                        "XGBRegressor                                 0.62       0.62  0.41        0.34\n",
                        "HistGradientBoostingRegressor                0.62       0.62  0.41        0.53\n",
                        "RandomForestRegressor                        0.60       0.60  0.42       13.86\n",
                        "GradientBoostingRegressor                    0.60       0.60  0.42        4.38\n",
                        "NuSVR                                        0.59       0.59  0.43       76.59\n",
                        "MLPRegressor                                 0.59       0.59  0.43        9.15\n",
                        "SVR                                          0.59       0.59  0.43       57.67\n",
                        "ExtraTreesRegressor                          0.57       0.57  0.44        6.42\n",
                        "BaggingRegressor                             0.57       0.57  0.44        1.49\n",
                        "KNeighborsRegressor                          0.56       0.56  0.44        0.28\n",
                        "Lars                                         0.51       0.51  0.47        0.01\n",
                        "LassoLarsCV                                  0.51       0.51  0.47        0.10\n",
                        "LarsCV                                       0.51       0.51  0.47        0.06\n",
                        "LassoLarsIC                                  0.51       0.51  0.47        0.04\n",
                        "TransformedTargetRegressor                   0.51       0.51  0.47        0.02\n",
                        "LinearRegression                             0.51       0.51  0.47        0.03\n",
                        "Ridge                                        0.51       0.51  0.47        0.01\n",
                        "BayesianRidge                                0.51       0.51  0.47        0.09\n",
                        "RidgeCV                                      0.51       0.51  0.47        0.04\n",
                        "LassoCV                                      0.51       0.51  0.47        0.35\n",
                        "ElasticNetCV                                 0.51       0.51  0.47        0.30\n",
                        "SGDRegressor                                 0.51       0.51  0.47        0.08\n",
                        "HuberRegressor                               0.51       0.51  0.47        0.12\n",
                        "OrthogonalMatchingPursuitCV                  0.51       0.51  0.47        0.04\n",
                        "LinearSVR                                    0.51       0.51  0.47        0.51\n",
                        "PoissonRegressor                             0.50       0.50  0.47        0.02\n",
                        "AdaBoostRegressor                            0.46       0.46  0.49        1.06\n",
                        "RANSACRegressor                              0.45       0.45  0.50        0.13\n",
                        "OrthogonalMatchingPursuit                    0.41       0.41  0.51        0.02\n",
                        "GammaRegressor                               0.40       0.40  0.52        0.04\n",
                        "TweedieRegressor                             0.40       0.40  0.52        0.02\n",
                        "DecisionTreeRegressor                        0.28       0.28  0.57        0.33\n",
                        "ExtraTreeRegressor                           0.25       0.25  0.58        0.12\n",
                        "PassiveAggressiveRegressor                   0.10       0.10  0.64        0.04\n",
                        "Lasso                                       -0.00      -0.00  0.67        0.02\n",
                        "DummyRegressor                              -0.00      -0.00  0.67        0.01\n",
                        "ElasticNet                                  -0.00      -0.00  0.67        0.02\n",
                        "LassoLars                                   -0.00      -0.00  0.67        0.01\n",
                        "QuantileRegressor                           -0.01      -0.01  0.67       44.32\n"
                    ]
                }
            ],
            "source": [
                "print(models)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002908 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003038 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003044 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003077 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004487 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003181 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003392 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003259 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003370 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002703 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003152 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002960 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003127 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002974 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003077 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003056 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003022 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006781 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003338 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003020 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003228 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003068 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003167 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003029 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003077 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002920 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002911 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002901 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003046 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002527 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002942 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002597 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002694 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000468 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002672 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003253 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002888 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002796 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002648 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002735 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002828 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002645 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000486 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002902 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002688 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002889 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000514 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002880 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002788 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002648 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005837 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002870 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002720 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003388 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003667 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002952 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002782 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003479 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003117 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002931 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003026 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003827 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003056 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002796 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002765 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002846 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003021 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002874 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003112 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003311 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003104 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003152 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003064 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002748 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002721 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002792 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002767 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002735 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002732 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002734 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002873 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002953 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002856 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002779 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002795 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002693 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002765 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006911 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002973 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003129 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003076 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003018 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003021 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002991 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002700 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003148 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005802 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003098 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002761 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002897 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002885 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003026 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002885 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003056 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003217 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003120 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003016 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003218 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002835 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002616 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002712 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002692 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002719 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002844 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003285 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000853 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003103 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003021 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002982 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003129 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005272 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003080 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003154 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003108 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003321 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003141 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003248 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003150 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002759 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002829 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002764 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002779 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002803 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003010 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003069 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003037 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003016 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005175 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003001 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003141 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003020 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002985 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003125 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003080 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002999 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003115 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002963 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003131 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002725 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002757 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002648 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002796 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002836 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002922 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002951 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003077 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002671 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009610 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003047 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003327 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003116 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003094 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008730 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003714 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002933 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003045 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002747 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003439 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002763 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003528 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002781 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002769 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002765 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002761 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002899 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002878 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005556 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003135 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004530 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003033 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006232 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003085 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002789 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002789 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002863 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002694 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003715 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004382 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003058 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003035 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003105 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002995 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003053 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003005 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002996 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003038 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003029 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002839 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003235 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010087 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003602 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003263 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001783 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000726 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004893 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003010 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002996 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003034 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002957 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001199 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003018 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003039 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003515 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002958 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002992 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003118 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003243 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002911 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003015 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003042 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003126 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002853 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002950 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002943 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003069 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002704 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003082 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003067 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003378 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003357 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003352 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003069 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002997 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003149 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007711 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005471 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003173 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002760 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002548 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002762 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002775 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002779 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003058 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003071 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006848 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003013 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002925 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000634 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 959\n",
                        "[LightGBM] [Info] Number of data points in the train set: 38916, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712752\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-1 {\n",
                            "  /* Definition of color scheme common for light and dark mode */\n",
                            "  --sklearn-color-text: black;\n",
                            "  --sklearn-color-line: gray;\n",
                            "  /* Definition of color scheme for unfitted estimators */\n",
                            "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
                            "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
                            "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
                            "  --sklearn-color-unfitted-level-3: chocolate;\n",
                            "  /* Definition of color scheme for fitted estimators */\n",
                            "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
                            "  --sklearn-color-fitted-level-1: #d4ebff;\n",
                            "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
                            "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
                            "\n",
                            "  /* Specific color for light theme */\n",
                            "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                            "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
                            "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                            "  --sklearn-color-icon: #696969;\n",
                            "\n",
                            "  @media (prefers-color-scheme: dark) {\n",
                            "    /* Redefinition of color scheme for dark theme */\n",
                            "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                            "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
                            "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                            "    --sklearn-color-icon: #878787;\n",
                            "  }\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 pre {\n",
                            "  padding: 0;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 input.sk-hidden--visually {\n",
                            "  border: 0;\n",
                            "  clip: rect(1px 1px 1px 1px);\n",
                            "  clip: rect(1px, 1px, 1px, 1px);\n",
                            "  height: 1px;\n",
                            "  margin: -1px;\n",
                            "  overflow: hidden;\n",
                            "  padding: 0;\n",
                            "  position: absolute;\n",
                            "  width: 1px;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-dashed-wrapped {\n",
                            "  border: 1px dashed var(--sklearn-color-line);\n",
                            "  margin: 0 0.4em 0.5em 0.4em;\n",
                            "  box-sizing: border-box;\n",
                            "  padding-bottom: 0.4em;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-container {\n",
                            "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
                            "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
                            "     so we also need the `!important` here to be able to override the\n",
                            "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
                            "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
                            "  display: inline-block !important;\n",
                            "  position: relative;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-text-repr-fallback {\n",
                            "  display: none;\n",
                            "}\n",
                            "\n",
                            "div.sk-parallel-item,\n",
                            "div.sk-serial,\n",
                            "div.sk-item {\n",
                            "  /* draw centered vertical line to link estimators */\n",
                            "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
                            "  background-size: 2px 100%;\n",
                            "  background-repeat: no-repeat;\n",
                            "  background-position: center center;\n",
                            "}\n",
                            "\n",
                            "/* Parallel-specific style estimator block */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item::after {\n",
                            "  content: \"\";\n",
                            "  width: 100%;\n",
                            "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
                            "  flex-grow: 1;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel {\n",
                            "  display: flex;\n",
                            "  align-items: stretch;\n",
                            "  justify-content: center;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  position: relative;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
                            "  align-self: flex-end;\n",
                            "  width: 50%;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
                            "  align-self: flex-start;\n",
                            "  width: 50%;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
                            "  width: 0;\n",
                            "}\n",
                            "\n",
                            "/* Serial-specific style estimator block */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-serial {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "  align-items: center;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  padding-right: 1em;\n",
                            "  padding-left: 1em;\n",
                            "}\n",
                            "\n",
                            "\n",
                            "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
                            "clickable and can be expanded/collapsed.\n",
                            "- Pipeline and ColumnTransformer use this feature and define the default style\n",
                            "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
                            "*/\n",
                            "\n",
                            "/* Pipeline and ColumnTransformer style (default) */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable {\n",
                            "  /* Default theme specific background. It is overwritten whether we have a\n",
                            "  specific estimator or a Pipeline/ColumnTransformer */\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "}\n",
                            "\n",
                            "/* Toggleable label */\n",
                            "#sk-container-id-1 label.sk-toggleable__label {\n",
                            "  cursor: pointer;\n",
                            "  display: block;\n",
                            "  width: 100%;\n",
                            "  margin-bottom: 0;\n",
                            "  padding: 0.5em;\n",
                            "  box-sizing: border-box;\n",
                            "  text-align: center;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
                            "  /* Arrow on the left of the label */\n",
                            "  content: \"▸\";\n",
                            "  float: left;\n",
                            "  margin-right: 0.25em;\n",
                            "  color: var(--sklearn-color-icon);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "}\n",
                            "\n",
                            "/* Toggleable content - dropdown */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable__content {\n",
                            "  max-height: 0;\n",
                            "  max-width: 0;\n",
                            "  overflow: hidden;\n",
                            "  text-align: left;\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable__content pre {\n",
                            "  margin: 0.2em;\n",
                            "  border-radius: 0.25em;\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
                            "  /* Expand drop-down */\n",
                            "  max-height: 200px;\n",
                            "  max-width: 100%;\n",
                            "  overflow: auto;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
                            "  content: \"▾\";\n",
                            "}\n",
                            "\n",
                            "/* Pipeline/ColumnTransformer-specific style */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Estimator-specific style */\n",
                            "\n",
                            "/* Colorize estimator box */\n",
                            "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
                            "#sk-container-id-1 div.sk-label label {\n",
                            "  /* The background is the default theme color */\n",
                            "  color: var(--sklearn-color-text-on-default-background);\n",
                            "}\n",
                            "\n",
                            "/* On hover, darken the color of the background */\n",
                            "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Label box, darken color on hover, fitted */\n",
                            "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Estimator label */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label label {\n",
                            "  font-family: monospace;\n",
                            "  font-weight: bold;\n",
                            "  display: inline-block;\n",
                            "  line-height: 1.2em;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label-container {\n",
                            "  text-align: center;\n",
                            "}\n",
                            "\n",
                            "/* Estimator-specific */\n",
                            "#sk-container-id-1 div.sk-estimator {\n",
                            "  font-family: monospace;\n",
                            "  border: 1px dotted var(--sklearn-color-border-box);\n",
                            "  border-radius: 0.25em;\n",
                            "  box-sizing: border-box;\n",
                            "  margin-bottom: 0.5em;\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-estimator.fitted {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "/* on hover */\n",
                            "#sk-container-id-1 div.sk-estimator:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
                            "\n",
                            "/* Common style for \"i\" and \"?\" */\n",
                            "\n",
                            ".sk-estimator-doc-link,\n",
                            "a:link.sk-estimator-doc-link,\n",
                            "a:visited.sk-estimator-doc-link {\n",
                            "  float: right;\n",
                            "  font-size: smaller;\n",
                            "  line-height: 1em;\n",
                            "  font-family: monospace;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  border-radius: 1em;\n",
                            "  height: 1em;\n",
                            "  width: 1em;\n",
                            "  text-decoration: none !important;\n",
                            "  margin-left: 1ex;\n",
                            "  /* unfitted */\n",
                            "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-unfitted-level-1);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link.fitted,\n",
                            "a:link.sk-estimator-doc-link.fitted,\n",
                            "a:visited.sk-estimator-doc-link.fitted {\n",
                            "  /* fitted */\n",
                            "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-fitted-level-1);\n",
                            "}\n",
                            "\n",
                            "/* On hover */\n",
                            "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
                            ".sk-estimator-doc-link:hover,\n",
                            "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
                            ".sk-estimator-doc-link:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
                            ".sk-estimator-doc-link.fitted:hover,\n",
                            "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
                            ".sk-estimator-doc-link.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "/* Span, style for the box shown on hovering the info icon */\n",
                            ".sk-estimator-doc-link span {\n",
                            "  display: none;\n",
                            "  z-index: 9999;\n",
                            "  position: relative;\n",
                            "  font-weight: normal;\n",
                            "  right: .2ex;\n",
                            "  padding: .5ex;\n",
                            "  margin: .5ex;\n",
                            "  width: min-content;\n",
                            "  min-width: 20ex;\n",
                            "  max-width: 50ex;\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  box-shadow: 2pt 2pt 4pt #999;\n",
                            "  /* unfitted */\n",
                            "  background: var(--sklearn-color-unfitted-level-0);\n",
                            "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link.fitted span {\n",
                            "  /* fitted */\n",
                            "  background: var(--sklearn-color-fitted-level-0);\n",
                            "  border: var(--sklearn-color-fitted-level-3);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link:hover span {\n",
                            "  display: block;\n",
                            "}\n",
                            "\n",
                            "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
                            "\n",
                            "#sk-container-id-1 a.estimator_doc_link {\n",
                            "  float: right;\n",
                            "  font-size: 1rem;\n",
                            "  line-height: 1em;\n",
                            "  font-family: monospace;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  border-radius: 1rem;\n",
                            "  height: 1rem;\n",
                            "  width: 1rem;\n",
                            "  text-decoration: none;\n",
                            "  /* unfitted */\n",
                            "  color: var(--sklearn-color-unfitted-level-1);\n",
                            "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
                            "  /* fitted */\n",
                            "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-fitted-level-1);\n",
                            "}\n",
                            "\n",
                            "/* On hover */\n",
                            "#sk-container-id-1 a.estimator_doc_link:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-3);\n",
                            "}\n",
                            "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=LGBMRegressor(), n_iter=50, n_jobs=-1,\n",
                            "                   param_distributions={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;, &#x27;dart&#x27;, &#x27;rf&#x27;],\n",
                            "                                        &#x27;colsample_bytree&#x27;: [0.5, 0.7, 0.8],\n",
                            "                                        &#x27;learning_rate&#x27;: array([0.001     , 0.00562341, 0.03162278, 0.17782794, 1.        ]),\n",
                            "                                        &#x27;max_depth&#x27;: array([ 50,  60,  70,  80,  90, 100, 110, 120, 130, 140, 150]),\n",
                            "                                        &#x27;num_leaves&#x27;: array([ 50,  60,  70,  80,  90, 100, 110, 120, 130, 140, 150]),\n",
                            "                                        &#x27;subsample&#x27;: [0.5, 0.7, 0.8]},\n",
                            "                   random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
                            "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=5, estimator=LGBMRegressor(), n_iter=50, n_jobs=-1,\n",
                            "                   param_distributions={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;, &#x27;dart&#x27;, &#x27;rf&#x27;],\n",
                            "                                        &#x27;colsample_bytree&#x27;: [0.5, 0.7, 0.8],\n",
                            "                                        &#x27;learning_rate&#x27;: array([0.001     , 0.00562341, 0.03162278, 0.17782794, 1.        ]),\n",
                            "                                        &#x27;max_depth&#x27;: array([ 50,  60,  70,  80,  90, 100, 110, 120, 130, 140, 150]),\n",
                            "                                        &#x27;num_leaves&#x27;: array([ 50,  60,  70,  80,  90, 100, 110, 120, 130, 140, 150]),\n",
                            "                                        &#x27;subsample&#x27;: [0.5, 0.7, 0.8]},\n",
                            "                   random_state=42, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
                            "                   verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor()</pre></div> </div></div></div></div></div></div></div></div></div>"
                        ],
                        "text/plain": [
                            "RandomizedSearchCV(cv=5, estimator=LGBMRegressor(), n_iter=50, n_jobs=-1,\n",
                            "                   param_distributions={'boosting_type': ['gbdt', 'dart', 'rf'],\n",
                            "                                        'colsample_bytree': [0.5, 0.7, 0.8],\n",
                            "                                        'learning_rate': array([0.001     , 0.00562341, 0.03162278, 0.17782794, 1.        ]),\n",
                            "                                        'max_depth': array([ 50,  60,  70,  80,  90, 100, 110, 120, 130, 140, 150]),\n",
                            "                                        'num_leaves': array([ 50,  60,  70,  80,  90, 100, 110, 120, 130, 140, 150]),\n",
                            "                                        'subsample': [0.5, 0.7, 0.8]},\n",
                            "                   random_state=42, scoring='neg_root_mean_squared_error',\n",
                            "                   verbose=1)"
                        ]
                    },
                    "execution_count": 67,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import lightgbm as lgb\n",
                "from sklearn.model_selection import RandomizedSearchCV\n",
                "\n",
                "model = lgb.LGBMRegressor()\n",
                "\n",
                "param_dict = {\n",
                "    'boosting_type': ['gbdt', 'dart', 'rf'],\n",
                "    'num_leaves': np.arange(50, 151, 10),\n",
                "    'max_depth': np.arange(50, 151, 10),\n",
                "    'learning_rate': np.logspace(-3, 0, 5),\n",
                "    'subsample': [0.5, 0.7, 0.8],\n",
                "    'colsample_bytree': [0.5, 0.7, 0.8]\n",
                "    }  \n",
                "\n",
                "random_search = RandomizedSearchCV(model, param_distributions=param_dict, n_iter=50, cv=5, random_state=42, n_jobs=-1, scoring='neg_root_mean_squared_error', verbose=1)\n",
                "random_search.fit(X_train_scaled, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Mejores hiperparámetros encontrados:\n",
                        "{'subsample': 0.8, 'num_leaves': 50, 'max_depth': 150, 'learning_rate': 0.1778279410038923, 'colsample_bytree': 0.8, 'boosting_type': 'gbdt'}\n",
                        "Mejor puntuación (RMSE) en el conjunto de prueba:\n",
                        "0.41439300751340913\n"
                    ]
                }
            ],
            "source": [
                "# Mostramos los mejores hiperparámetros encontrados\n",
                "print(\"Mejores hiperparámetros encontrados:\")\n",
                "print(random_search.best_params_)\n",
                "\n",
                "# Mostramos el rendimiento del mejor modelo\n",
                "print(\"Mejor puntuación (RMSE) en el conjunto de prueba:\")\n",
                "print(-1*random_search.best_score_)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004194 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011177 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=75; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=75; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003139 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003194 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=75; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=75; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=75; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003016 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002999 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002946 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003079 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003156 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=115; total time=   0.4s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003006 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004078 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=90, num_leaves=85; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=90, num_leaves=85; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002868 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003175 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=90, num_leaves=85; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003173 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=90, num_leaves=85; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=90, num_leaves=85; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002999 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003071 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=110, num_leaves=105; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=110, num_leaves=105; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003252 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003055 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=110, num_leaves=105; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003093 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=110, num_leaves=105; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=110, num_leaves=105; total time=   0.4s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002975 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003078 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=110, num_leaves=105; total time=   0.6s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=110, num_leaves=105; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003137 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003075 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=110, num_leaves=105; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=110, num_leaves=105; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000590 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=110, num_leaves=105; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002969 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003272 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=90, num_leaves=75; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=90, num_leaves=75; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003077 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003019 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=90, num_leaves=75; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=90, num_leaves=75; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000539 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=90, num_leaves=75; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000856 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003388 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003231 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003856 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000555 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=115; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003136 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003791 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003339 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001345 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002763 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=115; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003411 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003038 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=85; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000740 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=85; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004441 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=85; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003479 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=85; total time=   0.6s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=85; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002895 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003022 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=75; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=75; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000855 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003115 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=75; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=75; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=75; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002844 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008978 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=105; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=105; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004904 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003060 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=105; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003272 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=105; total time=   0.6s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=105; total time=   0.4s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002967 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002772 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=95; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003129 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=95; total time=   0.7s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003039 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=95; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003115 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=95; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=95; total time=   0.4s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003427 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007566 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002966 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003013 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=115; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000534 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=115; total time=   0.4s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002969 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006058 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=75; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003144 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=75; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003239 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=75; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003166 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=75; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=75; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002938 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003284 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=120, num_leaves=65; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=120, num_leaves=65; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004393 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=120, num_leaves=65; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003106 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=120, num_leaves=65; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=120, num_leaves=65; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008795 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007842 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=115; total time=   0.8s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=115; total time=   0.8s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003024 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003008 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=115; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=115; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=115; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003339 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002894 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=120, num_leaves=85; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003682 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=120, num_leaves=85; total time=   0.7s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003075 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=120, num_leaves=85; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003158 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=120, num_leaves=85; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=120, num_leaves=85; total time=   0.4s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002907 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001111 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=120, num_leaves=105; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003140 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=120, num_leaves=105; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012832 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=120, num_leaves=105; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003235 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=120, num_leaves=105; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=120, num_leaves=105; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008101 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004813 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=90, num_leaves=65; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003254 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=90, num_leaves=65; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003197 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=90, num_leaves=65; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=90, num_leaves=65; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003016 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=90, num_leaves=65; total time=   0.4s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002884 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007378 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=65; total time=   0.6s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=65; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000728 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004323 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=65; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003175 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=65; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=65; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011613 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012133 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "\n",
                        "[LightGBM] [Info] Start training from score 4.710578[LightGBM] [Info] Start training from score 4.711471\n",
                        "\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=90, num_leaves=95; total time=   0.7s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003125 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=90, num_leaves=95; total time=   0.8s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003079 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=90, num_leaves=95; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003187 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=90, num_leaves=95; total time=   0.6s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=90, num_leaves=95; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003184 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000910 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=105; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=105; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000832 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003054 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=105; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002938 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=105; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=105; total time=   0.4s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002952 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003012 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=120, num_leaves=115; total time=   0.7s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=120, num_leaves=115; total time=   0.7s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003030 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000879 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=120, num_leaves=115; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=120, num_leaves=115; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000564 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=120, num_leaves=115; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002957 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013775 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=100, num_leaves=75; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=100, num_leaves=75; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002933 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003049 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=100, num_leaves=75; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=100, num_leaves=75; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=100, num_leaves=75; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002776 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003075 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=90, num_leaves=85; total time=   0.6s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=90, num_leaves=85; total time=   0.7s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001249 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003033 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=90, num_leaves=85; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=90, num_leaves=85; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000539 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=90, num_leaves=85; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002941 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007858 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=110, num_leaves=65; total time=   0.6s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=110, num_leaves=65; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002891 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003094 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=110, num_leaves=65; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=110, num_leaves=65; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=110, num_leaves=65; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000776 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003190 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=120, num_leaves=75; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003182 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=120, num_leaves=75; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003064 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=120, num_leaves=75; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003315 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=120, num_leaves=75; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=120, num_leaves=75; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004908 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004545 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=90, num_leaves=75; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=90, num_leaves=75; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002852 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003043 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=90, num_leaves=75; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003425 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=90, num_leaves=75; total time=   0.7s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=90, num_leaves=75; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002967 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003045 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=90, num_leaves=75; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=90, num_leaves=75; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005146 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003109 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=90, num_leaves=75; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=90, num_leaves=75; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002902 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=90, num_leaves=75; total time=   0.4s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000711 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000763 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=90, num_leaves=65; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000890 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=90, num_leaves=65; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002840 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=90, num_leaves=65; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003302 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=90, num_leaves=65; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=90, num_leaves=65; total time=   0.4s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010392 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014401 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=90, num_leaves=65; total time=   0.8s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003004 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=90, num_leaves=65; total time=   0.9s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003183 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=90, num_leaves=65; total time=   0.7s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=90, num_leaves=65; total time=   0.7s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003065 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=90, num_leaves=65; total time=   0.4s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003398 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004036 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=120, num_leaves=95; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=120, num_leaves=95; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002953 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004854 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=120, num_leaves=95; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003153 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=120, num_leaves=95; total time=   0.6s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=120, num_leaves=95; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005429 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003073 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=85; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=85; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008503 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007279 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=85; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=85; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002829 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=100, num_leaves=85; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002915 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003091 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=110, num_leaves=65; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=110, num_leaves=65; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003074 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002974 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=110, num_leaves=65; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=110, num_leaves=65; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=110, num_leaves=65; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003737 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=95; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=95; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002974 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003074 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=95; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=95; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000539 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=95; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003121 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004111 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=110, num_leaves=115; total time=   0.6s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=110, num_leaves=115; total time=   0.7s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002990 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003056 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=110, num_leaves=115; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=110, num_leaves=115; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003098 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=110, num_leaves=115; total time=   0.4s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003178 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000882 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=120, num_leaves=75; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=120, num_leaves=75; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003072 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003030 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=120, num_leaves=75; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003222 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=120, num_leaves=75; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=120, num_leaves=75; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003172 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006538 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=90, num_leaves=115; total time=   0.6s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=90, num_leaves=115; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002966 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003094 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=90, num_leaves=115; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003165 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=90, num_leaves=115; total time=   0.6s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=90, num_leaves=115; total time=   0.4s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003002 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000743 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=105; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003184 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=105; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003162 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=105; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=105; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=105; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002914 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006406 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=90, num_leaves=105; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=90, num_leaves=105; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003110 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003098 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=90, num_leaves=105; total time=   0.6s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=90, num_leaves=105; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=90, num_leaves=105; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002910 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003133 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=65; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=65; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000764 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003111 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=65; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=65; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000569 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=120, num_leaves=65; total time=   0.2s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004242 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003024 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=95; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=95; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006219 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003091 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=95; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003107 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=95; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=95; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002955 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001533 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=100, num_leaves=65; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=100, num_leaves=65; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003090 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003898 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=100, num_leaves=65; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=100, num_leaves=65; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003062 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=100, num_leaves=65; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002850 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003068 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003228 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012806 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=100, num_leaves=115; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003244 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=100, num_leaves=115; total time=   0.7s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=100, num_leaves=115; total time=   0.4s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000760 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002962 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003065 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003011 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003124 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=100, num_leaves=115; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.17, max_depth=100, num_leaves=115; total time=   0.4s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002818 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003294 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=110, num_leaves=95; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=110, num_leaves=95; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002857 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003034 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=110, num_leaves=95; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=110, num_leaves=95; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000542 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=110, num_leaves=95; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002923 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003056 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=85; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=85; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004401 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003103 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=85; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003180 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=85; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=85; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002892 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003024 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=65; total time=   0.4s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=65; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002949 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003050 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=65; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=65; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002632 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.13, max_depth=100, num_leaves=65; total time=   0.3s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002957 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014740 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=115; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=115; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003091 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=115; total time=   0.6s\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000746 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=115; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.2, max_depth=110, num_leaves=115; total time=   0.4s\n",
                        "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000737 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 955\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.711471\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003014 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 953\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31132, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.710578\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=120, num_leaves=105; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=120, num_leaves=105; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003322 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 957\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000917 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 952\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.716203\n",
                        "[LightGBM] [Info] Start training from score 4.713416\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=120, num_leaves=105; total time=   0.5s\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=120, num_leaves=105; total time=   0.5s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003191 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 958\n",
                        "[LightGBM] [Info] Number of data points in the train set: 31133, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712094\n",
                        "[CV] END boosting_type=gbdt, learning_rate=0.15, max_depth=120, num_leaves=105; total time=   0.4s\n",
                        "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003520 seconds.\n",
                        "You can set `force_col_wise=true` to remove the overhead.\n",
                        "[LightGBM] [Info] Total Bins 959\n",
                        "[LightGBM] [Info] Number of data points in the train set: 38916, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712752\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-2 {\n",
                            "  /* Definition of color scheme common for light and dark mode */\n",
                            "  --sklearn-color-text: black;\n",
                            "  --sklearn-color-line: gray;\n",
                            "  /* Definition of color scheme for unfitted estimators */\n",
                            "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
                            "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
                            "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
                            "  --sklearn-color-unfitted-level-3: chocolate;\n",
                            "  /* Definition of color scheme for fitted estimators */\n",
                            "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
                            "  --sklearn-color-fitted-level-1: #d4ebff;\n",
                            "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
                            "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
                            "\n",
                            "  /* Specific color for light theme */\n",
                            "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                            "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
                            "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                            "  --sklearn-color-icon: #696969;\n",
                            "\n",
                            "  @media (prefers-color-scheme: dark) {\n",
                            "    /* Redefinition of color scheme for dark theme */\n",
                            "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                            "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
                            "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                            "    --sklearn-color-icon: #878787;\n",
                            "  }\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 pre {\n",
                            "  padding: 0;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 input.sk-hidden--visually {\n",
                            "  border: 0;\n",
                            "  clip: rect(1px 1px 1px 1px);\n",
                            "  clip: rect(1px, 1px, 1px, 1px);\n",
                            "  height: 1px;\n",
                            "  margin: -1px;\n",
                            "  overflow: hidden;\n",
                            "  padding: 0;\n",
                            "  position: absolute;\n",
                            "  width: 1px;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-dashed-wrapped {\n",
                            "  border: 1px dashed var(--sklearn-color-line);\n",
                            "  margin: 0 0.4em 0.5em 0.4em;\n",
                            "  box-sizing: border-box;\n",
                            "  padding-bottom: 0.4em;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-container {\n",
                            "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
                            "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
                            "     so we also need the `!important` here to be able to override the\n",
                            "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
                            "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
                            "  display: inline-block !important;\n",
                            "  position: relative;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-text-repr-fallback {\n",
                            "  display: none;\n",
                            "}\n",
                            "\n",
                            "div.sk-parallel-item,\n",
                            "div.sk-serial,\n",
                            "div.sk-item {\n",
                            "  /* draw centered vertical line to link estimators */\n",
                            "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
                            "  background-size: 2px 100%;\n",
                            "  background-repeat: no-repeat;\n",
                            "  background-position: center center;\n",
                            "}\n",
                            "\n",
                            "/* Parallel-specific style estimator block */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel-item::after {\n",
                            "  content: \"\";\n",
                            "  width: 100%;\n",
                            "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
                            "  flex-grow: 1;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel {\n",
                            "  display: flex;\n",
                            "  align-items: stretch;\n",
                            "  justify-content: center;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  position: relative;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel-item {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
                            "  align-self: flex-end;\n",
                            "  width: 50%;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
                            "  align-self: flex-start;\n",
                            "  width: 50%;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
                            "  width: 0;\n",
                            "}\n",
                            "\n",
                            "/* Serial-specific style estimator block */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-serial {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "  align-items: center;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  padding-right: 1em;\n",
                            "  padding-left: 1em;\n",
                            "}\n",
                            "\n",
                            "\n",
                            "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
                            "clickable and can be expanded/collapsed.\n",
                            "- Pipeline and ColumnTransformer use this feature and define the default style\n",
                            "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
                            "*/\n",
                            "\n",
                            "/* Pipeline and ColumnTransformer style (default) */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-toggleable {\n",
                            "  /* Default theme specific background. It is overwritten whether we have a\n",
                            "  specific estimator or a Pipeline/ColumnTransformer */\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "}\n",
                            "\n",
                            "/* Toggleable label */\n",
                            "#sk-container-id-2 label.sk-toggleable__label {\n",
                            "  cursor: pointer;\n",
                            "  display: block;\n",
                            "  width: 100%;\n",
                            "  margin-bottom: 0;\n",
                            "  padding: 0.5em;\n",
                            "  box-sizing: border-box;\n",
                            "  text-align: center;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
                            "  /* Arrow on the left of the label */\n",
                            "  content: \"▸\";\n",
                            "  float: left;\n",
                            "  margin-right: 0.25em;\n",
                            "  color: var(--sklearn-color-icon);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "}\n",
                            "\n",
                            "/* Toggleable content - dropdown */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-toggleable__content {\n",
                            "  max-height: 0;\n",
                            "  max-width: 0;\n",
                            "  overflow: hidden;\n",
                            "  text-align: left;\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-toggleable__content pre {\n",
                            "  margin: 0.2em;\n",
                            "  border-radius: 0.25em;\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
                            "  /* Expand drop-down */\n",
                            "  max-height: 200px;\n",
                            "  max-width: 100%;\n",
                            "  overflow: auto;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
                            "  content: \"▾\";\n",
                            "}\n",
                            "\n",
                            "/* Pipeline/ColumnTransformer-specific style */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Estimator-specific style */\n",
                            "\n",
                            "/* Colorize estimator box */\n",
                            "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
                            "#sk-container-id-2 div.sk-label label {\n",
                            "  /* The background is the default theme color */\n",
                            "  color: var(--sklearn-color-text-on-default-background);\n",
                            "}\n",
                            "\n",
                            "/* On hover, darken the color of the background */\n",
                            "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Label box, darken color on hover, fitted */\n",
                            "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Estimator label */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-label label {\n",
                            "  font-family: monospace;\n",
                            "  font-weight: bold;\n",
                            "  display: inline-block;\n",
                            "  line-height: 1.2em;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-label-container {\n",
                            "  text-align: center;\n",
                            "}\n",
                            "\n",
                            "/* Estimator-specific */\n",
                            "#sk-container-id-2 div.sk-estimator {\n",
                            "  font-family: monospace;\n",
                            "  border: 1px dotted var(--sklearn-color-border-box);\n",
                            "  border-radius: 0.25em;\n",
                            "  box-sizing: border-box;\n",
                            "  margin-bottom: 0.5em;\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-estimator.fitted {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "/* on hover */\n",
                            "#sk-container-id-2 div.sk-estimator:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
                            "\n",
                            "/* Common style for \"i\" and \"?\" */\n",
                            "\n",
                            ".sk-estimator-doc-link,\n",
                            "a:link.sk-estimator-doc-link,\n",
                            "a:visited.sk-estimator-doc-link {\n",
                            "  float: right;\n",
                            "  font-size: smaller;\n",
                            "  line-height: 1em;\n",
                            "  font-family: monospace;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  border-radius: 1em;\n",
                            "  height: 1em;\n",
                            "  width: 1em;\n",
                            "  text-decoration: none !important;\n",
                            "  margin-left: 1ex;\n",
                            "  /* unfitted */\n",
                            "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-unfitted-level-1);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link.fitted,\n",
                            "a:link.sk-estimator-doc-link.fitted,\n",
                            "a:visited.sk-estimator-doc-link.fitted {\n",
                            "  /* fitted */\n",
                            "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-fitted-level-1);\n",
                            "}\n",
                            "\n",
                            "/* On hover */\n",
                            "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
                            ".sk-estimator-doc-link:hover,\n",
                            "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
                            ".sk-estimator-doc-link:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
                            ".sk-estimator-doc-link.fitted:hover,\n",
                            "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
                            ".sk-estimator-doc-link.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "/* Span, style for the box shown on hovering the info icon */\n",
                            ".sk-estimator-doc-link span {\n",
                            "  display: none;\n",
                            "  z-index: 9999;\n",
                            "  position: relative;\n",
                            "  font-weight: normal;\n",
                            "  right: .2ex;\n",
                            "  padding: .5ex;\n",
                            "  margin: .5ex;\n",
                            "  width: min-content;\n",
                            "  min-width: 20ex;\n",
                            "  max-width: 50ex;\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  box-shadow: 2pt 2pt 4pt #999;\n",
                            "  /* unfitted */\n",
                            "  background: var(--sklearn-color-unfitted-level-0);\n",
                            "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link.fitted span {\n",
                            "  /* fitted */\n",
                            "  background: var(--sklearn-color-fitted-level-0);\n",
                            "  border: var(--sklearn-color-fitted-level-3);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link:hover span {\n",
                            "  display: block;\n",
                            "}\n",
                            "\n",
                            "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
                            "\n",
                            "#sk-container-id-2 a.estimator_doc_link {\n",
                            "  float: right;\n",
                            "  font-size: 1rem;\n",
                            "  line-height: 1em;\n",
                            "  font-family: monospace;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  border-radius: 1rem;\n",
                            "  height: 1rem;\n",
                            "  width: 1rem;\n",
                            "  text-decoration: none;\n",
                            "  /* unfitted */\n",
                            "  color: var(--sklearn-color-unfitted-level-1);\n",
                            "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
                            "  /* fitted */\n",
                            "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-fitted-level-1);\n",
                            "}\n",
                            "\n",
                            "/* On hover */\n",
                            "#sk-container-id-2 a.estimator_doc_link:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-3);\n",
                            "}\n",
                            "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5, estimator=LGBMRegressor(), n_jobs=-1, random_state=42,\n",
                            "              scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
                            "              search_spaces={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;],\n",
                            "                             &#x27;learning_rate&#x27;: [0.13, 0.15, 0.17, 0.2],\n",
                            "                             &#x27;max_depth&#x27;: array([ 90, 100, 110, 120]),\n",
                            "                             &#x27;num_leaves&#x27;: array([ 65,  75,  85,  95, 105, 115])},\n",
                            "              verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BayesSearchCV<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BayesSearchCV(cv=5, estimator=LGBMRegressor(), n_jobs=-1, random_state=42,\n",
                            "              scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
                            "              search_spaces={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;],\n",
                            "                             &#x27;learning_rate&#x27;: [0.13, 0.15, 0.17, 0.2],\n",
                            "                             &#x27;max_depth&#x27;: array([ 90, 100, 110, 120]),\n",
                            "                             &#x27;num_leaves&#x27;: array([ 65,  75,  85,  95, 105, 115])},\n",
                            "              verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor()</pre></div> </div></div></div></div></div></div></div></div></div>"
                        ],
                        "text/plain": [
                            "BayesSearchCV(cv=5, estimator=LGBMRegressor(), n_jobs=-1, random_state=42,\n",
                            "              scoring='neg_root_mean_squared_error',\n",
                            "              search_spaces={'boosting_type': ['gbdt'],\n",
                            "                             'learning_rate': [0.13, 0.15, 0.17, 0.2],\n",
                            "                             'max_depth': array([ 90, 100, 110, 120]),\n",
                            "                             'num_leaves': array([ 65,  75,  85,  95, 105, 115])},\n",
                            "              verbose=2)"
                        ]
                    },
                    "execution_count": 69,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from skopt import BayesSearchCV\n",
                "\n",
                "model = lgb.LGBMRegressor()\n",
                "\n",
                "param_dict = {'boosting_type': ['gbdt'],\n",
                "              'num_leaves': np.arange(65, 120, 10),\n",
                "              'max_depth':np.arange(90, 130, 10),\n",
                "              'learning_rate':[0.13,0.15,0.17,0.2]}\n",
                "\n",
                "# Inicializa el objeto BayesSearchCV\n",
                "opt = BayesSearchCV(\n",
                "    model,\n",
                "    param_dict,\n",
                "    n_iter=50,  # Número de iteraciones de la búsqueda\n",
                "    cv=5,       # Número de divisiones en validación cruzada\n",
                "    n_jobs=-1,\n",
                "    random_state=42,\n",
                "    scoring='neg_root_mean_squared_error',  # Métrica a optimizar\n",
                "    verbose=2\n",
                ")\n",
                "\n",
                "# Realiza la búsqueda bayesiana\n",
                "opt.fit(X_train_scaled, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Mejores hiperparámetros encontrados:\n",
                        "OrderedDict([('boosting_type', 'gbdt'), ('learning_rate', 0.13), ('max_depth', 120), ('num_leaves', 65)])\n",
                        "Mejor puntuación (RMSE) en el conjunto de prueba:\n",
                        "0.41414038427779276\n"
                    ]
                }
            ],
            "source": [
                "# Imprime los mejores hiperparámetros\n",
                "print(\"Mejores hiperparámetros encontrados:\")\n",
                "print(opt.best_params_)\n",
                "\n",
                "# Mostramos el rendimiento del mejor modelo\n",
                "print(\"Mejor puntuación (RMSE) en el conjunto de prueba:\")\n",
                "print(-1*opt.best_score_)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "modelo = opt.best_estimator_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred_train = np.exp(modelo.predict(X_train_scaled))\n",
                "y_pred_test = np.exp(modelo.predict(X_test_scaled))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_train_euros = np.exp(y_train)\n",
                "y_test_euros = np.exp(y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "17.08305951117629"
                        ]
                    },
                    "execution_count": 74,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "min(y_train_euros)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Error absoluto medio (MAE): Es la media del valor absoluto de las diferencias entre las predicciones y los valores reales. Ayuda a comprender la magnitud promedio de los errores en las predicciones.\n",
                "\n",
                "Coeficiente de determinación (R2): Es una medida de la proporción de la varianza en la variable dependiente que es predecible a partir de las variables independientes. Un valor más cercano a 1 indica un mejor ajuste del modelo.\n",
                "\n",
                "Error porcentual absoluto medio (MAPE): Calcula el promedio del error porcentual absoluto entre las predicciones y los valores reales. Es una medida relativa que proporciona una idea de la precisión del modelo en términos porcentuales.\n",
                "\n",
                "El código imprime los resultados de estas métricas tanto para el conjunto de entrenamiento como para el conjunto de prueba, lo que proporciona una visión general del rendimiento del modelo en ambos conjuntos de datos. Esto es crucial para evaluar si el modelo generaliza bien a nuevos datos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import *"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "42.91402546415306\n",
                        "46.415279529931844\n"
                    ]
                }
            ],
            "source": [
                "print(mean_absolute_error(y_train_euros,y_pred_train))\n",
                "print(mean_absolute_error(y_test_euros,y_pred_test))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.4904328114516019\n",
                        "0.43624488085666135\n"
                    ]
                }
            ],
            "source": [
                "print(r2_score(y_train_euros,y_pred_train))\n",
                "print(r2_score(y_test_euros,y_pred_test))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "29.08002797696027\n",
                        "31.58833860316098\n"
                    ]
                }
            ],
            "source": [
                "print(mean_absolute_percentage_error(y_train_euros,y_pred_train)*100)\n",
                "print(mean_absolute_percentage_error(y_test_euros,y_pred_test)*100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "BaggingRegressor es un metaestimador que ajusta varios estimadores base en subconjuntos aleatorios del conjunto de datos original y luego promedia sus predicciones para mejorar la precisión y la robustez del modelo.\n",
                "\n",
                "Puedes usar BaggingRegressor para entrenar modelos de regresión utilizando diferentes algoritmos base, como árboles de decisión, regresión lineal, SVM, etc. Este enfoque de ensamblaje puede ser útil para reducir el sobreajuste y mejorar el rendimiento predictivo del modelo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.ensemble import BaggingRegressor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002005 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 959\n",
                        "[LightGBM] [Info] Number of data points in the train set: 38916, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.712892\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000687 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 959\n",
                        "[LightGBM] [Info] Number of data points in the train set: 38916, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.708941\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 959\n",
                        "[LightGBM] [Info] Number of data points in the train set: 38916, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.703431\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001087 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 959\n",
                        "[LightGBM] [Info] Number of data points in the train set: 38916, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.708079\n",
                        "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000721 seconds.\n",
                        "You can set `force_row_wise=true` to remove the overhead.\n",
                        "And if memory is not enough, you can set `force_col_wise=true`.\n",
                        "[LightGBM] [Info] Total Bins 959\n",
                        "[LightGBM] [Info] Number of data points in the train set: 38916, number of used features: 7\n",
                        "[LightGBM] [Info] Start training from score 4.719069\n"
                    ]
                }
            ],
            "source": [
                "# Creamos un metaclasificador usando como estimador base el mejor estimador obtenido\n",
                "model_bagging = BaggingRegressor(estimator=opt.best_estimator_, n_estimators=5, random_state=42).fit(X_train_scaled, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred_train = np.exp(model_bagging.predict(X_train_sc))\n",
                "y_pred_test = np.exp(model_bagging.predict(X_test_sc))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "42.97505669295065\n",
                        "46.45439888491071\n"
                    ]
                }
            ],
            "source": [
                "print(mean_absolute_error(y_train_euros,y_pred_train))\n",
                "print(mean_absolute_error(y_test_euros,y_pred_test))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.48835595709053614\n",
                        "0.43346522191378356\n"
                    ]
                }
            ],
            "source": [
                "print(r2_score(y_train_euros,y_pred_train))\n",
                "print(r2_score(y_test_euros,y_pred_test))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "29.16346213518426\n",
                        "31.552646191139637\n"
                    ]
                }
            ],
            "source": [
                "print(mean_absolute_percentage_error(y_train_euros,y_pred_train)*100)\n",
                "print(mean_absolute_percentage_error(y_test_euros,y_pred_test)*100)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>calculated_host_listings_count</th>\n",
                            "      <th>availability_365</th>\n",
                            "      <th>neighbourhood</th>\n",
                            "      <th>neighbourhood_group</th>\n",
                            "      <th>room_type</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0.25</td>\n",
                            "      <td>0.56</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.27</td>\n",
                            "      <td>0.25</td>\n",
                            "      <td>0.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0.57</td>\n",
                            "      <td>0.36</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.60</td>\n",
                            "      <td>0.58</td>\n",
                            "      <td>0.50</td>\n",
                            "      <td>0.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>0.43</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.91</td>\n",
                            "      <td>0.48</td>\n",
                            "      <td>0.75</td>\n",
                            "      <td>0.50</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>0.61</td>\n",
                            "      <td>0.33</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.15</td>\n",
                            "      <td>0.43</td>\n",
                            "      <td>0.50</td>\n",
                            "      <td>0.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>0.51</td>\n",
                            "      <td>0.37</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.29</td>\n",
                            "      <td>0.50</td>\n",
                            "      <td>0.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>38911</th>\n",
                            "      <td>0.29</td>\n",
                            "      <td>0.85</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.74</td>\n",
                            "      <td>0.29</td>\n",
                            "      <td>0.25</td>\n",
                            "      <td>1.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>38912</th>\n",
                            "      <td>0.63</td>\n",
                            "      <td>0.41</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.97</td>\n",
                            "      <td>0.58</td>\n",
                            "      <td>0.50</td>\n",
                            "      <td>0.50</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>38913</th>\n",
                            "      <td>0.28</td>\n",
                            "      <td>0.38</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.49</td>\n",
                            "      <td>0.83</td>\n",
                            "      <td>0.25</td>\n",
                            "      <td>0.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>38914</th>\n",
                            "      <td>0.37</td>\n",
                            "      <td>0.42</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.36</td>\n",
                            "      <td>0.25</td>\n",
                            "      <td>0.50</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>38915</th>\n",
                            "      <td>0.30</td>\n",
                            "      <td>0.41</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.13</td>\n",
                            "      <td>0.69</td>\n",
                            "      <td>0.25</td>\n",
                            "      <td>0.00</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>38916 rows × 7 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       latitude  longitude  calculated_host_listings_count  availability_365  \\\n",
                            "0          0.25       0.56                            0.00              0.00   \n",
                            "1          0.57       0.36                            1.00              0.60   \n",
                            "2          0.43       1.00                            0.00              0.91   \n",
                            "3          0.61       0.33                            0.00              0.15   \n",
                            "4          0.51       0.37                            0.00              0.00   \n",
                            "...         ...        ...                             ...               ...   \n",
                            "38911      0.29       0.85                            0.00              0.74   \n",
                            "38912      0.63       0.41                            1.00              0.97   \n",
                            "38913      0.28       0.38                            0.00              0.49   \n",
                            "38914      0.37       0.42                            0.00              0.00   \n",
                            "38915      0.30       0.41                            0.00              0.13   \n",
                            "\n",
                            "       neighbourhood  neighbourhood_group  room_type  \n",
                            "0               0.27                 0.25       0.00  \n",
                            "1               0.58                 0.50       0.00  \n",
                            "2               0.48                 0.75       0.50  \n",
                            "3               0.43                 0.50       0.00  \n",
                            "4               0.29                 0.50       0.00  \n",
                            "...              ...                  ...        ...  \n",
                            "38911           0.29                 0.25       1.00  \n",
                            "38912           0.58                 0.50       0.50  \n",
                            "38913           0.83                 0.25       0.00  \n",
                            "38914           0.36                 0.25       0.50  \n",
                            "38915           0.69                 0.25       0.00  \n",
                            "\n",
                            "[38916 rows x 7 columns]"
                        ]
                    },
                    "execution_count": 85,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X_train_scaled"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.preprocessing import FunctionTransformer\n",
                "import joblib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def custom_transform(X):\n",
                "  X_num = X\n",
                "  X_sc = scaler.transform(X_num)\n",
                "  return X_sc\n",
                "\n",
                "\n",
                "# Define los pasos del pipeline\n",
                "steps = [\n",
                "    ('custom_transform', FunctionTransformer(func=custom_transform)),  # Paso con función personalizada\n",
                "    ('modelo', model_bagging)  # Paso del modelo de regresión\n",
                "]\n",
                "\n",
                "# Crea el pipeline\n",
                "pipeline = Pipeline(steps)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['model_pipeline.pkl']"
                        ]
                    },
                    "execution_count": 95,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "joblib.dump(pipeline, 'model_pipeline.pkl')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "loaded_pipeline = joblib.load('model_pipeline.pkl')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Precio predicho: 207.02€\n"
                    ]
                }
            ],
            "source": [
                "cols = ['latitude', 'longitude', 'calculated_host_listings_count',\n",
                "        'availability_365', 'neighbourhood', 'neighbourhood_group', 'room_type']\n",
                "\n",
                "new_house_data =pd.DataFrame([[40.80, -73.94, 2, 365, 61, 2, 0]],columns=cols)\n",
                "\n",
                "print(f'Precio predicho: {round(np.exp(loaded_pipeline.predict(new_house_data))[0],2)}€')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
